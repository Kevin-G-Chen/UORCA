{
 "cells": [
  {
   "cell_type": "raw",
   "id": "232f6a47-2bc6-4384-8de9-14140fc9d4f8",
   "metadata": {},
   "source": [
    "This notebook will contain attempts to analyse Kallisto data.\n",
    "\n",
    "While Kallisto is downstream of downloading FASTQ files (and subsequently quantification via Kallisto), I will still just be starting here. \n",
    "\n",
    "My goals here are as follows:\n",
    "- Process metadata (including interpreting the different research groups, identifying what comparisons might be interesting, fixing any errors in the metadata. I will be providing a metadata sheet with mistakes to see how this will work.). Note that the prompt I end up needing here might have to be revised based on how I go with the dataset download.\n",
    "- Create (what I assume is) the DGEList object in Python, i.e. via PyDESeq2. If I can't get this to work, I will create an R script and call this script in Python. This is true for future steps too. Note that part of this entails being able to match samples to the correct files\n",
    "- Perform the filtering and normalisation. Should be straightfoward (I think...) if I can get the above to work\n",
    "- Perform the DEG analysis. Note that this relies on correctly identifying the groups. \n",
    "- Perform an ORA/GSEA. If I can get the above to work, this should be straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d5ce11-4322-466f-8ec6-397ca9f78750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2546b752-753c-4247-aa60-37fd3c702b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../.env')\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d981877-4137-4ef5-b1e7-4478705bd96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red, Orange, Yellow, Green, Blue, Indigo, Violet.\n"
     ]
    }
   ],
   "source": [
    "# Test OpenAI API...\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=openai_api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the colours of the rainbow? Only respond with the names of the colours.\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98796af4-7e42-4728-8bbf-84fbd8b487d2",
   "metadata": {},
   "source": [
    "I think my goal will be to integrate R, OpenAI, and Python. I would feel more confident working with an edgeR/limma based pipeline. \n",
    "\n",
    "Therefore, I will begin with just a simple implementation, testing SETBP1 data.\n",
    "\n",
    "Note that while sample data is provided with pydeseq2, this is completely synthetic - the genes are not real, and therefore this ends up not being very valuable.\n",
    "\n",
    "With R integration, the specific steps are as follows:\n",
    "- Identify the Kallisto files (likely no LLM needed)\n",
    "- Identify other files (i.e. tx2gene) (likely no LLM needed)\n",
    "- Process metadata, i.e. correct errors, match to Kallisto files (LLM needed)\n",
    "- Import Kallisto counts (no LLM needed)\n",
    "- Add metadata (and gene data) to the Kallisto counts, i.e. create DGEList object (no LLM needed)\n",
    "- Perform filtering and normalisation (no LLM needed, I can use default settings)\n",
    "- Define contrasts (probably the main hard part - from a value standpoint, there are considerations around which contrasts are interesting and valid, from the technical standpoint it's probably ok? Unsure how easily the LLM will interpret the metadata...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ccf30-35f8-4a34-aa73-24503445a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing correction of metadata"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d88fd0ff-c0d5-4b51-9f91-e5d241b4020c",
   "metadata": {},
   "source": [
    "I am going to begin with testing to see if I can get the LLM to analyse metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1bab847-c833-43f6-8115-5435954848e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test matching of Kallisto samples to metadata\n",
    "\n",
    "# I will begin by testing to see if 1) Kallisto samples can be matched to metadata based on the names of the samples in the metadata, and 2) if the two can be merged together in a single data frame\n",
    "\n",
    "class ColumnIdentification(BaseModel):\n",
    "    likely_sample_column: str = Field(..., description=\"The column name most likely to contain sample identifiers\")\n",
    "    confidence: float = Field(..., description=\"Confidence score for the column identification (0-1)\")\n",
    "    reasoning: str = Field(..., description=\"Explanation for why this column was chosen\")\n",
    "\n",
    "class SampleMatch(BaseModel):\n",
    "    metadata_sample: str = Field(..., description=\"The sample name from the metadata\")\n",
    "    file_name: str = Field(..., description=\"The matched file name\")\n",
    "    confidence: float = Field(..., description=\"Confidence score of the match (0-1)\")\n",
    "\n",
    "class MatchResult(BaseModel):\n",
    "    column_identification: ColumnIdentification = Field(..., description=\"Identification of the sample name column\")\n",
    "    matches: List[SampleMatch] = Field(..., description=\"List of matched samples and file names\")\n",
    "    matching_logic: str = Field(..., description=\"Explanation of the logic used to match samples to file names\")\n",
    "\n",
    "def read_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def create_prompt(metadata_df, file_names):\n",
    "    prompt = f\"\"\"Analyze the following metadata and list of file names:\n",
    "\n",
    "Metadata columns:\n",
    "{metadata_df.columns.tolist()}\n",
    "\n",
    "Metadata:\n",
    "{metadata_df.to_string()}\n",
    "\n",
    "File names:\n",
    "{file_names}\n",
    "\n",
    "Tasks:\n",
    "1. Identify the column most likely to contain sample identifiers. Provide the column name, a confidence score, and your reasoning.\n",
    "2. Match each sample from the identified column to the most likely corresponding file name. Consider variations in capitalization, spaces, dashes, and potential typos.\n",
    "3. Explain the logic you used to match samples to file names.\n",
    "\n",
    "Provide your analysis in a structured format.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def get_openai_response(prompt, openai_api_key):\n",
    "    client = instructor.patch(OpenAI(\n",
    "    api_key=openai_api_key))\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_model=MatchResult\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def update_metadata(metadata_df, match_result):\n",
    "    sample_column = match_result.column_identification.likely_sample_column\n",
    "    file_name_dict = {match.metadata_sample: match.file_name for match in match_result.matches}\n",
    "    metadata_df['file_name'] = metadata_df[sample_column].map(file_name_dict)\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ff40434-4b29-4d85-9749-f25219082f3d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likely sample name column: Sample Name\n",
      "Confidence: 1.0\n",
      "Reasoning: The 'Sample Name' column contains names that are structured similarly to the file names, with consistent patterns allowing for clear correspondence.\n",
      "\n",
      "Matching logic:\n",
      "The matching was performed by normalizing both sample identifiers and file names to a consistent format: converting underscores to dashes, stripping out spaces, and ensuring uniform casing. The resulting normalized names were then compared for exact matches.\n",
      "\n",
      "Updated Metadata:\n",
      "                          Sample Name Transfection      Genotype Cell type   \\\n",
      "0      KOLF2_SETBP1_VUS2_A21_10_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "1       KOLF2_SETBP1_VUS2_A21_7_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "2     KOLF2_SETBP1_VUS2_A21_10_day 24            A   VUS2 HDR/WT        NPC   \n",
      "3      KOLF2_SETBP1_VUS2_A21_7_day 24            A   VUS2 HDR/WT        NPC   \n",
      "4      KOLF2_SETBP1_VUS2_B1_4.1_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "5      KOLF2_SETBP1_VUS2_B1_4.2_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "6     KOLF2_SETBP1_VUS2_B1_4.1_day 24            B   VUS2 HDR/WT        NPC   \n",
      "7     KOLF2_SETBP1_VUS2_B1_4.2_day 24            B   VUS2 HDR/WT        NPC   \n",
      "8    KOLF2_SETBP1_VUS2_C12.1_WT_day 0            C         WT/WT       iPSC   \n",
      "9    KOLF2_SETBP1_VUS2_C12.2_WT_day 0            C         WT/WT       iPSC   \n",
      "10   KOLF2_SETBP1_VUS2_C12.3_WT_day 0            C         WT/WT       iPSC   \n",
      "11  KOLF2_SETBP1_VUS2_C12.1_WT_day 24            C         WT/WT        NPC   \n",
      "12  KOLF2_SETBP1_VUS2_C12.2_WT_day 24            C         WT/WT        NPC   \n",
      "13  KOLF2_SETBP1_VUS2_C12.3_WT_day 24            C         WT/WT        NPC   \n",
      "14    KOLF2_SETBP1_PATH1_4.6_WT_day 0            D         WT/WT       iPSC   \n",
      "15    KOLF2_SETBP1_PATH1_4.7_WT_day 0            D         WT/WT       iPSC   \n",
      "16   KOLF2_SETBP1_PATH1_4.6_WT_day 24            D         WT/WT        NPC   \n",
      "17   KOLF2_SETBP1_PATH1_4.7_WT_day 24            D         WT/WT        NPC   \n",
      "18       KOLF2_SETBP1_PATH2_3.2_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "19    KOLF2_SETBP1_PATH2_3.3_WT_day 0            E         WT/WT       iPSC   \n",
      "20       KOLF2_SETBP1_PATH2_3.4_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "21       KOLF2_SETBP1_PATH2_3.6_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "22      KOLF2_SETBP1_PATH2_3.2_day 24            E  PATH2 HDR/WT        NPC   \n",
      "23   KOLF2_SETBP1_PATH2_3.3_WT_day 24            E         WT/WT        NPC   \n",
      "24      KOLF2_SETBP1_PATH2_3.4_day 24            E  PATH2 HDR/WT        NPC   \n",
      "25      KOLF2_SETBP1_PATH2_3.6_day 24            E  PATH2 HDR/WT        NPC   \n",
      "26     KOLF2_SETBP1_PATH3_15.10_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "27    KOLF2_SETBP1_PATH3_15.7.1_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "28    KOLF2_SETBP1_PATH3_15.7.2_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "29    KOLF2_SETBP1_PATH3_15.10_day 24            F  PATH3 HDR/WT        NPC   \n",
      "30   KOLF2_SETBP1_PATH3_15.7.1_day 24            F  PATH3 HDR/WT        NPC   \n",
      "31   KOLF2_SETBP1_PATH3_15.7.2_day 24            F  PATH3 HDR/WT        NPC   \n",
      "\n",
      "    Neural differentiation set                                       file_name  \n",
      "0                            2     KOLF2-SETBP1-VUS2-A21-10-day-0/abundance.h5  \n",
      "1                            1      KOLF2-SETBP1-VUS2-A21-7-day-0/abundance.h5  \n",
      "2                            2    KOLF2-SETBP1-VUS2-A21-10-day-24/abundance.h5  \n",
      "3                            1     KOLF2-SETBP1-VUS2-A21-7-day-24/abundance.h5  \n",
      "4                            1     KOLF2-SETBP1-VUS2-B1-4-1-day-0/abundance.h5  \n",
      "5                            2     KOLF2-SETBP1-VUS2-B1-4-2-day-0/abundance.h5  \n",
      "6                            1    KOLF2-SETBP1-VUS2-B1-4-1-day-24/abundance.h5  \n",
      "7                            2    KOLF2-SETBP1-VUS2-B1-4-2-day-24/abundance.h5  \n",
      "8                            1   KOLF2-SETBP1-VUS2-C12-1-WT-day-0/abundance.h5  \n",
      "9                            1   KOLF2-SETBP1-VUS2-C12-2-WT-day-0/abundance.h5  \n",
      "10                           2   KOLF2-SETBP1-VUS2-C12-3-WT-day-0/abundance.h5  \n",
      "11                           1  KOLF2-SETBP1-VUS2-C12-1-WT-day-24/abundance.h5  \n",
      "12                           1  KOLF2-SETBP1-VUS2-C12-2-WT-day-24/abundance.h5  \n",
      "13                           2  KOLF2-SETBP1-VUS2-C12-3-WT-day-24/abundance.h5  \n",
      "14                           1    KOLF2-SETBP1-PATH1-4-6-WT-day-0/abundance.h5  \n",
      "15                           2    KOLF2-SETBP1-PATH1-4-7-WT-day-0/abundance.h5  \n",
      "16                           1   KOLF2-SETBP1-PATH1-4-6-WT-day-24/abundance.h5  \n",
      "17                           2   KOLF2-SETBP1-PATH1-4-7-WT-day-24/abundance.h5  \n",
      "18                           1       KOLF2-SETBP1-PATH2-3-2-day-0/abundance.h5  \n",
      "19                           2    KOLF2-SETBP1-PATH2-3-3-WT-day-0/abundance.h5  \n",
      "20                           1       KOLF2-SETBP1-PATH2-3-4-day-0/abundance.h5  \n",
      "21                           2       KOLF2-SETBP1-PATH2-3-6-day-0/abundance.h5  \n",
      "22                           1      KOLF2-SETBP1-PATH2-3-2-day-24/abundance.h5  \n",
      "23                           2   KOLF2-SETBP1-PATH2-3-3-WT-day-24/abundance.h5  \n",
      "24                           1      KOLF2-SETBP1-PATH2-3-4-day-24/abundance.h5  \n",
      "25                           2      KOLF2-SETBP1-PATH2-3-6-day-24/abundance.h5  \n",
      "26                           2     KOLF2-SETBP1-PATH3-15-10-day-0/abundance.h5  \n",
      "27                           1    KOLF2-SETBP1-PATH3-15-7-1-day-0/abundance.h5  \n",
      "28                           2    KOLF2-SETBP1-PATH3-15-7-2-day-0/abundance.h5  \n",
      "29                           2    KOLF2-SETBP1-PATH3-15-10-day-24/abundance.h5  \n",
      "30                           1   KOLF2-SETBP1-PATH3-15-7-1-day-24/abundance.h5  \n",
      "31                           2   KOLF2-SETBP1-PATH3-15-7-2-day-24/abundance.h5  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    api_key = openai_api_key\n",
    "\n",
    "    # Path to your metadata CSV file\n",
    "    metadata_file_path = \"../InputData/SETBP1_Tests/SETBP1_RNAseq_samples.csv\"\n",
    "    \n",
    "    # Read the metadata CSV file\n",
    "    metadata_df = read_csv(metadata_file_path)\n",
    "    \n",
    "    # List of sample file names (you would typically read this from a directory or another source)\n",
    "    with open(\"../InputData/SETBP1_Tests/abundance_files.txt\", 'r') as file:\n",
    "        file_names = file.read()\n",
    "    \n",
    "    # Create a prompt with the metadata and file names\n",
    "    prompt = create_prompt(metadata_df, file_names)\n",
    "    \n",
    "    # Get the response from OpenAI\n",
    "    response = get_openai_response(prompt, openai_api_key)\n",
    "    # Print the identified sample name column and reasoning\n",
    "    print(f\"Likely sample name column: {response.column_identification.likely_sample_column}\")\n",
    "    print(f\"Confidence: {response.column_identification.confidence}\")\n",
    "    print(f\"Reasoning: {response.column_identification.reasoning}\\n\")\n",
    "    \n",
    "    # Print the matching logic\n",
    "    print(\"Matching logic:\")\n",
    "    print(response.matching_logic)\n",
    "    print()\n",
    "    \n",
    "    # Update the metadata DataFrame with matched file names\n",
    "    updated_metadata = update_metadata(metadata_df, response)\n",
    "    \n",
    "    # Print the updated metadata\n",
    "    print(\"Updated Metadata:\")\n",
    "    print(updated_metadata)\n",
    "    \n",
    "    # Optionally, save the updated metadata to a new CSV file\n",
    "    updated_metadata.to_csv(\"../results/2024_07_31_AutomatedDataProcessing/Clean_MetadataSampleMatching.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f8b5a8b-37e0-4dd3-ac7b-0536f5ca6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat above but with a more error-filled CSV. This will also be where I refine my prompt.\n",
    "\n",
    "class ColumnIdentification(BaseModel):\n",
    "    likely_sample_column: str = Field(..., description=\"The column name most likely to contain sample identifiers\")\n",
    "    confidence: float = Field(..., description=\"Confidence score for the column identification (0-1)\")\n",
    "    reasoning: str = Field(..., description=\"Explanation for why this column was chosen\")\n",
    "\n",
    "class SampleMatch(BaseModel):\n",
    "    metadata_sample: str = Field(..., description=\"The sample name from the metadata\")\n",
    "    file_name: str = Field(..., description=\"The matched file name\")\n",
    "    confidence: float = Field(..., description=\"Confidence score of the match (0-1)\")\n",
    "\n",
    "class MatchResult(BaseModel):\n",
    "    column_identification: ColumnIdentification = Field(..., description=\"Identification of the sample name column\")\n",
    "    matches: List[SampleMatch] = Field(..., description=\"List of matched samples and file names\")\n",
    "    matching_logic: str = Field(..., description=\"Explanation of the logic used to match samples to file names\")\n",
    "\n",
    "def read_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def get_openai_response(prompt, openai_api_key):\n",
    "    client = instructor.patch(OpenAI(\n",
    "    api_key=openai_api_key))\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_model=MatchResult\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def update_metadata(metadata_df, match_result):\n",
    "    sample_column = match_result.column_identification.likely_sample_column\n",
    "    file_name_dict = {match.metadata_sample: match.file_name for match in match_result.matches}\n",
    "    file_match_score = {match.metadata_sample: match.confidence for match in match_result.matches}\n",
    "    metadata_df['file_name'] = metadata_df[sample_column].map(file_name_dict)\n",
    "    metadata_df['match_confidence'] = metadata_df[sample_column].map(file_match_score)\n",
    "    return metadata_df\n",
    "\n",
    "def process_metadata_and_files(metadata_file_path, file_names_path, openai_api_key):\n",
    "    # Read the metadata CSV file\n",
    "    metadata_df = read_csv(metadata_file_path)\n",
    "    \n",
    "    # Read the list of sample file names. For the moment I just manually specified the input text files, but this will need to change later.\n",
    "    with open(file_names_path, 'r') as file:\n",
    "        file_names = file.read().splitlines()\n",
    "    \n",
    "    # Create a prompt with the metadata and file names\n",
    "    prompt = create_prompt(metadata_df, file_names)\n",
    "    \n",
    "    # Get the response from OpenAI\n",
    "    response = get_openai_response(prompt, openai_api_key)\n",
    "    \n",
    "    if isinstance(response, str):\n",
    "        print(response)\n",
    "        return\n",
    "    \n",
    "    # Print the identified sample name column and reasoning\n",
    "    print(f\"Likely sample name column: {response.column_identification.likely_sample_column}\")\n",
    "    print(f\"Confidence: {response.column_identification.confidence}\")\n",
    "    print(f\"Reasoning: {response.column_identification.reasoning}\\n\")\n",
    "    \n",
    "    # Print the matching logic\n",
    "    print(\"Matching logic:\")\n",
    "    print(response.matching_logic)\n",
    "    print()\n",
    "    \n",
    "    # Update the metadata DataFrame with matched file names\n",
    "    updated_metadata = update_metadata(metadata_df, response)\n",
    "    \n",
    "    # Print the updated metadata\n",
    "    return(updated_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "556ef456-657b-476f-b86c-965b69c301d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likely sample name column: Sample Name\n",
      "Confidence: 0.95\n",
      "Reasoning: The metadata column 'Sample Name' contains identifiers for the samples, which typically aligns with the format of file names that include sample identifiers and respective conditions.\n",
      "\n",
      "Matching logic:\n",
      "I matched the file names to the metadata samples by normalizing both data sets. I transformed both the sample names in the metadata and the file names to a consistent format by removing punctuations, standardizing case, and replacing spaces with hyphens. Each file name was then iteratively checked for substring matches against the cleaned sample names using a confidence scoring system based on the degree of exact match and logical adjustments for minor discrepancies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    api_key = openai_api_key\n",
    "\n",
    "    # Path to your metadata CSV file\n",
    "    metadata_file_path = \"../InputData/SETBP1_Tests/SETBP1_RNAseq_samples_errors.csv\"\n",
    "    \n",
    "    # Path to your file names list\n",
    "    file_names_path = \"../InputData/SETBP1_Tests/abundance_files.txt\"\n",
    "    \n",
    "    # Process the metadata and files\n",
    "    updated_metadata = process_metadata_and_files(metadata_file_path, file_names_path, api_key)\n",
    "\n",
    "updated_metadata.to_csv(\"../results/2024_07_31_AutomatedDataProcessing/Errors_MetadataSampleMatching.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d0dba03-3a9a-4c18-bcfd-1a741692391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.to_string of                           Sample Name Transfection      Genotype Cell type   \\\n",
      "0      KOLF2_SETBP1_VUS2_A21_10_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "1      KOLF2_SETBP1_ VUS2_A21_7_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "2   KOLF2_SETBP1_VUS2_A21_10_day 24.             A          VUS@        NPC   \n",
      "3      KOLF2_SETBP1_VUS2_A21_7_day 24            A   VUS2 HDR/WT        NPC   \n",
      "4      KOLF2_SETBP1_VUS2_B1_4.1_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "5      KOLF2_SETBP1_VUS2_B1_4.2_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "6     KOLF2_SETBP1_VUS2_B1_4.1_day 24            B   vus2 HDR/WT        NPC   \n",
      "7     KOLF2_SETBP1_VUS2_B1_4.2_day 24            B   VUS2 HDR/WT        NPC   \n",
      "8    KOLF2_SETBP1_VUS2_C12.1_WT_day 0            C         WT/WT       iPSC   \n",
      "9    KOLF2_SETBP1_VUS2_C12.2_WT_day 0            C         WT/WT       iPSC   \n",
      "10   KOLF2_SETBP1_VUS2_C12-3_WT_day 0            C         WT/WT       iPSC   \n",
      "11  KOLF2_SETBP1_VUS2_C12.1_WT_day 24            C         WT/WT        NPC   \n",
      "12  KOLF2_SETBP1_VUS2_C12.2_WT_day 24            C         WT/WT        NPC   \n",
      "13  KOLF2_SETBP1_VUS2_C12.3_WT_day 24            C         WT/WT        NPC   \n",
      "14    KOLF2_SETBP1_PATH1_4.6_WT_day 0            D           NaN       iPSC   \n",
      "15    KOLF2_SETBP1_PATH1_4.7_WT_day 0            D         WT/WT       iPSC   \n",
      "16   KOLF2_SETBP1_PATH1_4.6_WT_day 24            D         WT/wt        NaN   \n",
      "17   KOLF2_SETBP1_PATH1_4.7_WT_day 24            D         WT/WT        NaN   \n",
      "18        KOLF2_SETBP1_PATH2_3.2_day0            E  PATH2 HDR/WT       iPSC   \n",
      "19    KOLF2_SETBP1_PATH2_3.3_WT_day 0            E         WT/WT       iPSC   \n",
      "20       KOLF2_SETBP1_PATH2_3.4_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "21       KOLF2_SETBP1_PATH2_3.6_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "22      KOLF2_SETBP1_PATH2_3.2_day 24            E  PATH2 HDR/WT        NPC   \n",
      "23   kolf2_SETBP1_PATH2_3.3_WT_day 24            E         WT/WT        NPC   \n",
      "24      KOLF2_SETBP1_PATH2_3.4_day 24            E  PATH2 HDR/WT        NPC   \n",
      "25      KLOF2_SETBP1_PATH2_3.6_day 24            E  PATH2 HDR/WT        NPC   \n",
      "26     KOLF2_SETBP1_PATH3_15.10_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "27    KOLF2_SETBP1_PATH3_15.7.1_day 0            F         PATH3       iPSC   \n",
      "28    KOLF2_SETPB1_PATH3_15.7.2_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "29    KOLF2_SETBP1_PATH3_15.10_day 24            F  PATH3 HDR/WT        NPC   \n",
      "30   KOLF2_SETBP1_PATH3_15.7.1_day 24            F  PATH3 HDR/WT        NPC   \n",
      "31   KOLF2_SETBP1_PATH3_15.7.2_day 24            F  PATH3 HDR/WT        NPC   \n",
      "\n",
      "    Neural differentiation set  \n",
      "0                            2  \n",
      "1                            1  \n",
      "2                            2  \n",
      "3                            1  \n",
      "4                            1  \n",
      "5                            2  \n",
      "6                            1  \n",
      "7                            2  \n",
      "8                            1  \n",
      "9                            1  \n",
      "10                           2  \n",
      "11                           1  \n",
      "12                           1  \n",
      "13                           2  \n",
      "14                           1  \n",
      "15                           2  \n",
      "16                           1  \n",
      "17                           2  \n",
      "18                           1  \n",
      "19                           2  \n",
      "20                           1  \n",
      "21                           2  \n",
      "22                           1  \n",
      "23                           2  \n",
      "24                           1  \n",
      "25                           2  \n",
      "26                           2  \n",
      "27                           1  \n",
      "28                           2  \n",
      "29                           2  \n",
      "30                           1  \n",
      "31                           2  >\n"
     ]
    }
   ],
   "source": [
    "metadata_df = read_csv(\"../InputData/SETBP1_Tests/SETBP1_RNAseq_samples_errors.csv\")\n",
    "    \n",
    "    # Read the list of sample file names. For the moment I just manually specified the input text files, but this will need to change later.\n",
    "with open(file_names_path, 'r') as file:\n",
    "    file_names = file.read().splitlines()\n",
    "\n",
    "class ColumnIdentification(BaseModel):\n",
    "    likely_sample_column: str = Field(..., description=\"The column name most likely to contain sample identifiers\")\n",
    "    confidence: float = Field(..., description=\"Confidence score for the column identification (0-1)\")\n",
    "    reasoning: str = Field(..., description=\"Explanation for why this column was chosen\")\n",
    "\n",
    "class SampleMatch(BaseModel):\n",
    "    metadata_sample: str = Field(..., description=\"The matched sample name as reported in the metadata\")\n",
    "    file_name: str = Field(..., description=\"The file name\")\n",
    "    confidence: float = Field(..., description=\"Confidence score of the match (0-1)\")\n",
    "\n",
    "class MatchResult(BaseModel):\n",
    "    column_identification: ColumnIdentification = Field(..., description=\"Identification of the sample name column\")\n",
    "    matches: List[SampleMatch] = Field(..., description=\"List of matched samples and file names\")\n",
    "\n",
    "def create_prompt(metadata_df, file_names):\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "## IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert in bioinformatic analyses. You will be provided with a list of files, and a metadata data frame. You are tasked with matching the file names to the existing metadata data frame. \n",
    "\n",
    "Take a deep breath, and carefully follow the steps outlined below to achieve the intended task.\n",
    "\n",
    "## STEPS\n",
    "\n",
    "1. First, identify the column name that is most likely to correspond to sample names. Focus on words such as \"sample name\" or \"ID\" to make this judgement.\n",
    "2. Match ALL file names to rows in the metadata. Keep the following in mind:\n",
    "- Every file name should match to a row in the metadata\n",
    "- There may be errors in the metadata\n",
    "- You should make efforts to identify likely errors, and consider the possibility of a match if the error was corrected\n",
    "- Examples of errors include random spaces, incorrect spellings, inconsistent cases, and random punctuations\n",
    "- Note that you may need to systematically apply some rules to better identify matches\n",
    "- Do not prescriptively follow a rule to find matches; be flexible instead\n",
    "- If a file name does not have a match in the sample metadata, report this as \"No Match\"\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "Provided your analysis in a structured format:\n",
    "1. Provide the column name most likely to correspond to sample names, with a confidence score and reasoning.\n",
    "2. List of EACH file, and the most likely corresponding sample name. Report the sample name EXACTLY as it is in the metadata - do not attempt to correct the metadata value. Similarly, report the file name EXACTLY as given.\n",
    "\n",
    "## INPUT\n",
    "Metadata columns:\n",
    "{metadata_df.columns.tolist()}\n",
    "\n",
    "Metadata:\n",
    "{metadata_df.to_string()}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "    \n",
    "prompt = create_prompt(metadata_df, file_names)\n",
    "\n",
    "def get_openai_response(prompt, openai_api_key):\n",
    "    client = instructor.patch(OpenAI(\n",
    "    api_key=openai_api_key))\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_tokens = 10000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_model=MatchResult\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "response = get_openai_response(prompt, openai_api_key)\n",
    "print(metadata_df.to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c5d82e3-22be-431f-86f3-3f4de0dfba1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_A21_10_day 0', file_name='KOLF2_SETBP1_VUS2_A21_10_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_ VUS2_A21_7_day 0', file_name='KOLF2_SETBP1_ VUS2_A21_7_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_A21_10_day 24.', file_name='KOLF2_SETBP1_VUS2_A21_10_day 24.', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_A21_7_day 24', file_name='KOLF2_SETBP1_VUS2_A21_7_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.1_day 0', file_name='KOLF2_SETBP1_VUS2_B1_4.1_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.2_day 0', file_name='KOLF2_SETBP1_VUS2_B1_4.2_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.1_day 24', file_name='KOLF2_SETBP1_VUS2_B1_4.1_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.2_day 24', file_name='KOLF2_SETBP1_VUS2_B1_4.2_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.1_WT_day 0', file_name='KOLF2_SETBP1_VUS2_C12.1_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.2_WT_day 0', file_name='KOLF2_SETBP1_VUS2_C12.2_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12-3_WT_day 0', file_name='KOLF2_SETBP1_VUS2_C12-3_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.1_WT_day 24', file_name='KOLF2_SETBP1_VUS2_C12.1_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.2_WT_day 24', file_name='KOLF2_SETBP1_VUS2_C12.2_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.3_WT_day 24', file_name='KOLF2_SETBP1_VUS2_C12.3_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.6_WT_day 0', file_name='KOLF2_SETBP1_PATH1_4.6_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.7_WT_day 0', file_name='KOLF2_SETBP1_PATH1_4.7_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.6_WT_day 24', file_name='KOLF2_SETBP1_PATH1_4.6_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.7_WT_day 24', file_name='KOLF2_SETBP1_PATH1_4.7_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.2_day0', file_name='KOLF2_SETBP1_PATH2_3.2_day0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.3_WT_day 0', file_name='KOLF2_SETBP1_PATH2_3.3_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.4_day 0', file_name='KOLF2_SETBP1_PATH2_3.4_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.6_day 0', file_name='KOLF2_SETBP1_PATH2_3.6_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.2_day 24', file_name='KOLF2_SETBP1_PATH2_3.2_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.3_WT_day 24', file_name='KOLF2_SETBP1_PATH2_3.3_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.4_day 24', file_name='KOLF2_SETBP1_PATH2_3.4_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KLOF2_SETBP1_PATH2_3.6_day 24', file_name='KLOF2_SETBP1_PATH2_3.6_day 24', confidence=0.9),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.10_day 0', file_name='KOLF2_SETBP1_PATH3_15.10_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.7.1_day 0', file_name='KOLF2_SETBP1_PATH3_15.7.1_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETPB1_PATH3_15.7.2_day 0', file_name='No Match', confidence=0.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.10_day 24', file_name='KOLF2_SETBP1_PATH3_15.10_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.7.1_day 24', file_name='KOLF2_SETBP1_PATH3_15.7.1_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.7.2_day 24', file_name='KOLF2_SETBP1_PATH3_15.7.2_day 24', confidence=1.0)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "755fbffc-9354-4b67-9bc8-ce8a128d0337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Column Names and Descriptions:\n",
      "\n",
      "1. **title**: Identifies the specific dataset and sample information.\n",
      "2. **geo_accession**: Unique identifier for the data entry in the Gene Expression Omnibus (GEO) database.\n",
      "3. **status**: Current status of the dataset (e.g., Public).\n",
      "4. **submission_date**: Date when the dataset was submitted to GEO.\n",
      "5. **last_update_date**: The date of the most recent update of the dataset.\n",
      "6. **type**: The type of study (e.g., SRA).\n",
      "7. **channel_count**: Number of channels used in the experiment.\n",
      "8. **source_name_ch1**: The name of the source tissue or sample origin.\n",
      "9. **organism_ch1**: The organism from which the samples were derived, predominantly \"Homo sapiens\".\n",
      "10. **characteristics_ch1**: A categorical descriptor of the sample (e.g. tissue type).\n",
      "11. **characteristics_ch1.1**: Additional categorical descriptor regarding patient or sample characteristics.\n",
      "12. **characteristics_ch1.2**: More detailed information about disease state or context.\n",
      "13. **characteristics_ch1.3**: Further informative categories, possibly related to sampling.\n",
      "14. **characteristics_ch1.4**: Additional specific characteristics of the samples.\n",
      "15. **characteristics_ch1.5**: More categorical descriptors for sample context.\n",
      "16. **molecule_ch1**: The type of molecule being analyzed, such as RNA.\n",
      "17. **extract_protocol_ch1**: Description of the extraction protocol used for sampling.\n",
      "18. **taxid_ch1**: Taxonomic identifier for the organism.\n",
      "19. **data_processing**: Overview of data processing steps.\n",
      "20. **data_processing.1**: Additional processing information.\n",
      "21. **data_processing.2**: More on data processing methods used.\n",
      "22. **data_processing.3**: Extra data preprocessing details.\n",
      "23. **data_processing.4**: Final aspects of processing pipeline.\n",
      "24. **data_processing.5**: Information related to data normalization or quality control.\n",
      "25. **data_processing.6**: Last processing details before data submission.\n",
      "26. **platform_id**: Identifier for the platform used to generate the data.\n",
      "27. **contact_name**: Name of the individual to contact about the dataset.\n",
      "28. **contact_email**: Email address for dataset inquiries.\n",
      "29. **contact_department**: Department affiliation of the contact person.\n",
      "30. **contact_institute**: Institution associated with the dataset.\n",
      "31. **contact_address**: Address for the contact institution.\n",
      "32. **contact_city**: City of the contact institution.\n",
      "33. **contact_state**: State of the contact institution.\n",
      "34. **contact_zip/postal_code**: Zip or postal code for contact institution.\n",
      "35. **contact_country**: Country of the contact institution.\n",
      "36. **data_row_count**: Number of data rows present in the dataset.\n",
      "37. **instrument_model**: Model of the instrument used for the data collection.\n",
      "38. **library_selection**: Method used for library selection in sequencing.\n",
      "39. **library_source**: Source of the library used in sequencing.\n",
      "40. **library_strategy**: Strategy used for library preparation.\n",
      "41. **relation**: Relation between sample types or other datasets.\n",
      "42. **relation.1**: Additional relational metadata.\n",
      "43. **supplementary_file_1**: Links to supplementary files related to the dataset.\n",
      "44. **disease:ch1**: Disease state associated with the sample.\n",
      "45. **patient:ch1**: Unique patient identifier linked to each sample.\n",
      "46. **region of_interest_(roi):ch1**: Description of the region of interest sampled.\n",
      "47. **roi nuclei_count:ch1**: Count of nuclei observed in the region of interest.\n",
      "48. **roi surface_area:ch1**: Surface area measurement of the sampled region.\n",
      "49. **tissue:ch1**: Type of tissue being analyzed.\n",
      "\n",
      "### Interesting Comparisons for Analysis:\n",
      "\n",
      "1. **Comparison 1: disease:ch1**  \n",
      "   **Values**: HS vs Cyst  \n",
      "   **Justification**: Comparing tissue samples derived from healthy skin affected by the disease (HS) vs those derived from cyst patients could provide insights into disease mechanisms and tissue alterations due to different pathologies.\n",
      "\n",
      "2. **Comparison 2: region of_interest_(roi):ch1**  \n",
      "   **Values**: \"Epidermis\" vs \"Stroma\"  \n",
      "   **Justification**: This contrast presents an opportunity to explore the differential expression profiles between the epidermal and stromal compartments in skin tissue, which may have significant implications for understanding skin biology and pathology.\n",
      "\n",
      "3. **Comparison 3: patient:ch1**  \n",
      "   **Values**: patient 4 vs patient 2  \n",
      "   **Justification**: Differences between patient samples allow for the examination of inter-individual variation in gene expression related to skin conditions and could lead to personalized treatment approaches depending on patient characteristics.\n",
      "\n",
      "4. **Comparison 4: roi nuclei_count:ch1**  \n",
      "   **Values**: High (>800) vs Low (<800)  \n",
      "   **Justification**: Analyzing differences in gene expression based on nuclei count can give insights into the cellularity and health of the tissue, which is critical for understanding tumor microenvironments or the pathology of other skin diseases.\n",
      "\n",
      "5. **Comparison 5: tissue:ch1**  \n",
      "   **Values**: \"Skin\" vs \"CD31 Rich\" or \"Plasma Cell Rich\"  \n",
      "   **Justification**: contrasting gene expression in typical skin versus regions rich in specific cellular populations (e.g., CD31, associated with angiogenesis) could elucidate local tissue adaptations and responses in the context of pathologies like HS or cysts.\n"
     ]
    }
   ],
   "source": [
    "# Testing for identification of interesting comparisons \n",
    "\n",
    "meta = pd.read_csv(\"../InputData/GSE273227_SkinTests/meta.csv\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "## IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert in bioinformatic analyses. You will be provided with a metadata sheet, and are tasked with identifying contrasts that could be interesting in the metadata, with the intention of analysing these in a edgeR/limma based pipeline.\n",
    "Take a deep breath, and carefully follow the steps outlined below to achieve the intended task.\n",
    "\n",
    "## STEPS\n",
    "\n",
    "1. Carefully consider each column, inferring what each column means from its name, and also the values in the column. \n",
    "2. Determine columns that appear to contain data that would be scientifically and biologically interesting to compare within the column.\n",
    "- Only include comparisons that can be easily analysed in a limma/edgeR based pipeline\n",
    "- Only include comparisons that would be valuable to the literature generally, and not just within the dataset\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "1. State all column names EXACTLY, and also include a brief 1 sentence description of what each column contains\n",
    "2. State 5 comparisons that would be interesting to analyse in a limma/edgeR-based pipeline. \n",
    "3. For each comparison, include the EXACT column name, as well as the EXACT values that should be used for the comparison. Additionally, justify why the comparison would be interesting using up to 3 sentences\n",
    "\n",
    "\n",
    "## INPUT\n",
    "\n",
    "Metadata:\n",
    "{meta.to_string()}\n",
    "\"\"\"\n",
    "client = OpenAI(\n",
    "  api_key=openai_api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens = 6000\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0360f5-f8dd-464d-b592-8e33c8f55e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Poetry)",
   "language": "python",
   "name": "poetry-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
