{
 "cells": [
  {
   "cell_type": "raw",
   "id": "232f6a47-2bc6-4384-8de9-14140fc9d4f8",
   "metadata": {},
   "source": [
    "This notebook will contain attempts to analyse Kallisto data.\n",
    "\n",
    "While Kallisto is downstream of downloading FASTQ files (and subsequently quantification via Kallisto), I will still just be starting here. \n",
    "\n",
    "My goals here are as follows:\n",
    "- Process metadata (including interpreting the different research groups, identifying what comparisons might be interesting, fixing any errors in the metadata. I will be providing a metadata sheet with mistakes to see how this will work.). Note that the prompt I end up needing here might have to be revised based on how I go with the dataset download.\n",
    "- Create (what I assume is) the DGEList object in Python, i.e. via PyDESeq2. If I can't get this to work, I will create an R script and call this script in Python. This is true for future steps too. Note that part of this entails being able to match samples to the correct files\n",
    "- Perform the filtering and normalisation. Should be straightfoward (I think...) if I can get the above to work\n",
    "- Perform the DEG analysis. Note that this relies on correctly identifying the groups. \n",
    "- Perform an ORA/GSEA. If I can get the above to work, this should be straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d5ce11-4322-466f-8ec6-397ca9f78750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2546b752-753c-4247-aa60-37fd3c702b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../.env')\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d981877-4137-4ef5-b1e7-4478705bd96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red, Orange, Yellow, Green, Blue, Indigo, Violet.\n"
     ]
    }
   ],
   "source": [
    "# Test OpenAI API...\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=openai_api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the colours of the rainbow? Only respond with the names of the colours.\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98796af4-7e42-4728-8bbf-84fbd8b487d2",
   "metadata": {},
   "source": [
    "I think my goal will be to integrate R, OpenAI, and Python. I would feel more confident working with an edgeR/limma based pipeline. \n",
    "\n",
    "Therefore, I will begin with just a simple implementation, testing SETBP1 data.\n",
    "\n",
    "Note that while sample data is provided with pydeseq2, this is completely synthetic - the genes are not real, and therefore this ends up not being very valuable.\n",
    "\n",
    "With R integration, the specific steps are as follows:\n",
    "- Identify the Kallisto files (likely no LLM needed)\n",
    "- Identify other files (i.e. tx2gene) (likely no LLM needed)\n",
    "- Process metadata, i.e. correct errors, match to Kallisto files (LLM needed)\n",
    "- Import Kallisto counts (no LLM needed)\n",
    "- Add metadata (and gene data) to the Kallisto counts, i.e. create DGEList object (no LLM needed)\n",
    "- Perform filtering and normalisation (no LLM needed, I can use default settings)\n",
    "- Define contrasts (probably the main hard part - from a value standpoint, there are considerations around which contrasts are interesting and valid, from the technical standpoint it's probably ok? Unsure how easily the LLM will interpret the metadata...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ccf30-35f8-4a34-aa73-24503445a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing correction of metadata"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d88fd0ff-c0d5-4b51-9f91-e5d241b4020c",
   "metadata": {},
   "source": [
    "I am going to begin with testing to see if I can get the LLM to analyse metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1bab847-c833-43f6-8115-5435954848e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test matching of Kallisto samples to metadata\n",
    "\n",
    "# I will begin by testing to see if 1) Kallisto samples can be matched to metadata based on the names of the samples in the metadata, and 2) if the two can be merged together in a single data frame\n",
    "\n",
    "class ColumnIdentification(BaseModel):\n",
    "    likely_sample_column: str = Field(..., description=\"The column name most likely to contain sample identifiers\")\n",
    "    confidence: float = Field(..., description=\"Confidence score for the column identification (0-1)\")\n",
    "    reasoning: str = Field(..., description=\"Explanation for why this column was chosen\")\n",
    "\n",
    "class SampleMatch(BaseModel):\n",
    "    metadata_sample: str = Field(..., description=\"The sample name from the metadata\")\n",
    "    file_name: str = Field(..., description=\"The matched file name\")\n",
    "    confidence: float = Field(..., description=\"Confidence score of the match (0-1)\")\n",
    "\n",
    "class MatchResult(BaseModel):\n",
    "    column_identification: ColumnIdentification = Field(..., description=\"Identification of the sample name column\")\n",
    "    matches: List[SampleMatch] = Field(..., description=\"List of matched samples and file names\")\n",
    "    matching_logic: str = Field(..., description=\"Explanation of the logic used to match samples to file names\")\n",
    "\n",
    "def read_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def create_prompt(metadata_df, file_names):\n",
    "    prompt = f\"\"\"Analyze the following metadata and list of file names:\n",
    "\n",
    "Metadata columns:\n",
    "{metadata_df.columns.tolist()}\n",
    "\n",
    "Metadata:\n",
    "{metadata_df.to_string()}\n",
    "\n",
    "File names:\n",
    "{file_names}\n",
    "\n",
    "Tasks:\n",
    "1. Identify the column most likely to contain sample identifiers. Provide the column name, a confidence score, and your reasoning.\n",
    "2. Match each sample from the identified column to the most likely corresponding file name. Consider variations in capitalization, spaces, dashes, and potential typos.\n",
    "3. Explain the logic you used to match samples to file names.\n",
    "\n",
    "Provide your analysis in a structured format.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def get_openai_response(prompt, openai_api_key):\n",
    "    client = instructor.patch(OpenAI(\n",
    "    api_key=openai_api_key))\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_model=MatchResult\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def update_metadata(metadata_df, match_result):\n",
    "    sample_column = match_result.column_identification.likely_sample_column\n",
    "    file_name_dict = {match.metadata_sample: match.file_name for match in match_result.matches}\n",
    "    metadata_df['file_name'] = metadata_df[sample_column].map(file_name_dict)\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ff40434-4b29-4d85-9749-f25219082f3d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likely sample name column: Sample Name\n",
      "Confidence: 1.0\n",
      "Reasoning: The 'Sample Name' column contains names that are structured similarly to the file names, with consistent patterns allowing for clear correspondence.\n",
      "\n",
      "Matching logic:\n",
      "The matching was performed by normalizing both sample identifiers and file names to a consistent format: converting underscores to dashes, stripping out spaces, and ensuring uniform casing. The resulting normalized names were then compared for exact matches.\n",
      "\n",
      "Updated Metadata:\n",
      "                          Sample Name Transfection      Genotype Cell type   \\\n",
      "0      KOLF2_SETBP1_VUS2_A21_10_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "1       KOLF2_SETBP1_VUS2_A21_7_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "2     KOLF2_SETBP1_VUS2_A21_10_day 24            A   VUS2 HDR/WT        NPC   \n",
      "3      KOLF2_SETBP1_VUS2_A21_7_day 24            A   VUS2 HDR/WT        NPC   \n",
      "4      KOLF2_SETBP1_VUS2_B1_4.1_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "5      KOLF2_SETBP1_VUS2_B1_4.2_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "6     KOLF2_SETBP1_VUS2_B1_4.1_day 24            B   VUS2 HDR/WT        NPC   \n",
      "7     KOLF2_SETBP1_VUS2_B1_4.2_day 24            B   VUS2 HDR/WT        NPC   \n",
      "8    KOLF2_SETBP1_VUS2_C12.1_WT_day 0            C         WT/WT       iPSC   \n",
      "9    KOLF2_SETBP1_VUS2_C12.2_WT_day 0            C         WT/WT       iPSC   \n",
      "10   KOLF2_SETBP1_VUS2_C12.3_WT_day 0            C         WT/WT       iPSC   \n",
      "11  KOLF2_SETBP1_VUS2_C12.1_WT_day 24            C         WT/WT        NPC   \n",
      "12  KOLF2_SETBP1_VUS2_C12.2_WT_day 24            C         WT/WT        NPC   \n",
      "13  KOLF2_SETBP1_VUS2_C12.3_WT_day 24            C         WT/WT        NPC   \n",
      "14    KOLF2_SETBP1_PATH1_4.6_WT_day 0            D         WT/WT       iPSC   \n",
      "15    KOLF2_SETBP1_PATH1_4.7_WT_day 0            D         WT/WT       iPSC   \n",
      "16   KOLF2_SETBP1_PATH1_4.6_WT_day 24            D         WT/WT        NPC   \n",
      "17   KOLF2_SETBP1_PATH1_4.7_WT_day 24            D         WT/WT        NPC   \n",
      "18       KOLF2_SETBP1_PATH2_3.2_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "19    KOLF2_SETBP1_PATH2_3.3_WT_day 0            E         WT/WT       iPSC   \n",
      "20       KOLF2_SETBP1_PATH2_3.4_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "21       KOLF2_SETBP1_PATH2_3.6_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "22      KOLF2_SETBP1_PATH2_3.2_day 24            E  PATH2 HDR/WT        NPC   \n",
      "23   KOLF2_SETBP1_PATH2_3.3_WT_day 24            E         WT/WT        NPC   \n",
      "24      KOLF2_SETBP1_PATH2_3.4_day 24            E  PATH2 HDR/WT        NPC   \n",
      "25      KOLF2_SETBP1_PATH2_3.6_day 24            E  PATH2 HDR/WT        NPC   \n",
      "26     KOLF2_SETBP1_PATH3_15.10_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "27    KOLF2_SETBP1_PATH3_15.7.1_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "28    KOLF2_SETBP1_PATH3_15.7.2_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "29    KOLF2_SETBP1_PATH3_15.10_day 24            F  PATH3 HDR/WT        NPC   \n",
      "30   KOLF2_SETBP1_PATH3_15.7.1_day 24            F  PATH3 HDR/WT        NPC   \n",
      "31   KOLF2_SETBP1_PATH3_15.7.2_day 24            F  PATH3 HDR/WT        NPC   \n",
      "\n",
      "    Neural differentiation set                                       file_name  \n",
      "0                            2     KOLF2-SETBP1-VUS2-A21-10-day-0/abundance.h5  \n",
      "1                            1      KOLF2-SETBP1-VUS2-A21-7-day-0/abundance.h5  \n",
      "2                            2    KOLF2-SETBP1-VUS2-A21-10-day-24/abundance.h5  \n",
      "3                            1     KOLF2-SETBP1-VUS2-A21-7-day-24/abundance.h5  \n",
      "4                            1     KOLF2-SETBP1-VUS2-B1-4-1-day-0/abundance.h5  \n",
      "5                            2     KOLF2-SETBP1-VUS2-B1-4-2-day-0/abundance.h5  \n",
      "6                            1    KOLF2-SETBP1-VUS2-B1-4-1-day-24/abundance.h5  \n",
      "7                            2    KOLF2-SETBP1-VUS2-B1-4-2-day-24/abundance.h5  \n",
      "8                            1   KOLF2-SETBP1-VUS2-C12-1-WT-day-0/abundance.h5  \n",
      "9                            1   KOLF2-SETBP1-VUS2-C12-2-WT-day-0/abundance.h5  \n",
      "10                           2   KOLF2-SETBP1-VUS2-C12-3-WT-day-0/abundance.h5  \n",
      "11                           1  KOLF2-SETBP1-VUS2-C12-1-WT-day-24/abundance.h5  \n",
      "12                           1  KOLF2-SETBP1-VUS2-C12-2-WT-day-24/abundance.h5  \n",
      "13                           2  KOLF2-SETBP1-VUS2-C12-3-WT-day-24/abundance.h5  \n",
      "14                           1    KOLF2-SETBP1-PATH1-4-6-WT-day-0/abundance.h5  \n",
      "15                           2    KOLF2-SETBP1-PATH1-4-7-WT-day-0/abundance.h5  \n",
      "16                           1   KOLF2-SETBP1-PATH1-4-6-WT-day-24/abundance.h5  \n",
      "17                           2   KOLF2-SETBP1-PATH1-4-7-WT-day-24/abundance.h5  \n",
      "18                           1       KOLF2-SETBP1-PATH2-3-2-day-0/abundance.h5  \n",
      "19                           2    KOLF2-SETBP1-PATH2-3-3-WT-day-0/abundance.h5  \n",
      "20                           1       KOLF2-SETBP1-PATH2-3-4-day-0/abundance.h5  \n",
      "21                           2       KOLF2-SETBP1-PATH2-3-6-day-0/abundance.h5  \n",
      "22                           1      KOLF2-SETBP1-PATH2-3-2-day-24/abundance.h5  \n",
      "23                           2   KOLF2-SETBP1-PATH2-3-3-WT-day-24/abundance.h5  \n",
      "24                           1      KOLF2-SETBP1-PATH2-3-4-day-24/abundance.h5  \n",
      "25                           2      KOLF2-SETBP1-PATH2-3-6-day-24/abundance.h5  \n",
      "26                           2     KOLF2-SETBP1-PATH3-15-10-day-0/abundance.h5  \n",
      "27                           1    KOLF2-SETBP1-PATH3-15-7-1-day-0/abundance.h5  \n",
      "28                           2    KOLF2-SETBP1-PATH3-15-7-2-day-0/abundance.h5  \n",
      "29                           2    KOLF2-SETBP1-PATH3-15-10-day-24/abundance.h5  \n",
      "30                           1   KOLF2-SETBP1-PATH3-15-7-1-day-24/abundance.h5  \n",
      "31                           2   KOLF2-SETBP1-PATH3-15-7-2-day-24/abundance.h5  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    api_key = openai_api_key\n",
    "\n",
    "    # Path to your metadata CSV file\n",
    "    metadata_file_path = \"../InputData/SETBP1_Tests/SETBP1_RNAseq_samples.csv\"\n",
    "    \n",
    "    # Read the metadata CSV file\n",
    "    metadata_df = read_csv(metadata_file_path)\n",
    "    \n",
    "    # List of sample file names (you would typically read this from a directory or another source)\n",
    "    with open(\"../InputData/SETBP1_Tests/abundance_files.txt\", 'r') as file:\n",
    "        file_names = file.read()\n",
    "    \n",
    "    # Create a prompt with the metadata and file names\n",
    "    prompt = create_prompt(metadata_df, file_names)\n",
    "    \n",
    "    # Get the response from OpenAI\n",
    "    response = get_openai_response(prompt, openai_api_key)\n",
    "    # Print the identified sample name column and reasoning\n",
    "    print(f\"Likely sample name column: {response.column_identification.likely_sample_column}\")\n",
    "    print(f\"Confidence: {response.column_identification.confidence}\")\n",
    "    print(f\"Reasoning: {response.column_identification.reasoning}\\n\")\n",
    "    \n",
    "    # Print the matching logic\n",
    "    print(\"Matching logic:\")\n",
    "    print(response.matching_logic)\n",
    "    print()\n",
    "    \n",
    "    # Update the metadata DataFrame with matched file names\n",
    "    updated_metadata = update_metadata(metadata_df, response)\n",
    "    \n",
    "    # Print the updated metadata\n",
    "    print(\"Updated Metadata:\")\n",
    "    print(updated_metadata)\n",
    "    \n",
    "    # Optionally, save the updated metadata to a new CSV file\n",
    "    updated_metadata.to_csv(\"../results/2024_07_31_AutomatedDataProcessing/Clean_MetadataSampleMatching.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f8b5a8b-37e0-4dd3-ac7b-0536f5ca6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat above but with a more error-filled CSV. This will also be where I refine my prompt.\n",
    "\n",
    "class ColumnIdentification(BaseModel):\n",
    "    likely_sample_column: str = Field(..., description=\"The column name most likely to contain sample identifiers\")\n",
    "    confidence: float = Field(..., description=\"Confidence score for the column identification (0-1)\")\n",
    "    reasoning: str = Field(..., description=\"Explanation for why this column was chosen\")\n",
    "\n",
    "class SampleMatch(BaseModel):\n",
    "    metadata_sample: str = Field(..., description=\"The sample name from the metadata\")\n",
    "    file_name: str = Field(..., description=\"The matched file name\")\n",
    "    confidence: float = Field(..., description=\"Confidence score of the match (0-1)\")\n",
    "\n",
    "class MatchResult(BaseModel):\n",
    "    column_identification: ColumnIdentification = Field(..., description=\"Identification of the sample name column\")\n",
    "    matches: List[SampleMatch] = Field(..., description=\"List of matched samples and file names\")\n",
    "    matching_logic: str = Field(..., description=\"Explanation of the logic used to match samples to file names\")\n",
    "\n",
    "def read_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def get_openai_response(prompt, openai_api_key):\n",
    "    client = instructor.patch(OpenAI(\n",
    "    api_key=openai_api_key))\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_model=MatchResult\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def update_metadata(metadata_df, match_result):\n",
    "    sample_column = match_result.column_identification.likely_sample_column\n",
    "    file_name_dict = {match.metadata_sample: match.file_name for match in match_result.matches}\n",
    "    file_match_score = {match.metadata_sample: match.confidence for match in match_result.matches}\n",
    "    metadata_df['file_name'] = metadata_df[sample_column].map(file_name_dict)\n",
    "    metadata_df['match_confidence'] = metadata_df[sample_column].map(file_match_score)\n",
    "    return metadata_df\n",
    "\n",
    "def process_metadata_and_files(metadata_file_path, file_names_path, openai_api_key):\n",
    "    # Read the metadata CSV file\n",
    "    metadata_df = read_csv(metadata_file_path)\n",
    "    \n",
    "    # Read the list of sample file names. For the moment I just manually specified the input text files, but this will need to change later.\n",
    "    with open(file_names_path, 'r') as file:\n",
    "        file_names = file.read().splitlines()\n",
    "    \n",
    "    # Create a prompt with the metadata and file names\n",
    "    prompt = create_prompt(metadata_df, file_names)\n",
    "    \n",
    "    # Get the response from OpenAI\n",
    "    response = get_openai_response(prompt, openai_api_key)\n",
    "    \n",
    "    if isinstance(response, str):\n",
    "        print(response)\n",
    "        return\n",
    "    \n",
    "    # Print the identified sample name column and reasoning\n",
    "    print(f\"Likely sample name column: {response.column_identification.likely_sample_column}\")\n",
    "    print(f\"Confidence: {response.column_identification.confidence}\")\n",
    "    print(f\"Reasoning: {response.column_identification.reasoning}\\n\")\n",
    "    \n",
    "    # Print the matching logic\n",
    "    print(\"Matching logic:\")\n",
    "    print(response.matching_logic)\n",
    "    print()\n",
    "    \n",
    "    # Update the metadata DataFrame with matched file names\n",
    "    updated_metadata = update_metadata(metadata_df, response)\n",
    "    \n",
    "    # Print the updated metadata\n",
    "    return(updated_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "556ef456-657b-476f-b86c-965b69c301d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likely sample name column: Sample Name\n",
      "Confidence: 0.95\n",
      "Reasoning: The metadata column 'Sample Name' contains identifiers for the samples, which typically aligns with the format of file names that include sample identifiers and respective conditions.\n",
      "\n",
      "Matching logic:\n",
      "I matched the file names to the metadata samples by normalizing both data sets. I transformed both the sample names in the metadata and the file names to a consistent format by removing punctuations, standardizing case, and replacing spaces with hyphens. Each file name was then iteratively checked for substring matches against the cleaned sample names using a confidence scoring system based on the degree of exact match and logical adjustments for minor discrepancies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    api_key = openai_api_key\n",
    "\n",
    "    # Path to your metadata CSV file\n",
    "    metadata_file_path = \"../InputData/SETBP1_Tests/SETBP1_RNAseq_samples_errors.csv\"\n",
    "    \n",
    "    # Path to your file names list\n",
    "    file_names_path = \"../InputData/SETBP1_Tests/abundance_files.txt\"\n",
    "    \n",
    "    # Process the metadata and files\n",
    "    updated_metadata = process_metadata_and_files(metadata_file_path, file_names_path, api_key)\n",
    "\n",
    "updated_metadata.to_csv(\"../results/2024_07_31_AutomatedDataProcessing/Errors_MetadataSampleMatching.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d0dba03-3a9a-4c18-bcfd-1a741692391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.to_string of                           Sample Name Transfection      Genotype Cell type   \\\n",
      "0      KOLF2_SETBP1_VUS2_A21_10_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "1      KOLF2_SETBP1_ VUS2_A21_7_day 0            A   VUS2 HDR/WT       iPSC   \n",
      "2   KOLF2_SETBP1_VUS2_A21_10_day 24.             A          VUS@        NPC   \n",
      "3      KOLF2_SETBP1_VUS2_A21_7_day 24            A   VUS2 HDR/WT        NPC   \n",
      "4      KOLF2_SETBP1_VUS2_B1_4.1_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "5      KOLF2_SETBP1_VUS2_B1_4.2_day 0            B   VUS2 HDR/WT       iPSC   \n",
      "6     KOLF2_SETBP1_VUS2_B1_4.1_day 24            B   vus2 HDR/WT        NPC   \n",
      "7     KOLF2_SETBP1_VUS2_B1_4.2_day 24            B   VUS2 HDR/WT        NPC   \n",
      "8    KOLF2_SETBP1_VUS2_C12.1_WT_day 0            C         WT/WT       iPSC   \n",
      "9    KOLF2_SETBP1_VUS2_C12.2_WT_day 0            C         WT/WT       iPSC   \n",
      "10   KOLF2_SETBP1_VUS2_C12-3_WT_day 0            C         WT/WT       iPSC   \n",
      "11  KOLF2_SETBP1_VUS2_C12.1_WT_day 24            C         WT/WT        NPC   \n",
      "12  KOLF2_SETBP1_VUS2_C12.2_WT_day 24            C         WT/WT        NPC   \n",
      "13  KOLF2_SETBP1_VUS2_C12.3_WT_day 24            C         WT/WT        NPC   \n",
      "14    KOLF2_SETBP1_PATH1_4.6_WT_day 0            D           NaN       iPSC   \n",
      "15    KOLF2_SETBP1_PATH1_4.7_WT_day 0            D         WT/WT       iPSC   \n",
      "16   KOLF2_SETBP1_PATH1_4.6_WT_day 24            D         WT/wt        NaN   \n",
      "17   KOLF2_SETBP1_PATH1_4.7_WT_day 24            D         WT/WT        NaN   \n",
      "18        KOLF2_SETBP1_PATH2_3.2_day0            E  PATH2 HDR/WT       iPSC   \n",
      "19    KOLF2_SETBP1_PATH2_3.3_WT_day 0            E         WT/WT       iPSC   \n",
      "20       KOLF2_SETBP1_PATH2_3.4_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "21       KOLF2_SETBP1_PATH2_3.6_day 0            E  PATH2 HDR/WT       iPSC   \n",
      "22      KOLF2_SETBP1_PATH2_3.2_day 24            E  PATH2 HDR/WT        NPC   \n",
      "23   kolf2_SETBP1_PATH2_3.3_WT_day 24            E         WT/WT        NPC   \n",
      "24      KOLF2_SETBP1_PATH2_3.4_day 24            E  PATH2 HDR/WT        NPC   \n",
      "25      KLOF2_SETBP1_PATH2_3.6_day 24            E  PATH2 HDR/WT        NPC   \n",
      "26     KOLF2_SETBP1_PATH3_15.10_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "27    KOLF2_SETBP1_PATH3_15.7.1_day 0            F         PATH3       iPSC   \n",
      "28    KOLF2_SETPB1_PATH3_15.7.2_day 0            F  PATH3 HDR/WT       iPSC   \n",
      "29    KOLF2_SETBP1_PATH3_15.10_day 24            F  PATH3 HDR/WT        NPC   \n",
      "30   KOLF2_SETBP1_PATH3_15.7.1_day 24            F  PATH3 HDR/WT        NPC   \n",
      "31   KOLF2_SETBP1_PATH3_15.7.2_day 24            F  PATH3 HDR/WT        NPC   \n",
      "\n",
      "    Neural differentiation set  \n",
      "0                            2  \n",
      "1                            1  \n",
      "2                            2  \n",
      "3                            1  \n",
      "4                            1  \n",
      "5                            2  \n",
      "6                            1  \n",
      "7                            2  \n",
      "8                            1  \n",
      "9                            1  \n",
      "10                           2  \n",
      "11                           1  \n",
      "12                           1  \n",
      "13                           2  \n",
      "14                           1  \n",
      "15                           2  \n",
      "16                           1  \n",
      "17                           2  \n",
      "18                           1  \n",
      "19                           2  \n",
      "20                           1  \n",
      "21                           2  \n",
      "22                           1  \n",
      "23                           2  \n",
      "24                           1  \n",
      "25                           2  \n",
      "26                           2  \n",
      "27                           1  \n",
      "28                           2  \n",
      "29                           2  \n",
      "30                           1  \n",
      "31                           2  >\n"
     ]
    }
   ],
   "source": [
    "metadata_df = read_csv(\"../InputData/SETBP1_Tests/SETBP1_RNAseq_samples_errors.csv\")\n",
    "    \n",
    "    # Read the list of sample file names. For the moment I just manually specified the input text files, but this will need to change later.\n",
    "with open(file_names_path, 'r') as file:\n",
    "    file_names = file.read().splitlines()\n",
    "\n",
    "class ColumnIdentification(BaseModel):\n",
    "    likely_sample_column: str = Field(..., description=\"The column name most likely to contain sample identifiers\")\n",
    "    confidence: float = Field(..., description=\"Confidence score for the column identification (0-1)\")\n",
    "    reasoning: str = Field(..., description=\"Explanation for why this column was chosen\")\n",
    "\n",
    "class SampleMatch(BaseModel):\n",
    "    metadata_sample: str = Field(..., description=\"The matched sample name as reported in the metadata\")\n",
    "    file_name: str = Field(..., description=\"The file name\")\n",
    "    confidence: float = Field(..., description=\"Confidence score of the match (0-1)\")\n",
    "\n",
    "class MatchResult(BaseModel):\n",
    "    column_identification: ColumnIdentification = Field(..., description=\"Identification of the sample name column\")\n",
    "    matches: List[SampleMatch] = Field(..., description=\"List of matched samples and file names\")\n",
    "\n",
    "def create_prompt(metadata_df, file_names):\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "## IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert in bioinformatic analyses. You will be provided with a list of files, and a metadata data frame. You are tasked with matching the file names to the existing metadata data frame. \n",
    "\n",
    "Take a deep breath, and carefully follow the steps outlined below to achieve the intended task.\n",
    "\n",
    "## STEPS\n",
    "\n",
    "1. First, identify the column name that is most likely to correspond to sample names. Focus on words such as \"sample name\" or \"ID\" to make this judgement.\n",
    "2. Match ALL file names to rows in the metadata. Keep the following in mind:\n",
    "- Every file name should match to a row in the metadata\n",
    "- There may be errors in the metadata\n",
    "- You should make efforts to identify likely errors, and consider the possibility of a match if the error was corrected\n",
    "- Examples of errors include random spaces, incorrect spellings, inconsistent cases, and random punctuations\n",
    "- Note that you may need to systematically apply some rules to better identify matches\n",
    "- Do not prescriptively follow a rule to find matches; be flexible instead\n",
    "- If a file name does not have a match in the sample metadata, report this as \"No Match\"\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "Provided your analysis in a structured format:\n",
    "1. Provide the column name most likely to correspond to sample names, with a confidence score and reasoning.\n",
    "2. List of EACH file, and the most likely corresponding sample name. Report the sample name EXACTLY as it is in the metadata - do not attempt to correct the metadata value. Similarly, report the file name EXACTLY as given.\n",
    "\n",
    "## INPUT\n",
    "Metadata columns:\n",
    "{metadata_df.columns.tolist()}\n",
    "\n",
    "Metadata:\n",
    "{metadata_df.to_string()}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "    \n",
    "prompt = create_prompt(metadata_df, file_names)\n",
    "\n",
    "def get_openai_response(prompt, openai_api_key):\n",
    "    client = instructor.patch(OpenAI(\n",
    "    api_key=openai_api_key))\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_tokens = 10000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_model=MatchResult\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "response = get_openai_response(prompt, openai_api_key)\n",
    "print(metadata_df.to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c5d82e3-22be-431f-86f3-3f4de0dfba1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_A21_10_day 0', file_name='KOLF2_SETBP1_VUS2_A21_10_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_ VUS2_A21_7_day 0', file_name='KOLF2_SETBP1_ VUS2_A21_7_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_A21_10_day 24.', file_name='KOLF2_SETBP1_VUS2_A21_10_day 24.', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_A21_7_day 24', file_name='KOLF2_SETBP1_VUS2_A21_7_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.1_day 0', file_name='KOLF2_SETBP1_VUS2_B1_4.1_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.2_day 0', file_name='KOLF2_SETBP1_VUS2_B1_4.2_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.1_day 24', file_name='KOLF2_SETBP1_VUS2_B1_4.1_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_B1_4.2_day 24', file_name='KOLF2_SETBP1_VUS2_B1_4.2_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.1_WT_day 0', file_name='KOLF2_SETBP1_VUS2_C12.1_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.2_WT_day 0', file_name='KOLF2_SETBP1_VUS2_C12.2_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12-3_WT_day 0', file_name='KOLF2_SETBP1_VUS2_C12-3_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.1_WT_day 24', file_name='KOLF2_SETBP1_VUS2_C12.1_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.2_WT_day 24', file_name='KOLF2_SETBP1_VUS2_C12.2_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_VUS2_C12.3_WT_day 24', file_name='KOLF2_SETBP1_VUS2_C12.3_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.6_WT_day 0', file_name='KOLF2_SETBP1_PATH1_4.6_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.7_WT_day 0', file_name='KOLF2_SETBP1_PATH1_4.7_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.6_WT_day 24', file_name='KOLF2_SETBP1_PATH1_4.6_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH1_4.7_WT_day 24', file_name='KOLF2_SETBP1_PATH1_4.7_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.2_day0', file_name='KOLF2_SETBP1_PATH2_3.2_day0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.3_WT_day 0', file_name='KOLF2_SETBP1_PATH2_3.3_WT_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.4_day 0', file_name='KOLF2_SETBP1_PATH2_3.4_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.6_day 0', file_name='KOLF2_SETBP1_PATH2_3.6_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.2_day 24', file_name='KOLF2_SETBP1_PATH2_3.2_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.3_WT_day 24', file_name='KOLF2_SETBP1_PATH2_3.3_WT_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH2_3.4_day 24', file_name='KOLF2_SETBP1_PATH2_3.4_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KLOF2_SETBP1_PATH2_3.6_day 24', file_name='KLOF2_SETBP1_PATH2_3.6_day 24', confidence=0.9),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.10_day 0', file_name='KOLF2_SETBP1_PATH3_15.10_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.7.1_day 0', file_name='KOLF2_SETBP1_PATH3_15.7.1_day 0', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETPB1_PATH3_15.7.2_day 0', file_name='No Match', confidence=0.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.10_day 24', file_name='KOLF2_SETBP1_PATH3_15.10_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.7.1_day 24', file_name='KOLF2_SETBP1_PATH3_15.7.1_day 24', confidence=1.0),\n",
       " SampleMatch(metadata_sample='KOLF2_SETBP1_PATH3_15.7.2_day 24', file_name='KOLF2_SETBP1_PATH3_15.7.2_day 24', confidence=1.0)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "755fbffc-9354-4b67-9bc8-ce8a128d0337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Output\n",
      "\n",
      "1. **Column Names and Descriptions**\n",
      "\n",
      "   - **title**: Identifier for the sample entry.\n",
      "   - **geo_accession**: Unique identifier for accessing the data in the GEO database.\n",
      "   - **status**: Status of the sample submissions (Public, etc.).\n",
      "   - **submission_date**: Date the data was submitted to GEO.\n",
      "   - **last_update_date**: Date when the sample was last updated.\n",
      "   - **type**: Type of the sequencing project (SRA, etc.).\n",
      "   - **channel_count**: Number of channels used in the experiment.\n",
      "   - **source_name_ch1**: The source or tissue type for channel 1.\n",
      "   - **organism_ch1**: Organism from which the sample is derived (e.g., Homo sapiens).\n",
      "   - **characteristics_ch1**: Characteristics like tissue of origin.\n",
      "   - **characteristics_ch1.1**: Additional characteristics such as patient number.\n",
      "   - **characteristics_ch1.2**: Additional characteristics like the disease associated with the sample.\n",
      "   - **characteristics_ch1.3**: Region of interest for the analysis.\n",
      "   - **characteristics_ch1.4**: Nuclei count for the region of interest.\n",
      "   - **characteristics_ch1.5**: Surface area of the region of interest.\n",
      "   - **molecule_ch1**: Type of molecule analyzed (e.g., total RNA).\n",
      "   - **extract_protocol_ch1**: Protocol used for extraction of RNA.\n",
      "   - **data_processing**: Description of how the data was processed.\n",
      "   - **platform_id**: Identifier for the sequencing platform used.\n",
      "   - **contact_name**: Name of the researcher/contact person.\n",
      "   - **contact_email**: Email address of the contact.\n",
      "   - **contact_department**: Department of the contact.\n",
      "   - **contact_institute**: Institution associated with the research.\n",
      "   - **contact_address**: Address of the contact institute.\n",
      "   - **contact_city**: City of the contact institute.\n",
      "   - **contact_state**: State of the contact institute.\n",
      "   - **contact_zip/postal_code**: Zip or postal code for the contact address.\n",
      "   - **contact_country**: Country associated with the contact.\n",
      "   - **data_row_count**: Number of data rows available.\n",
      "   - **instrument_model**: Model of the instrument used for sequencing.\n",
      "   - **library_selection**: Selection method for the library.\n",
      "   - **library_source**: Source of the library (e.g. transcriptomic).\n",
      "   - **library_strategy**: Strategy employed in the library preparation.\n",
      "   - **relation**: Relation to bio-sample or similar identifiers.\n",
      "   - **supplementary_file_1**: Links to supplementary files related to the data.\n",
      "   - **disease:ch1**: Disease category.\n",
      "   - **patient:ch1**: Patient identifier.\n",
      "   - **region of_interest_(roi):ch1**: Region of interest from the sample.\n",
      "   - **roi nuclei_count:ch1**: Total count of nuclei in the region of interest.\n",
      "   - **roi surface_area:ch1**: Surface area of the region of interest.\n",
      "   - **tissue:ch1**: Type of tissue analyzed.\n",
      "\n",
      "2. **Interesting Comparisons for Analysis**\n",
      "\n",
      "   - **Comparison by Disease Status (e.g., Healthy Control vs. Disease)**\n",
      "     - This comparison allows research into gene expression patterns that distinguish healthy tissues from those affected by diseases, leading to insights into disease mechanisms and potential biomarkers.\n",
      "\n",
      "   - **Comparison by Region of Interest in Tissue (e.g., Epidermis, Stroma)**\n",
      "     - By comparing different regions within the same type of tissue, researchers can identify region-specific gene expression profiles, revealing insights into how different microenvironments influence cellular behavior.\n",
      "\n",
      "   - **Comparison of Nuclei Count Impact (e.g., High vs. Low Nuclei Count)**\n",
      "     - Investigating how the number of nuclei correlates with gene expression levels could provide insights into cellular proliferation, tissue organization, and potential pathological conditions.\n",
      "\n",
      "   - **Comparison between Patients with Different Disease Types (e.g., Cysts vs. SCC)**\n",
      "     - This would help elucidate the molecular differences between distinct pathologies, advancing the understanding of disease etiology and progression.\n",
      "\n",
      "   - **Comparison of Different Biopsied Features (e.g., Plasma Cell Rich vs. Poor)**\n",
      "     - Analyzing samples with varied plasma cell densities could reveal important functional differences related to immune response and tissue health, offering potential therapeutic targets.\n",
      "\n",
      "3. **Justifications for Comparisons**\n",
      "\n",
      "   - **Comparison by Disease Status**: This analysis is pivotal for identifying distinct gene signatures that can serve as diagnostic markers for diseases. Understanding these signatures can enhance the precision of targeted therapies and improve patient outcomes.\n",
      "\n",
      "   - **Comparison by Region of Interest**: Regions within tissues can have vastly different functional roles, and studying their unique expression profiles can provide critical insights into tissue-specific functions and the impact of local environments on cell fate.\n",
      "\n",
      "   - **Comparison of Nuclei Count Impact**: A clear understanding of how nuclei count can influence gene expression provides a basis for assessing tissue health and pathology. This can aid in identifying critical thresholds for interventions in clinical settings.\n",
      "\n",
      "   - **Comparison between Patients with Different Disease Types**: Such comparative analyses can significantly advance our understanding of disease mechanisms and aid in identifying specific interventions tailored to the molecular profile of a patient's specific condition.\n",
      "\n",
      "   - **Comparison of Different Biopsied Features**: Understanding how differences in cellular composition impact functionality can highlight potential roles of immune cells in skin pathology, guiding future therapeutic strategies in conditions driven by immune responses.\n"
     ]
    }
   ],
   "source": [
    "# Testing for identification of interesting comparisons \n",
    "\n",
    "meta = pd.read_csv(\"../InputData/GSE273227_SkinTests/meta.csv\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "## IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert in bioinformatic analyses. You will be provided with a metadata sheet, and are tasked with identifying contrasts that could be interesting in the metadata, with the intention of analysing these in a edgeR/limma based pipeline.\n",
    "Take a deep breath, and carefully follow the steps outlined below to achieve the intended task.\n",
    "\n",
    "## STEPS\n",
    "\n",
    "1. Carefully consider each column, inferring what each column means from its name, and also the values in the column. \n",
    "2. Determine columns that appear to contain data that would be scientifically and biologically interesting to compare within the column.\n",
    "- Only include comparisons that can be easily analysed in a limma/edgeR based pipeline\n",
    "- Only include comparisons that would be valuable to the literature generally, and not just within the dataset\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "1. State all column names EXACTLY, and also include a brief 1 sentence description of what each column contains\n",
    "2. State 5 comparisons that would be interesting to analyse in a limma/edgeR-based pipeline. \n",
    "3. For each comparison, include the EXACT column name that contains the relevant values for the comparison. Additionally, justify why the comparison would be interesting using up to 3 sentences\n",
    "\n",
    "\n",
    "## INPUT\n",
    "\n",
    "Metadata:\n",
    "{meta.to_string()}\n",
    "\"\"\"\n",
    "client = OpenAI(\n",
    "  api_key=openai_api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens = 6000\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0360f5-f8dd-464d-b592-8e33c8f55e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Poetry)",
   "language": "python",
   "name": "poetry-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
