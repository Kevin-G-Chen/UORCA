{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4410b7ed-cce0-443e-b3b8-c33c611bdb97",
   "metadata": {},
   "source": [
    "This notebook is intended to develop a framework for extracting data from NCBI GEO datasets.\n",
    "\n",
    "There are approaches I can take. I initially had wanted to extract the FASTQ files - however, I am now considering whether simply getting the expression matrices is sufficient.\n",
    "- this is reliant on all datasets having expression matrices. I'm not sure this is a safe assumption. \n",
    "- In my initial test cases, I was able to get expression matrices from either supp files or \"main\" (?) files. It is trivial to access either of these using GEOquery in R. However, automating this might be trickier.\n",
    "\n",
    "It feels a possible approach is:\n",
    "- Extract main data - \"is there a counts matrix?\"\n",
    "- Extract supplementary data - \"is there a counts matrix?\"\n",
    "- Extract metadata\n",
    "\n",
    "The obvious question in this case is \"will there always be a counts matrix,\" to which the answer is no. My train of thought is then to process FASTQ files.\n",
    "- As it happens, if I set up a pipeline to just do the analysis for FASTQ files, it would greatly simplify the insights that researchers can extract when getting new data? \n",
    "- Alternatively I could say \"start with a counts matrix,\" that could be a viable approach.\n",
    "\n",
    "Ah yeah - I will most likely be using R scripts to extract data. GEOquery worked well in my interactive test cases. \n",
    "\n",
    "Therefore, this notebook will be a Python script (where I call upon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8498eb7-4f14-429c-81c9-aa74c3390c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import instructor # I'm not sure if this will actually be needed...\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b383a139-6f9b-4926-9305-7ef604408c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pica pica\n"
     ]
    }
   ],
   "source": [
    "load_dotenv('../.env')\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Test OpenAI API...\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=openai_api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you state the name of a real species of bird? Only reply with the species name.\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "605e4d07-3b52-4f55-9b05-e7f8186dfa53",
   "metadata": {},
   "source": [
    "Can't say I've heard of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448ec3f-e21f-4095-8990-58682dc9b48d",
   "metadata": {},
   "source": [
    "# Plan of action\n",
    "\n",
    "- Create R scripts that extract a) main files, b) supplementary files, c) metadata. Separately.\n",
    "- I suspect I would want to download and output the structure of these files... I had a passing thought that just looking at the name of the file could be sufficient (e.g. save time/space associated with downloading a file), but given the possible heterogeneity of data in GEO, I think it would be beneficial to download the actual data and visualise the output\n",
    "- After seeing the output, I could ask the LLM \"is this a counts matrix...\"\n",
    "- But I'm also aware that some (all probably...) files come as zipped, so I would need to unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d42f2-a272-4cbe-8400-40339ce519b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the path to the R script\n",
    "r_script_path = \"./RScript_GetGEOData.r\"  # Ensure the path is correct and script is executable\n",
    "\n",
    "# Define the GEO accession you want to use\n",
    "geo_accession = \"GSE3494\"  # Replace with the actual GEO accession number\n",
    "\n",
    "# Construct the command to run the R script with the GEO accession as an argument\n",
    "command = [\"Rscript\", r_script_path, \"-g\", geo_accession]\n",
    "\n",
    "# Call the R script using subprocess\n",
    "try:\n",
    "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "    print(\"R script output:\")\n",
    "    print(result.stdout)  # This will print the standard output from the R script\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Error running R script:\")\n",
    "    print(e.stderr)  # This will print any error messages from the R script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fb18c-85a0-453d-9f81-6f6557d21a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Poetry)",
   "language": "python",
   "name": "poetry-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
