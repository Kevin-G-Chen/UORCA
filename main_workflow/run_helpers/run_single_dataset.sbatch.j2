#!/usr/bin/env bash
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=16G
#SBATCH --partition=tki_agpdev
#SBATCH --constraint="icx"
#SBATCH -t 0-6:00
#SBATCH -o {{ logs_dir }}/run_{{ accession }}.out
#SBATCH -e {{ logs_dir }}/run_{{ accession }}.err

module load apptainer

TEMP_DIR=$(pwd)/tmp_apptainer_{{ accession }}
mkdir -p ${TEMP_DIR}

# Path to your .sif
SIF=/data/tki_agpdev/kevin/phd/aim1/UORCA/scratch/container_testing/uorca_0.1.0.sif

echo "Current time: $(date)"
echo "Running with parallelized Kallisto quantification"
echo "CPUs available: $SLURM_CPUS_PER_TASK"
echo "Using temporary directory: ${TEMP_DIR}"

# Bind-mounts:
#  - your repo → /workspace
#  - the host's output directory → /UORCA_results in the container
BIND="-B {{ project_root }}:/workspace \
      -B {{ output_dir }}:/UORCA_results \
      -B ${TEMP_DIR}:/tmp"

echo "[$(date)] Starting agentic workflow via Apptainer for {{ accession }}"

# Run the container with additional options for temporary directories
apptainer exec \
  $BIND \
  --tmpdir=${TEMP_DIR} \
  --cleanenv \
  $SIF \
  bash -lc "\
    cd /workspace && \
    uv run ./main_workflow/master.py \
      --accession {{ accession }} \
      --output_dir /UORCA_results \
      --resource_dir {{ resource_dir }} \
      {% if cleanup %}--cleanup{% endif %}
  "

echo "[$(date)] Workflow complete for {{ accession }}."

# Clean up temporary directory
rm -rf ${TEMP_DIR}

# Update job status to completed
# Note: Script files are cleaned up immediately after job submission
STATUS_DIR="{{ output_dir }}/job_status"
STATUS_FILE="$STATUS_DIR/{{ accession }}_status.json"
if [ -f "$STATUS_FILE" ]; then
    python3 -c "
import json
import os
from datetime import datetime

status_file = '$STATUS_FILE'
if os.path.exists(status_file):
    with open(status_file, 'r') as f:
        status = json.load(f)
    status['state'] = 'completed'
    status['completed_time'] = datetime.now().isoformat()
    with open(status_file, 'w') as f:
        json.dump(status, f, indent=2)
"
fi
