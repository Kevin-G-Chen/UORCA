{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7a1dbc-c000-47fd-aa85-b8d941549284",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook will contain experimentation (and hopefully the final implementation) of me using LLMs to analyse the Kallisto quantification data.\n",
    "\n",
    "The ideal final outcome is a workflow where I can take in my Kallisto quantification files and perform DEG analysis. However, the exploratory steps that I'd be interested in:\n",
    "- How well does the LLM produce a working R (I can more comfortably work with R) pipeline?\n",
    "- How well does it handle inputs/outputs?\n",
    "- How well will it handle the METADATA?\n",
    "- How much guidance do I need to give? e.g. with the libraries that are available (in theory, I'd like this to be a \"step\" that the LLM is smart enough to know to implement). I don't want to have the LLM install new packages, that feels like a security risk.\n",
    "\n",
    "Other notes:\n",
    "- For the moment, I'll have the LLM use the \"LLM Playground\" directory to save its outputs\n",
    "- In my head, this \"workflow\" will be \"hi, here's what I want, do some steps to achieve this\" - a bit like the worked example of solving an equation\n",
    "- I also need to integrate this with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c1db7285-b40e-48aa-b3e5-94a745101423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "import openai # I need this and above\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Literal\n",
    "import subprocess\n",
    "import glob\n",
    "import asyncio\n",
    "import json\n",
    "import base64 # image interpretation\n",
    "import requests # image interpretation\n",
    "import shlex # suggested for command-line strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "be251aa2-f5c1-4010-bd26-87a411ad147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a step-by-step guide on how to import Kallisto's `abundance.tsv` files into R and then identify differentially expressed genes (DEGs). We'll use the `tximport`, `DESeq2`, and `ggplot2` packages to facilitate this process. \n",
      "\n",
      "### Step 1: Set up your environment\n",
      "\n",
      "First, make sure you have the required packages installed. You can install them using the following command (if you haven't done so already):\n",
      "\n",
      "```R\n",
      "install.packages(\"BiocManager\")\n",
      "BiocManager::install(c(\"DESeq2\", \"tximport\", \"ggplot2\"))\n",
      "```\n",
      "\n",
      "### Step 2: Load the libraries\n",
      "\n",
      "Now, load the necessary libraries:\n",
      "\n",
      "```R\n",
      "library(DESeq2)\n",
      "library(tximport)\n",
      "library(ggplot2)\n",
      "```\n",
      "\n",
      "### Step 3: Import Kallisto abundance files\n",
      "\n",
      "Assuming you have multiple `abundance.tsv` files from Kallisto, you'll typically have a directory where these files are stored. Each file corresponds to a sample. You'll need to create a data frame with the sample information and the file paths, and then use `tximport` to read the data.\n",
      "\n",
      "Here’s an example code:\n",
      "\n",
      "```R\n",
      "# Set the working directory to where your abundance.tsv files are located\n",
      "setwd(\"/path/to/your/kallisto_output\")\n",
      "\n",
      "# List files and filter for abundance.tsv\n",
      "abundance_files <- list.files(pattern = \"abundance.tsv$\", full.names = TRUE)\n",
      "\n",
      "# Create a data frame with sample names and their corresponding file paths\n",
      "sample_names <- gsub(\"/path/to/your/kallisto_output/(.+)/abundance.tsv\", \"\\\\1\", abundance_files)\n",
      "sample_data <- data.frame(sample=sample_names, files=abundance_files)\n",
      "\n",
      "# Check the sample data\n",
      "print(sample_data)\n",
      "\n",
      "# Load your sample information (this should include conditions or groups)\n",
      "# Here we assume you have a data frame with two columns: Sample and Condition\n",
      "# For example:\n",
      "# samples <- data.frame(sample = sample_names, condition = c(\"control\", \"treatment\", ...))\n",
      "\n",
      "# Load tximport\n",
      "txi <- tximport(sample_data$files, type = \"kallisto\", txIn = FALSE, txOut = FALSE)\n",
      "\n",
      "# Check the imported data\n",
      "head(txi$counts)\n",
      "```\n",
      "\n",
      "### Step 4: Create a DESeq2 dataset object\n",
      "\n",
      "You'll now convert the imported data into a DESeq2 dataset:\n",
      "\n",
      "```R\n",
      "# Create DESeq2 dataset\n",
      "dds <- DESeqDataSetFromTximport(txi, colData = samples, design = ~ condition)\n",
      "\n",
      "# Check the DESeq2 object\n",
      "dds\n",
      "```\n",
      "\n",
      "### Step 5: Run the differential expression analysis\n",
      "\n",
      "Next, you perform the differential expression analysis:\n",
      "\n",
      "```R\n",
      "# Run the DESeq function\n",
      "dds <- DESeq(dds)\n",
      "\n",
      "# Retrieve results\n",
      "results <- results(dds)\n",
      "\n",
      "# View the top results\n",
      "head(results[order(results$padj), ])\n",
      "```\n",
      "\n",
      "### Step 6: Visualize the results\n",
      "\n",
      "Finally, you can visualize the results using a volcano plot or a PCA plot:\n",
      "\n",
      "```R\n",
      "# Volcano plot\n",
      "ggplot(as.data.frame(results), aes(x = log2FoldChange, y = -log10(padj))) +\n",
      "  geom_point() +\n",
      "  theme_minimal() +\n",
      "  labs(title = \"Volcano plot\", x = \"log2 Fold Change\", y = \"-log10 adjusted p-value\")\n",
      "\n",
      "# PCA plot\n",
      "rlog_counts <- rlog(dds)\n",
      "plotPCA(rlog_counts, intgroup = \"condition\")\n",
      "```\n",
      "\n",
      "### Important Notes:\n",
      "\n",
      "1. **Sample Metadata**: Ensure your `samples` data frame correctly maps your samples to their respective experimental conditions. This is crucial for accurate differential expression analysis.\n",
      "\n",
      "2. **Quality Control**: It's often helpful to perform quality control checks (like examining the distribution of counts) and normalization before conducting differential expression analysis.\n",
      "\n",
      "3. **Results Interpretation**: After obtaining results, always interpret the results with caution, considering biological relevance, effect sizes, and the context of your experiment.\n",
      "\n",
      "This code provides a basic pipeline for identifying DEGs using Kallisto `abundance.tsv` files in R. Modify it based on your specific experimental design and requirements!\n"
     ]
    }
   ],
   "source": [
    "# Quick OpenAI API test - note this does not reflect what I intend my end prompt to be, just want to get a quick idea of what I get...\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Test OpenAI API...\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Could you provide code to import abundance.tsv Kallisto files into R and identify DEGs?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9009174d-fe77-44d2-84a5-ab96475b9540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens:  862\n",
      "Prompt tokens:  26\n",
      "Total tokens:  888\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generated tokens: \", chat_completion.usage.completion_tokens)\n",
    "print(f\"Prompt tokens: \", chat_completion.usage.prompt_tokens)\n",
    "print(f\"Total tokens: \", chat_completion.usage.total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c4dc9-82aa-48f3-8e99-ddd57ff29aa9",
   "metadata": {},
   "source": [
    "Obviously a one-sentence prompt will get nowhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900cb9b-9164-4614-92b0-41ea4d685793",
   "metadata": {},
   "source": [
    "# Investigating metadata\n",
    "\n",
    "I technically have a separate notebook analysing metadata, but I will more formally do my tests here.\n",
    "\n",
    "The initial test case is to give a metadata CSV and see if the LLM is able to identify what contrasts would be interesting. However, I would eventually probably want a separate function for finding the CSV, and I would later also need to determine what specific outputs I want.\n",
    "\n",
    "At least in the initial conceptualisation stage, I'm not sure where I'll be integrating this (i.e. will this be something I do separately, then feed as input into the LLM), but nonetheless my goal is to develop a prompt that will get meaningful results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ac6e059b-139c-4865-9b9d-308c2d25e937",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>geo_accession</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_date</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>type</th>\n",
       "      <th>channel_count</th>\n",
       "      <th>source_name_ch1</th>\n",
       "      <th>organism_ch1</th>\n",
       "      <th>characteristics_ch1</th>\n",
       "      <th>...</th>\n",
       "      <th>library_selection</th>\n",
       "      <th>library_source</th>\n",
       "      <th>library_strategy</th>\n",
       "      <th>relation</th>\n",
       "      <th>relation.1</th>\n",
       "      <th>supplementary_file_1</th>\n",
       "      <th>cell line:ch1</th>\n",
       "      <th>cell type:ch1</th>\n",
       "      <th>genotype:ch1</th>\n",
       "      <th>treatment:ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUDHL4_LacZ_RGFP0_1</td>\n",
       "      <td>GSM8284502</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479047</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625208</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284502/suppl/GSM8284502_SUDHL4_LacZ_RGFP0_1.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>WT</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUDHL4_LacZ_RGFP0_2</td>\n",
       "      <td>GSM8284503</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479046</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625209</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284503/suppl/GSM8284503_SUDHL4_LacZ_RGFP0_2.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>WT</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUDHL4_LacZ_RGFP5_1</td>\n",
       "      <td>GSM8284504</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479045</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625210</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284504/suppl/GSM8284504_SUDHL4_LacZ_RGFP5_1.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>WT</td>\n",
       "      <td>RGFP966 (5 µM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUDHL4_LacZ_RGFP5_2</td>\n",
       "      <td>GSM8284505</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479044</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625211</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284505/suppl/GSM8284505_SUDHL4_LacZ_RGFP5_2.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>WT</td>\n",
       "      <td>RGFP966 (5 µM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUDHL4_GNASKO2_RGFP0_1</td>\n",
       "      <td>GSM8284506</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479043</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625212</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284506/suppl/GSM8284506_SUDHL4_GNASKO2_RGFP0_1.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUDHL4_GNASKO2_RGFP0_2</td>\n",
       "      <td>GSM8284507</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479042</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625213</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284507/suppl/GSM8284507_SUDHL4_GNASKO2_RGFP0_2.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUDHL4_GNASKO2_RGFP5_1</td>\n",
       "      <td>GSM8284508</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479041</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625214</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284508/suppl/GSM8284508_SUDHL4_GNASKO2_RGFP5_1.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>RGFP966 (5 µM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUDHL4_GNASKO2_RGFP5_2</td>\n",
       "      <td>GSM8284509</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479040</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625215</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284509/suppl/GSM8284509_SUDHL4_GNASKO2_RGFP5_2.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>RGFP966 (5 µM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUDHL4_GNASKO3_RGFP0_1</td>\n",
       "      <td>GSM8284510</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479039</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625216</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284510/suppl/GSM8284510_SUDHL4_GNASKO3_RGFP0_1.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUDHL4_GNASKO3_RGFP0_2</td>\n",
       "      <td>GSM8284511</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479038</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625217</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284511/suppl/GSM8284511_SUDHL4_GNASKO3_RGFP0_2.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SUDHL4_GNASKO3_RGFP5_1</td>\n",
       "      <td>GSM8284512</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479037</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625218</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284512/suppl/GSM8284512_SUDHL4_GNASKO3_RGFP5_1.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>RGFP966 (5 µM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SUDHL4_GNASKO3_RGFP5_2</td>\n",
       "      <td>GSM8284513</td>\n",
       "      <td>Public on Aug 08 2024</td>\n",
       "      <td>May 21 2024</td>\n",
       "      <td>Aug 08 2024</td>\n",
       "      <td>SRA</td>\n",
       "      <td>1</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>cell line: SU-DHL-4</td>\n",
       "      <td>...</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>transcriptomic</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479036</td>\n",
       "      <td>SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625219</td>\n",
       "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284513/suppl/GSM8284513_SUDHL4_GNASKO3_RGFP5_2.txt.gz</td>\n",
       "      <td>SU-DHL-4</td>\n",
       "      <td>diffuse large B-cell lymphoma cells</td>\n",
       "      <td>GNAS knockout</td>\n",
       "      <td>RGFP966 (5 µM)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title geo_accession                 status  \\\n",
       "0      SUDHL4_LacZ_RGFP0_1    GSM8284502  Public on Aug 08 2024   \n",
       "1      SUDHL4_LacZ_RGFP0_2    GSM8284503  Public on Aug 08 2024   \n",
       "2      SUDHL4_LacZ_RGFP5_1    GSM8284504  Public on Aug 08 2024   \n",
       "3      SUDHL4_LacZ_RGFP5_2    GSM8284505  Public on Aug 08 2024   \n",
       "4   SUDHL4_GNASKO2_RGFP0_1    GSM8284506  Public on Aug 08 2024   \n",
       "5   SUDHL4_GNASKO2_RGFP0_2    GSM8284507  Public on Aug 08 2024   \n",
       "6   SUDHL4_GNASKO2_RGFP5_1    GSM8284508  Public on Aug 08 2024   \n",
       "7   SUDHL4_GNASKO2_RGFP5_2    GSM8284509  Public on Aug 08 2024   \n",
       "8   SUDHL4_GNASKO3_RGFP0_1    GSM8284510  Public on Aug 08 2024   \n",
       "9   SUDHL4_GNASKO3_RGFP0_2    GSM8284511  Public on Aug 08 2024   \n",
       "10  SUDHL4_GNASKO3_RGFP5_1    GSM8284512  Public on Aug 08 2024   \n",
       "11  SUDHL4_GNASKO3_RGFP5_2    GSM8284513  Public on Aug 08 2024   \n",
       "\n",
       "   submission_date last_update_date type  channel_count source_name_ch1  \\\n",
       "0      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "1      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "2      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "3      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "4      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "5      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "6      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "7      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "8      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "9      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "10     May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "11     May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "\n",
       "    organism_ch1  characteristics_ch1  ... library_selection  library_source  \\\n",
       "0   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "1   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "2   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "3   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "4   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "5   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "6   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "7   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "8   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "9   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "10  Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "11  Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "\n",
       "   library_strategy  \\\n",
       "0           RNA-Seq   \n",
       "1           RNA-Seq   \n",
       "2           RNA-Seq   \n",
       "3           RNA-Seq   \n",
       "4           RNA-Seq   \n",
       "5           RNA-Seq   \n",
       "6           RNA-Seq   \n",
       "7           RNA-Seq   \n",
       "8           RNA-Seq   \n",
       "9           RNA-Seq   \n",
       "10          RNA-Seq   \n",
       "11          RNA-Seq   \n",
       "\n",
       "                                                          relation  \\\n",
       "0   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479047   \n",
       "1   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479046   \n",
       "2   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479045   \n",
       "3   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479044   \n",
       "4   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479043   \n",
       "5   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479042   \n",
       "6   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479041   \n",
       "7   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479040   \n",
       "8   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479039   \n",
       "9   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479038   \n",
       "10  BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479037   \n",
       "11  BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479036   \n",
       "\n",
       "                                                relation.1  \\\n",
       "0   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625208   \n",
       "1   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625209   \n",
       "2   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625210   \n",
       "3   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625211   \n",
       "4   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625212   \n",
       "5   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625213   \n",
       "6   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625214   \n",
       "7   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625215   \n",
       "8   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625216   \n",
       "9   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625217   \n",
       "10  SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625218   \n",
       "11  SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625219   \n",
       "\n",
       "                                                                                           supplementary_file_1  \\\n",
       "0      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284502/suppl/GSM8284502_SUDHL4_LacZ_RGFP0_1.txt.gz   \n",
       "1      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284503/suppl/GSM8284503_SUDHL4_LacZ_RGFP0_2.txt.gz   \n",
       "2      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284504/suppl/GSM8284504_SUDHL4_LacZ_RGFP5_1.txt.gz   \n",
       "3      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284505/suppl/GSM8284505_SUDHL4_LacZ_RGFP5_2.txt.gz   \n",
       "4   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284506/suppl/GSM8284506_SUDHL4_GNASKO2_RGFP0_1.txt.gz   \n",
       "5   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284507/suppl/GSM8284507_SUDHL4_GNASKO2_RGFP0_2.txt.gz   \n",
       "6   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284508/suppl/GSM8284508_SUDHL4_GNASKO2_RGFP5_1.txt.gz   \n",
       "7   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284509/suppl/GSM8284509_SUDHL4_GNASKO2_RGFP5_2.txt.gz   \n",
       "8   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284510/suppl/GSM8284510_SUDHL4_GNASKO3_RGFP0_1.txt.gz   \n",
       "9   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284511/suppl/GSM8284511_SUDHL4_GNASKO3_RGFP0_2.txt.gz   \n",
       "10  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284512/suppl/GSM8284512_SUDHL4_GNASKO3_RGFP5_1.txt.gz   \n",
       "11  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284513/suppl/GSM8284513_SUDHL4_GNASKO3_RGFP5_2.txt.gz   \n",
       "\n",
       "   cell line:ch1                        cell type:ch1   genotype:ch1  \\\n",
       "0       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "1       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "2       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "3       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "4       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "5       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "6       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "7       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "8       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "9       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "10      SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "11      SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "\n",
       "     treatment:ch1  \n",
       "0             DMSO  \n",
       "1             DMSO  \n",
       "2   RGFP966 (5 µM)  \n",
       "3   RGFP966 (5 µM)  \n",
       "4             DMSO  \n",
       "5             DMSO  \n",
       "6   RGFP966 (5 µM)  \n",
       "7   RGFP966 (5 µM)  \n",
       "8             DMSO  \n",
       "9             DMSO  \n",
       "10  RGFP966 (5 µM)  \n",
       "11  RGFP966 (5 µM)  \n",
       "\n",
       "[12 rows x 44 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(\"/home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv\")\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f4b600cd-ca54-48b3-87e4-7af6934deaa7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.to_string of                      title geo_accession                 status  \\\n",
       "0      SUDHL4_LacZ_RGFP0_1    GSM8284502  Public on Aug 08 2024   \n",
       "1      SUDHL4_LacZ_RGFP0_2    GSM8284503  Public on Aug 08 2024   \n",
       "2      SUDHL4_LacZ_RGFP5_1    GSM8284504  Public on Aug 08 2024   \n",
       "3      SUDHL4_LacZ_RGFP5_2    GSM8284505  Public on Aug 08 2024   \n",
       "4   SUDHL4_GNASKO2_RGFP0_1    GSM8284506  Public on Aug 08 2024   \n",
       "5   SUDHL4_GNASKO2_RGFP0_2    GSM8284507  Public on Aug 08 2024   \n",
       "6   SUDHL4_GNASKO2_RGFP5_1    GSM8284508  Public on Aug 08 2024   \n",
       "7   SUDHL4_GNASKO2_RGFP5_2    GSM8284509  Public on Aug 08 2024   \n",
       "8   SUDHL4_GNASKO3_RGFP0_1    GSM8284510  Public on Aug 08 2024   \n",
       "9   SUDHL4_GNASKO3_RGFP0_2    GSM8284511  Public on Aug 08 2024   \n",
       "10  SUDHL4_GNASKO3_RGFP5_1    GSM8284512  Public on Aug 08 2024   \n",
       "11  SUDHL4_GNASKO3_RGFP5_2    GSM8284513  Public on Aug 08 2024   \n",
       "\n",
       "   submission_date last_update_date type  channel_count source_name_ch1  \\\n",
       "0      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "1      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "2      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "3      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "4      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "5      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "6      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "7      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "8      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "9      May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "10     May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "11     May 21 2024      Aug 08 2024  SRA              1        SU-DHL-4   \n",
       "\n",
       "    organism_ch1  characteristics_ch1  ... library_selection  library_source  \\\n",
       "0   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "1   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "2   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "3   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "4   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "5   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "6   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "7   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "8   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "9   Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "10  Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "11  Homo sapiens  cell line: SU-DHL-4  ...              cDNA  transcriptomic   \n",
       "\n",
       "   library_strategy  \\\n",
       "0           RNA-Seq   \n",
       "1           RNA-Seq   \n",
       "2           RNA-Seq   \n",
       "3           RNA-Seq   \n",
       "4           RNA-Seq   \n",
       "5           RNA-Seq   \n",
       "6           RNA-Seq   \n",
       "7           RNA-Seq   \n",
       "8           RNA-Seq   \n",
       "9           RNA-Seq   \n",
       "10          RNA-Seq   \n",
       "11          RNA-Seq   \n",
       "\n",
       "                                                          relation  \\\n",
       "0   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479047   \n",
       "1   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479046   \n",
       "2   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479045   \n",
       "3   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479044   \n",
       "4   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479043   \n",
       "5   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479042   \n",
       "6   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479041   \n",
       "7   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479040   \n",
       "8   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479039   \n",
       "9   BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479038   \n",
       "10  BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479037   \n",
       "11  BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN41479036   \n",
       "\n",
       "                                                relation.1  \\\n",
       "0   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625208   \n",
       "1   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625209   \n",
       "2   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625210   \n",
       "3   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625211   \n",
       "4   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625212   \n",
       "5   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625213   \n",
       "6   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625214   \n",
       "7   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625215   \n",
       "8   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625216   \n",
       "9   SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625217   \n",
       "10  SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625218   \n",
       "11  SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX24625219   \n",
       "\n",
       "                                                                                           supplementary_file_1  \\\n",
       "0      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284502/suppl/GSM8284502_SUDHL4_LacZ_RGFP0_1.txt.gz   \n",
       "1      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284503/suppl/GSM8284503_SUDHL4_LacZ_RGFP0_2.txt.gz   \n",
       "2      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284504/suppl/GSM8284504_SUDHL4_LacZ_RGFP5_1.txt.gz   \n",
       "3      ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284505/suppl/GSM8284505_SUDHL4_LacZ_RGFP5_2.txt.gz   \n",
       "4   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284506/suppl/GSM8284506_SUDHL4_GNASKO2_RGFP0_1.txt.gz   \n",
       "5   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284507/suppl/GSM8284507_SUDHL4_GNASKO2_RGFP0_2.txt.gz   \n",
       "6   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284508/suppl/GSM8284508_SUDHL4_GNASKO2_RGFP5_1.txt.gz   \n",
       "7   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284509/suppl/GSM8284509_SUDHL4_GNASKO2_RGFP5_2.txt.gz   \n",
       "8   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284510/suppl/GSM8284510_SUDHL4_GNASKO3_RGFP0_1.txt.gz   \n",
       "9   ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284511/suppl/GSM8284511_SUDHL4_GNASKO3_RGFP0_2.txt.gz   \n",
       "10  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284512/suppl/GSM8284512_SUDHL4_GNASKO3_RGFP5_1.txt.gz   \n",
       "11  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8284nnn/GSM8284513/suppl/GSM8284513_SUDHL4_GNASKO3_RGFP5_2.txt.gz   \n",
       "\n",
       "   cell line:ch1                        cell type:ch1   genotype:ch1  \\\n",
       "0       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "1       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "2       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "3       SU-DHL-4  diffuse large B-cell lymphoma cells             WT   \n",
       "4       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "5       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "6       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "7       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "8       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "9       SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "10      SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "11      SU-DHL-4  diffuse large B-cell lymphoma cells  GNAS knockout   \n",
       "\n",
       "     treatment:ch1  \n",
       "0             DMSO  \n",
       "1             DMSO  \n",
       "2   RGFP966 (5 µM)  \n",
       "3   RGFP966 (5 µM)  \n",
       "4             DMSO  \n",
       "5             DMSO  \n",
       "6   RGFP966 (5 µM)  \n",
       "7   RGFP966 (5 µM)  \n",
       "8             DMSO  \n",
       "9             DMSO  \n",
       "10  RGFP966 (5 µM)  \n",
       "11  RGFP966 (5 µM)  \n",
       "\n",
       "[12 rows x 44 columns]>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d25b4758-9c9f-4145-8ea0-458fd6bd1318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are several interesting comparisons based on the provided metadata:\n",
      "\n",
      "1. **Comparison 1**:\n",
      "   - **Column Name**: `genotype:ch1`\n",
      "   - **Values**: `WT` vs. `GNAS knockout`\n",
      "   - **Justification**: Comparing the wild-type (WT) genotype with the GNAS knockout model can reveal insights into the role of GNAS in diffuse large B-cell lymphoma. A differential expression analysis may uncover how gene knockout affects the expression profile, potentially identifying pathways or markers critical in the disease.\n",
      "\n",
      "2. **Comparison 2**:\n",
      "   - **Column Name**: `treatment:ch1`\n",
      "   - **Values**: `DMSO` vs. `RGFP966 (5 µM)`\n",
      "   - **Justification**: Analyzing the gene expression differences between the DMSO-treated and RGFP966-treated samples allows for the evaluation of RGFP966's effects as a therapeutic agent. Such comparisons can yield important information on its mechanism of action and efficacy in affecting cellular processes in DLBCL.\n",
      "\n",
      "3. **Comparison 3**:\n",
      "   - **Column Name**: `genotype:ch1`\n",
      "   - **Values**: `GNAS knockout` (across treatments with DMSO and RGFP966)\n",
      "   - **Justification**: Investigating the effects of GNAS deletion across both treatment conditions (DMSO vs. RGFP966) can help understand whether the treatment response is dependent on the genetic background. This can provide insights into potential interactions between genotype and treatment effect, guiding personalized approaches in therapy.\n",
      "\n",
      "4. **Comparison 4**:\n",
      "   - **Column Name**: `treatment:ch1`\n",
      "   - **Values**: `DMSO` in WT vs. `DMSO` in GNAS knockout\n",
      "   - **Justification**: Comparing the effects of DMSO treatment on WT versus GNAS knockout cell lines can shed light on how the baseline genetic variation impacts cellular responses, thus offering insights into the biological roles of GNAS in DLBCL.\n",
      "\n",
      "5. **Comparison 5**:\n",
      "   - **Column Name**: `treatment:ch1`\n",
      "   - **Values**: `RGFP966 (5 µM)` in WT vs. `RGFP966 (5 µM)` in GNAS knockout\n",
      "   - **Justification**: This comparison assesses whether the therapeutic effect of RGFP966 is influenced by GNAS status. Understanding this relationship could reveal important information for the development of targeted cancer therapies, especially in cases where GNAS mutations might confer resistance or sensitivity to treatment.\n",
      "\n",
      "These comparisons make use of the metadata provided and have significant implications for understanding the biology underlying DLBCL, as well as the impact of genetic modifications and treatment strategies on gene expression profiles.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "## IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert in bioinformatic analyses. You will be provided with a metadata sheet, and are tasked with identifying contrasts that could be interesting in the metadata, with the intention of analysing these in a edgeR/limma based pipeline.\n",
    "Take a deep breath, and carefully follow the steps outlined below to achieve the intended task.\n",
    "\n",
    "## STEPS\n",
    "\n",
    "1. Carefully consider each column, inferring what each column means from its name, and also the values in the column. \n",
    "2. Determine columns that appear to contain data that would be scientifically and biologically interesting to compare within the column.\n",
    "- Only include comparisons that can be easily analysed in a limma/edgeR based pipeline\n",
    "- Only include comparisons that would be generally valuable to scientific and medical literature\n",
    "- Only include comparisons that can be made within this dataset only - i.e. does not require samples from additional datasets\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "1. For each comparison, include the EXACT column name, as well as the EXACT values that should be used for the comparison. Additionally, justify why the comparison would be interesting using up to 3 sentences\n",
    "\n",
    "## INPUT\n",
    "\n",
    "Metadata:\n",
    "{meta.to_string()}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.beta.chat.completions.parse(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a24f78-9be3-4015-92d8-98f418f9befd",
   "metadata": {},
   "source": [
    "The above does seem pretty good - it is capturing everything that I want. However, I could imagine improvements if I\n",
    "1. Repeated multiple times\n",
    "2. Collate responses (a bit of experimentation reveals this will most likely be a combination of code, but also an LLM to remove \"loose\" duplicates)\n",
    "3. Give scores to responses, to determine what the \"final\" list of contrasts to analyse should be.\n",
    "\n",
    "I will therefore adapt the approach I took in identifying relevant datasets, and implement it here (since I did perform both).\n",
    "\n",
    "I will need to give special consideration to how to evaluate/score the contrasts (perhaps Mr. Claude/ChatGPT will be helpful for me...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e017b3ed-105e-4058-975e-ea8bc7a01afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite selective HDAC3 inhibition showing promise in a subset of lymphomas with CREBBP mutations, wild-type tumors generally exhibit resistance. Here, using unbiased genome-wide CRISPR screening, we identify GNAS knockout (KO) as a sensitizer of resistant lymphoma cells to HDAC3 inhibition. Mechanistically, GNAS KO-induced sensitization is independent of the canonical G-protein activities but unexpectedly mediated by viral mimicry-related interferon (IFN) responses, characterized by TBK1 and IRF3 activation, double-stranded RNA formation, and transposable element (TE) expression. GNAS KO additionally synergizes with HDAC3 inhibition to enhance CD8+ T cell-induced cytotoxicity. Moreover, we observe in human lymphoma patients that low GNAS expression is associated with high baseline TE expression and upregulated IFN signaling and shares common disrupted biological activities with GNAS KO in histone modification, mRNA processing, and transcriptional regulation. Collectively, our findings establish an unprecedented link between HDAC3 inhibition and viral mimicry in lymphoma. We suggest low GNAS expression as a potential biomarker that reflects viral mimicry priming for enhanced response to HDAC3 inhibition in the clinical treatment of lymphoma, especially the CREBBP wild-type cases.\n"
     ]
    }
   ],
   "source": [
    "# This code block is for getting the study summary. I will want to implement this in determining the appropriate contrasts.\n",
    "\n",
    "def get_study_summary(accession, edirect_path=\"/home/myuser/edirect\"):\n",
    "\n",
    "    # Define the command as a string\n",
    "    command = (\n",
    "        f'esearch -db gds -query \"{accession}[ACCN]\" | '\n",
    "        'efetch -format docsum | '\n",
    "        'xtract -pattern DocumentSummarySet -block DocumentSummary '\n",
    "        f'-if Accession -equals {accession} -element summary'\n",
    "    )\n",
    "\n",
    "    # Execute the command\n",
    "    result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    # Check if the command was successful\n",
    "    if result.returncode == 0:\n",
    "        # Return the output\n",
    "        return result.stdout.strip()\n",
    "    else:\n",
    "        # Raise an error with the stderr output\n",
    "        raise Exception(f\"Error: {result.stderr}\")\n",
    "\n",
    "# Example usage:\n",
    "study_summary = get_study_summary(\"GSE268034\")\n",
    "print(study_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a990c-3d4c-45b7-ada6-5dfbbc323edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "18cf2d53-cdcf-4154-8dcc-67de531de42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assessment(BaseModel):\n",
    "    name: str = Field(description = \"A name to be given to describe the contrast\")\n",
    "    column: str = Field(description = \"Column, or column, in the metadata containing the values to be compared\")\n",
    "    values: str = Field(description = \"The values in the identified column that are to be compared\")\n",
    "    justification: str = Field(description = \"Justification for why the suggested contrast will be of use\")\n",
    "\n",
    "class Contrasts(BaseModel):\n",
    "    contrasts: list[Assessment]\n",
    "\n",
    "def identify_contrasts(meta):\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "## IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert in bioinformatic analyses. You will be provided with a metadata sheet, and are tasked with identifying contrasts that could be interesting in the metadata, with the intention of analysing these in a edgeR/limma based pipeline.\n",
    "Take a deep breath, and carefully follow the steps outlined below to achieve the intended task.\n",
    "\n",
    "## STEPS\n",
    "\n",
    "1. Carefully consider each column, inferring what each column means from its name, and also the values in the column. \n",
    "2. Carefully digest the contents of the study summary to help identify points of interest in the study\n",
    "- Use the study summary to generate up to three highly valuable and focussed research questions\n",
    "3. Determine columns that appear to contain data that would be scientifically and biologically interesting to analyse\n",
    "- These should be derived from the research questions determined from the study summary\n",
    "- Only include analyses that can be made within this dataset only - i.e. does not require samples from additional datasets\n",
    "- You are permitted to draw comparisons involving multiple different columns\n",
    "4. Specify the values in the columns that should be used to for the comparison\n",
    "- Only include comparisons that can be easily analysed in a limma/edgeR based pipeline. \n",
    "- Specifically take into consideration how a contrast matrix could be set up using the model.matrix and makeContrasts functions.\n",
    "- You are permitted to draw comparisons involving multiple different columns\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "1. Include output for each proposed comparison\n",
    "2. Specify the exact column name(s) that will need to be used for the comparison\n",
    "- If this includes columns that are needed to identify relevant samples, include these as well\n",
    "- For example, if the comparison is \"Treatment X vs. Y in genotype A samples,\" you should indicate both the Treatment and Genotype columns, assuming there are multiple genotypes\n",
    "- This is because the \"Genotype\" column is relevant for filtering down to Genotype A samples\"\n",
    "- Separate each value with \",\". Do not include any other formatting, e.g. \"vs\" or \"-\".\n",
    "3. Specify the exact values that will be used for the comparison\n",
    "- This includes any values which will be needed for filtering down, as per Point 2 in OUTPUT\n",
    "- If the samples to be compared are, for example \"Treatment X vs. Y in genotpye A samples\", the output should be \"X, A vs. Y, A\"\n",
    "4. Justify why the comparison would be interesting using up to 3 sentences\n",
    "\n",
    "For points 2 and 3, note that this should include enough information for someone to generate an appropriate contrast matrix using model.matrix and makeContrasts.\n",
    "\n",
    "## INPUT\n",
    "\n",
    "Study summary:\n",
    "{study_summary}\n",
    "\n",
    "Metadata:\n",
    "{meta.to_string()}\n",
    "\n",
    "\"\"\"\n",
    "    chat_completion = client.beta.chat.completions.parse(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_format = Contrasts\n",
    "        )\n",
    "    result = chat_completion.choices[0].message.parsed\n",
    "    print(f\"Generated tokens: \", chat_completion.usage.completion_tokens)\n",
    "    print(f\"Prompt tokens: \", chat_completion.usage.prompt_tokens)\n",
    "    print(f\"Total tokens: \", chat_completion.usage.total_tokens)\n",
    "    return(result)\n",
    "\n",
    "async def identify_contrasts_multiple(meta, num_queries: int = 3) -> Contrasts:\n",
    "    async def single_identify_contrasts():\n",
    "        return identify_contrasts(meta)\n",
    "\n",
    "    tasks = [single_identify_contrasts() for _ in range(num_queries)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Combine the results\n",
    "    all_contrasts = Contrasts(contrasts=[])\n",
    "    for result in results:\n",
    "        all_contrasts.contrasts.extend(result.contrasts)\n",
    "\n",
    "    # Deduplication process to remove duplicate contrasts\n",
    "    contrasts_dict = all_contrasts.dict()\n",
    "    seen = set()\n",
    "    unique_contrasts = []\n",
    "\n",
    "    for item in contrasts_dict['contrasts']:\n",
    "        identifier = (item['column'], item['values'])\n",
    "        if identifier not in seen:\n",
    "            unique_contrasts.append(item)\n",
    "            seen.add(identifier)\n",
    "\n",
    "    # Replace the original list with the filtered one\n",
    "    contrasts_dict['contrasts'] = unique_contrasts\n",
    "\n",
    "    # Convert back to the Contrasts model\n",
    "    unique_contrasts_model = Contrasts(**contrasts_dict)\n",
    "\n",
    "    return unique_contrasts_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "206209d2-3a71-4f34-92e9-b80377fbafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens:  275\n",
      "Prompt tokens:  9370\n",
      "Total tokens:  9645\n",
      "Generated tokens:  439\n",
      "Prompt tokens:  9370\n",
      "Total tokens:  9809\n",
      "contrasts=[Assessment(name='DMSO vs RGFP966 in WT samples', column='treatment', values='DMSO,RGFP966 (5 µM)', justification='Comparing the effects of DMSO to RGFP966 treatment in wild-type (WT) diffuse large B-cell lymphoma cells is crucial for understanding how RGFP966 impacts gene expression. This can reveal potential therapeutic benefits or mechanisms through which RGFP966 enhances sensitivity in GNAS wild-type samples.'), Assessment(name='GNAS KO vs WT without treatment', column='genotype', values='WT,GNAS knockout', justification='Examining the differences in gene expression between GNAS knockout and wild-type samples without treatment can help identify intrinsic molecular differences and pathways that are activated in the absence of GNAS. This comparison may uncover potential biomarkers or therapeutic targets for enhanced treatment strategies.'), Assessment(name='DMSO vs. RGFP966 in wild-type cells', column='treatment:ch1, genotype:ch1', values='DMSO, WT vs. RGFP966 (5 µM), WT\\nDMSO, WT vs. RGFP966, WT\\nDMSO, WT vs. RGFP966 (5 µM), WT\\nDMSO, WT vs. RGFP966, WT', justification='This comparison will reveal how the HDAC3 inhibition by RGFP966 affects gene expression in wild-type cells, which is crucial for understanding the therapeutic potential in lymphomas that typically show resistance.'), Assessment(name='DMSO vs. RGFP966 in GNAS knockout cells', column='treatment:ch1, genotype:ch1', values='DMSO, GNAS knockout vs. RGFP966 (5 µM), GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966, GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966 (5 µM), GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966, GNAS knockout', justification='This will help to elucidate how the GNAS knockout sensitizes cells to RGFP966 treatment, providing information on the mechanism of enhanced cytotoxicity observed in these cells.'), Assessment(name='Comparing wild-type and GNAS knockout responses to RGFP966', column='genotype:ch1, treatment:ch1', values='WT, RGFP966 (5 µM) vs. GNAS knockout, RGFP966 (5 µM)\\nWT, RGFP966 vs. GNAS knockout, RGFP966\\nWT, RGFP966 (5 µM) vs. GNAS knockout, RGFP966\\nWT, RGFP966 vs. GNAS knockout, RGFP966', justification='Comparing the expression profiles of wild-type and GNAS knockout cells under RGFP966 treatment will identify gene alterations due to the sensitization effect of GNAS knockout and its potential regulatory implications in response to HDAC3 inhibition.')]\n"
     ]
    }
   ],
   "source": [
    "contrasts = await identify_contrasts_multiple(meta, num_queries=2)\n",
    "print(contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "3a0bcb7f-d20f-42be-8c11-e6f2289fe512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens:  421\n",
      "Prompt tokens:  10324\n",
      "Total tokens:  10745\n"
     ]
    }
   ],
   "source": [
    "class ComparisonEval(BaseModel):\n",
    "    comparison: str\n",
    "    score: int\n",
    "    score_justification: str\n",
    "    redundant: Literal[\"Yes\", \"No\"]\n",
    "    redundant_justification: str\n",
    "    retain: Literal[\"Yes\", \"No\"]\n",
    "\n",
    "class AllEvals(BaseModel):\n",
    "    evals: list[ComparisonEval]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "### PURPOSE AND IDENTITY\n",
    "\n",
    "You are an expert and experienced bioinformatician and scientist, who focuses on clarifying analyses which will be meaningful to perform. \n",
    "\n",
    "You have been tasked with evaluating the potential scientific value of proposed comparisons. These comparisons are intended to be performed in a edgeR/limma-based RNA-seq pipeline.\n",
    "\n",
    "Take a deep breath, and carefully follow the below steps to achieve the best possible outcome.\n",
    "\n",
    "### STEPS \n",
    "\n",
    "1. You will be provided a Python dictionary of proposed scientific comparisons which have been proposed for a limma/edgeR RNAseq pipeline.\n",
    "- Do not propose any additional scientific comparisons beyond those specified in this Python dictionary\n",
    "- Throughout your evaluation, keep in mind that the analysis will be based on the construction of a contrast matrix, using the values specified in the column and values.\n",
    "2. You will also be provided metadata, which contains data that is mentioned in the Python dictionary, as well as a study summary\n",
    "- Do NOT use this metadata to hallucinate additional comparisons\n",
    "- Use this metadata ONLY to gather additional context for the defined scientific comparisons.\n",
    "- Use the study summary to contextualise\n",
    "3. For each proposed analysis, assign a score between 1 - 5, based on the scientific value that can be extracted out of the comparison. Do this independently for each comparison. Use the below as a scoring guide:\n",
    "\n",
    "Score 5 – Outstanding Scientific Value\n",
    "\n",
    "\t•\tThe proposed comparison is highly relevant and addresses a significant scientific question or hypothesis.\n",
    "\t•\tThe comparison is likely to yield new and impactful insights that could lead to meaningful advancements in the field.\n",
    "\t•\tThe analysis is well-aligned with the biological context provided by the metadata and is expected to generate robust, interpretable results.\n",
    "\t•\tThe comparison is novel or provides a unique perspective that has not been previously explored.\n",
    "\n",
    "Score 4 – High Scientific Value\n",
    "\n",
    "\t•\tThe proposed comparison is scientifically sound and addresses an important question.\n",
    "\t•\tThe analysis has the potential to contribute valuable insights, though it may be incremental rather than groundbreaking.\n",
    "\t•\tThe comparison is well-supported by the metadata and is expected to produce meaningful results.\n",
    "\t•\tThe comparison adds depth to existing knowledge but may not be entirely novel.\n",
    "\n",
    "Score 3 – Moderate Scientific Value\n",
    "\n",
    "\t•\tThe proposed comparison is reasonable and could yield useful information.\n",
    "\t•\tThe analysis addresses a relevant question, though the scientific impact may be limited or somewhat unclear.\n",
    "\t•\tThe comparison is supported by the metadata but may not be as compelling or novel as higher-scoring comparisons.\n",
    "\t•\tThe results may be interesting but are likely to confirm existing knowledge rather than provide new insights.\n",
    "\n",
    "Score 2 – Low Scientific Value\n",
    "\n",
    "\t•\tThe proposed comparison is somewhat relevant but does not address a particularly important or novel question.\n",
    "\t•\tThe analysis may yield some useful data, but the scientific impact is expected to be minimal.\n",
    "\t•\tThe comparison is only partially supported by the metadata, and the results may be difficult to interpret or have limited applicability.\n",
    "\t•\tThe comparison may be redundant with existing analyses or provide only marginal additional insights.\n",
    "\n",
    "Score 1 – Minimal or No Scientific Value\n",
    "\n",
    "\t•\tThe proposed comparison is poorly conceived and unlikely to yield meaningful scientific insights.\n",
    "\t•\tThe analysis does not address a relevant or important question, or the rationale for the comparison is unclear.\n",
    "\t•\tThe comparison is not well-supported by the metadata, and the results are likely to be uninterpretable or irrelevant.\n",
    "\t•\tThe comparison may be redundant, trivial, or based on a flawed premise.\n",
    "\n",
    "4. For each comparison, also identify if it is redundant and/or overlapping with another comparison.\n",
    "- An example of this is identical \"column\" and \"values\" (e.g. column of \"A\" and values of \"val1, val2\" as compared to \"val2, val1\" or \"val1 - val2\")\n",
    "- **Important** Note that if comparison 1 is redundant with comparison 2, BOTH comparisons 1 and 2 should be marked as redundant.\n",
    "- Comparisons which are similar, but not overlapping, should not be classed as redundant\n",
    "- Only classify comparisons as redundant if you are highly confident that they are redundant\n",
    "- Keep in mind the analysis will be based on an edgeR/limma/DESeq2 pipeline - if two analyses are likely to require the identical experimental setup, these are redundant.\n",
    "- After evaluating all comparisons for redundancy, double check whether the intended repsonse for any other comparison needs to be altered accordingly.\n",
    "5. Based on your score evaluation and redundancy evaluation, make an evaluation as to whether each comparison should be retained. \n",
    "- When there are redundant comparisons, ONLY the comparison with the higher scientific value score should be retained\n",
    "- If redundant comparisons have the same scientific value score, then retain EXACTLY one if both meet the scientific value score\n",
    "- A scientific value score of 4 should be used as the threshold to retain a comparison\n",
    "6. Prior to reporting results, double check that your responses are reasonable, and you have followed the steps correctly.\n",
    "7. Report your results in accordance to the instructions in OUTPUT.\n",
    "\n",
    "### OUTPUT\n",
    "\n",
    "1. Include output for all proposed comparisons. Use the comparison name to describe each comparison.\n",
    "2. Specify the scientific evaluation score\n",
    "3. Include justification for the scientific evaluation score\n",
    "4. Specify if the comparison is redundant\n",
    "5. If redundant, justify why it is redundant. If not redundant, specify \"Not redundant\" for this field.\n",
    "- The justification for selecting which of the redundant comparisons, if any, should be specified here.\n",
    "6. Specify if the comparison should be retained or not\n",
    "\n",
    "### PROPOSED SCIENTIFIC ANALYSES\n",
    "\n",
    "{contrasts}\n",
    "\n",
    "### METADATA\n",
    "\n",
    "{meta.to_string()}\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.beta.chat.completions.parse(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=AllEvals\n",
    ")\n",
    "print(f\"Generated tokens: \", chat_completion.usage.completion_tokens)\n",
    "print(f\"Prompt tokens: \", chat_completion.usage.prompt_tokens)\n",
    "print(f\"Total tokens: \", chat_completion.usage.total_tokens)\n",
    "result = chat_completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1014f693-3b7a-4fbd-9beb-0e4080a7aec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>column</th>\n",
       "      <th>values</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DMSO vs RGFP966 in WT samples</td>\n",
       "      <td>treatment</td>\n",
       "      <td>DMSO,RGFP966 (5 µM)</td>\n",
       "      <td>Comparing the effects of DMSO to RGFP966 treatment in wild-type (WT) diffuse large B-cell lymphoma cells is crucial for understanding how RGFP966 impacts gene expression. This can reveal potential therapeutic benefits or mechanisms through which RGFP966 enhances sensitivity in GNAS wild-type samples.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GNAS KO vs WT without treatment</td>\n",
       "      <td>genotype</td>\n",
       "      <td>WT,GNAS knockout</td>\n",
       "      <td>Examining the differences in gene expression between GNAS knockout and wild-type samples without treatment can help identify intrinsic molecular differences and pathways that are activated in the absence of GNAS. This comparison may uncover potential biomarkers or therapeutic targets for enhanced treatment strategies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DMSO vs. RGFP966 in wild-type cells</td>\n",
       "      <td>treatment:ch1, genotype:ch1</td>\n",
       "      <td>DMSO, WT vs. RGFP966 (5 µM), WT\\nDMSO, WT vs. RGFP966, WT\\nDMSO, WT vs. RGFP966 (5 µM), WT\\nDMSO, WT vs. RGFP966, WT</td>\n",
       "      <td>This comparison will reveal how the HDAC3 inhibition by RGFP966 affects gene expression in wild-type cells, which is crucial for understanding the therapeutic potential in lymphomas that typically show resistance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DMSO vs. RGFP966 in GNAS knockout cells</td>\n",
       "      <td>treatment:ch1, genotype:ch1</td>\n",
       "      <td>DMSO, GNAS knockout vs. RGFP966 (5 µM), GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966, GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966 (5 µM), GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966, GNAS knockout</td>\n",
       "      <td>This will help to elucidate how the GNAS knockout sensitizes cells to RGFP966 treatment, providing information on the mechanism of enhanced cytotoxicity observed in these cells.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparing wild-type and GNAS knockout responses to RGFP966</td>\n",
       "      <td>genotype:ch1, treatment:ch1</td>\n",
       "      <td>WT, RGFP966 (5 µM) vs. GNAS knockout, RGFP966 (5 µM)\\nWT, RGFP966 vs. GNAS knockout, RGFP966\\nWT, RGFP966 (5 µM) vs. GNAS knockout, RGFP966\\nWT, RGFP966 vs. GNAS knockout, RGFP966</td>\n",
       "      <td>Comparing the expression profiles of wild-type and GNAS knockout cells under RGFP966 treatment will identify gene alterations due to the sensitization effect of GNAS knockout and its potential regulatory implications in response to HDAC3 inhibition.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         name  \\\n",
       "0                               DMSO vs RGFP966 in WT samples   \n",
       "1                             GNAS KO vs WT without treatment   \n",
       "2                         DMSO vs. RGFP966 in wild-type cells   \n",
       "3                     DMSO vs. RGFP966 in GNAS knockout cells   \n",
       "4  Comparing wild-type and GNAS knockout responses to RGFP966   \n",
       "\n",
       "                        column  \\\n",
       "0                    treatment   \n",
       "1                     genotype   \n",
       "2  treatment:ch1, genotype:ch1   \n",
       "3  treatment:ch1, genotype:ch1   \n",
       "4  genotype:ch1, treatment:ch1   \n",
       "\n",
       "                                                                                                                                                                                                         values  \\\n",
       "0                                                                                                                                                                                           DMSO,RGFP966 (5 µM)   \n",
       "1                                                                                                                                                                                              WT,GNAS knockout   \n",
       "2                                                                                          DMSO, WT vs. RGFP966 (5 µM), WT\\nDMSO, WT vs. RGFP966, WT\\nDMSO, WT vs. RGFP966 (5 µM), WT\\nDMSO, WT vs. RGFP966, WT   \n",
       "3  DMSO, GNAS knockout vs. RGFP966 (5 µM), GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966, GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966 (5 µM), GNAS knockout\\nDMSO, GNAS knockout vs. RGFP966, GNAS knockout   \n",
       "4                           WT, RGFP966 (5 µM) vs. GNAS knockout, RGFP966 (5 µM)\\nWT, RGFP966 vs. GNAS knockout, RGFP966\\nWT, RGFP966 (5 µM) vs. GNAS knockout, RGFP966\\nWT, RGFP966 vs. GNAS knockout, RGFP966   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                     justification  \n",
       "0                    Comparing the effects of DMSO to RGFP966 treatment in wild-type (WT) diffuse large B-cell lymphoma cells is crucial for understanding how RGFP966 impacts gene expression. This can reveal potential therapeutic benefits or mechanisms through which RGFP966 enhances sensitivity in GNAS wild-type samples.  \n",
       "1  Examining the differences in gene expression between GNAS knockout and wild-type samples without treatment can help identify intrinsic molecular differences and pathways that are activated in the absence of GNAS. This comparison may uncover potential biomarkers or therapeutic targets for enhanced treatment strategies.  \n",
       "2                                                                                                            This comparison will reveal how the HDAC3 inhibition by RGFP966 affects gene expression in wild-type cells, which is crucial for understanding the therapeutic potential in lymphomas that typically show resistance.  \n",
       "3                                                                                                                                                This will help to elucidate how the GNAS knockout sensitizes cells to RGFP966 treatment, providing information on the mechanism of enhanced cytotoxicity observed in these cells.  \n",
       "4                                                                        Comparing the expression profiles of wild-type and GNAS knockout cells under RGFP966 treatment will identify gene alterations due to the sensitization effect of GNAS knockout and its potential regulatory implications in response to HDAC3 inhibition.  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = contrasts.dict()\n",
    "df = pd.DataFrame(df['contrasts'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c2bd5759-ecad-404f-8580-7318fef571c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparison</th>\n",
       "      <th>score</th>\n",
       "      <th>score_justification</th>\n",
       "      <th>redundant</th>\n",
       "      <th>redundant_justification</th>\n",
       "      <th>retain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DMSO vs RGFP966 in WT samples</td>\n",
       "      <td>5</td>\n",
       "      <td>This comparison addresses a significant scientific question regarding the impact of RGFP966 on gene expression in WT diffuse large B-cell lymphoma cells. The potential therapeutic insights gained from this analysis could greatly benefit treatment strategies.</td>\n",
       "      <td>No</td>\n",
       "      <td>Not redundant</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GNAS KO vs WT without treatment</td>\n",
       "      <td>4</td>\n",
       "      <td>This comparison is scientifically sound and aims to uncover intrinsic molecular differences between GNAS knockout and wild-type samples. Insights from this study might identify potential biomarkers for new therapeutic targets.</td>\n",
       "      <td>No</td>\n",
       "      <td>Not redundant</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DMSO vs. RGFP966 in wild-type cells</td>\n",
       "      <td>4</td>\n",
       "      <td>The analysis explores how RGFP966 affects gene expression in WT lymphomas. This is crucial for understanding its therapeutic potential, especially for cells showing drug resistance.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>This analysis is redundant with the 'DMSO vs RGFP966 in WT samples' comparison, as they address the same treatment condition and cell type.</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DMSO vs. RGFP966 in GNAS knockout cells</td>\n",
       "      <td>5</td>\n",
       "      <td>This comparison is valuable as it aims to elucidate the mechanism behind the increased sensitivity in GNAS knockout cells towards RGFP966, providing potential therapeutic insights.</td>\n",
       "      <td>No</td>\n",
       "      <td>Not redundant</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparing wild-type and GNAS knockout responses to RGFP966</td>\n",
       "      <td>5</td>\n",
       "      <td>This analysis will provide significant insights into the role of GNAS knockout on gene expression changes induced by RGFP966. It has the potential to identify mechanistic insights relevant to therapy.</td>\n",
       "      <td>No</td>\n",
       "      <td>Not redundant</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comparison  score  \\\n",
       "0                               DMSO vs RGFP966 in WT samples      5   \n",
       "1                             GNAS KO vs WT without treatment      4   \n",
       "2                         DMSO vs. RGFP966 in wild-type cells      4   \n",
       "3                     DMSO vs. RGFP966 in GNAS knockout cells      5   \n",
       "4  Comparing wild-type and GNAS knockout responses to RGFP966      5   \n",
       "\n",
       "                                                                                                                                                                                                                                                  score_justification  \\\n",
       "0  This comparison addresses a significant scientific question regarding the impact of RGFP966 on gene expression in WT diffuse large B-cell lymphoma cells. The potential therapeutic insights gained from this analysis could greatly benefit treatment strategies.   \n",
       "1                                  This comparison is scientifically sound and aims to uncover intrinsic molecular differences between GNAS knockout and wild-type samples. Insights from this study might identify potential biomarkers for new therapeutic targets.   \n",
       "2                                                                               The analysis explores how RGFP966 affects gene expression in WT lymphomas. This is crucial for understanding its therapeutic potential, especially for cells showing drug resistance.   \n",
       "3                                                                                This comparison is valuable as it aims to elucidate the mechanism behind the increased sensitivity in GNAS knockout cells towards RGFP966, providing potential therapeutic insights.   \n",
       "4                                                            This analysis will provide significant insights into the role of GNAS knockout on gene expression changes induced by RGFP966. It has the potential to identify mechanistic insights relevant to therapy.   \n",
       "\n",
       "  redundant  \\\n",
       "0        No   \n",
       "1        No   \n",
       "2       Yes   \n",
       "3        No   \n",
       "4        No   \n",
       "\n",
       "                                                                                                                       redundant_justification  \\\n",
       "0                                                                                                                                Not redundant   \n",
       "1                                                                                                                                Not redundant   \n",
       "2  This analysis is redundant with the 'DMSO vs RGFP966 in WT samples' comparison, as they address the same treatment condition and cell type.   \n",
       "3                                                                                                                                Not redundant   \n",
       "4                                                                                                                                Not redundant   \n",
       "\n",
       "  retain  \n",
       "0    Yes  \n",
       "1    Yes  \n",
       "2     No  \n",
       "3    Yes  \n",
       "4    Yes  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result.dict()\n",
    "df = pd.DataFrame(df['evals'])\n",
    "df.to_csv(\"temp.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86787fac-17e8-4656-9364-008542d3b5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117c325-50fb-4ea1-8c79-462df2ebe303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4950a396-f332-4907-8890-b5da3af8a506",
   "metadata": {},
   "source": [
    "I'm not entirely satisfied with the outcome so far (mainly with the inability to identify redundant contrasts) - however, the contrasts it is identifying do seem of interest, and I must admit is better than the singular one I came up with in my initial testing.\n",
    "\n",
    "I noted several instances of hallucinations, parituclarly with imagining contrast that I did not specify. I've tried to stamp these out... a bit concerningly, these were sometimes marked as \"retain\".\n",
    "\n",
    "My plan at the moment is to leave this as is (at least for the moment), and when I begin the prompt to develop the code a bit more explicitly, I think I might just include another check to see \"would the code be functionally identical? -> if yes, ignore\". This might be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34223c8-1d7a-45db-92a5-d3a5ca23a954",
   "metadata": {},
   "source": [
    "# Generating the RNAseq analysis code\n",
    "\n",
    "My focus will now switch to generating RNAseq analysis code. In my head, this would turn out as:\n",
    "- Identify the Kallisto files\n",
    "- Import the Kallisto abundances\n",
    "- Import the metadata\n",
    "- Create a DGEList object\n",
    "- Filtering/normalisation\n",
    "- DEG analysis\n",
    "\n",
    "Of course, if it ends up pivoting from this, then I can assess the performance. In any case, I think the overall workflow I am aiming for:\n",
    "- Propose pipeline\n",
    "- Evaluate the pipeline\n",
    "- If needed, adjust the proposed pipeline\n",
    "- Execute pipeline\n",
    "- Assess results of the pipeline (mainly in terms of stderr/stdout) - do the results make sense?\n",
    "- I'd also be interested to see how possible it is to integrate QC into this. e.g. I can provide images, but would these actually be interpreted correctly? (and I'm also unsure how I'd even feed these in...).\n",
    "\n",
    "EDIT - this will be changed to:\n",
    "- create an RNAseq pipeline with optional parameters\n",
    "- Have the LLM decide all the parameters for me\n",
    "- have a correction workflow\n",
    "- Make assessments based on the generated results - since I know I can do this for images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec5d32-e070-41ea-85d5-8d6b68533ae5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Small image test\n",
    "\n",
    "I want to get an idea of the value of inputting images. Both in terms of - can I expect it will perform well, and also how much does it cost? \n",
    "\n",
    "Seems that cost is not going to be a big issue. The manual implementation of this works... fine (it can interpret the image), but I'm not sure how viable this will become "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d486aa9d-16bb-471b-a685-42d5a17e392f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9yyGKp5IvN3DnfstTddh1kZ1mRcpa', 'object': 'chat.completion', 'created': 1724318356, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Based on the provided image, here's an assessment of the quality control (QC) check in the bioinformatic analysis:\\n\\n1. **Unfiltered Data** (Left Panel):\\n   - The density plot shows multiple peaks and a significant amount of density at lower log-cpm values (around 6). This suggests the presence of low count or noise, which may indicate poor quality data or a large number of low-expressed genes.\\n\\n2. **Filtered Data** (Right Panel):\\n   - The density plot indicates a much sharper and centralized peak around higher log-cpm values (8 to 12+). This suggests that filtering has improved the overall quality of the data by removing low-expressed genes or noise, and focusing on relevant gene expression.\\n\\n### Conclusion:\\nThe QC check likely passed since the filtered data shows a more normalized distribution with reduced noise, indicating that effective filtering has been applied to enhance the dataset's quality.\", 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 8541, 'completion_tokens': 184, 'total_tokens': 8725}, 'system_fingerprint': 'fp_507c9469a1'}\n"
     ]
    }
   ],
   "source": [
    "# Examples of image-based QC I might do include interpreting PCA plots, assessing the outcome of filtering as well as normalization.\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"./ManualRNASeqAnalysis/Filtering.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "The provided image is intended for use as a QC check in a bioinformatic analysis.\n",
    "\n",
    "Make an assessment as to whether the QC check is likely to have passed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {openai_api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": prompt\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d104bf8-3967-4083-b6ba-c3b80469b407",
   "metadata": {},
   "source": [
    "# Code generation test\n",
    "\n",
    "In the worked example OpenAI provides of structured outputs, they have an example of solving an equation - I am planning on doing something similar.\n",
    "\n",
    "I need to think carefully about the implementation - my first test case will be \"produce step-by-step pipeline\", followed by \"what are the expected inputs and outputs\" and \"generate code\" for each step in the pipeline. \n",
    "\n",
    "I need to think somewhat carefully about how I implement the metaeata... it is definitely necessary to get the correct code. I think with this in mind, it makes sense to have a separate LLM call for... each step...?\n",
    "\n",
    "EDIT FROM THE FUTURE - just do a customatizable R script and have the LLM plug in appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1d3f5e04-a97a-46bf-9b87-a83529b66a53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': [{'name': 'Load Required Libraries',\n",
       "   'description': 'Load necessary R packages for the analysis.',\n",
       "   'purpose': 'To ensure that all required libraries are available for subsequent steps.',\n",
       "   'functions': ['library', 'suppressPackageStartupMessages'],\n",
       "   'input': [],\n",
       "   'output': []},\n",
       "  {'name': 'Load Metadata',\n",
       "   'description': 'Read sample metadata and validate its structure.',\n",
       "   'purpose': 'To gather important information regarding samples, such as conditions and replicates for analysis.',\n",
       "   'functions': ['read.csv', 'glimpse'],\n",
       "   'input': ['sample_metadata.csv'],\n",
       "   'output': ['metadata']},\n",
       "  {'name': 'Load Kallisto Abundance Files',\n",
       "   'description': 'Load Kallisto abundance files and prepare for quantification analysis.',\n",
       "   'purpose': 'To aggregate quantification data from all Kallisto outputs for subsequent analysis.',\n",
       "   'functions': ['list.files', 'read_tsv'],\n",
       "   'input': ['kallisto_abundance_files/'],\n",
       "   'output': ['abundance_data']},\n",
       "  {'name': 'Combine Abundance Data',\n",
       "   'description': 'Combine multiple Kallisto abundance files into a single data frame.',\n",
       "   'purpose': 'To create a unified dataset for downstream analysis.',\n",
       "   'functions': ['tximport', 'as.data.frame'],\n",
       "   'input': ['abundance_data'],\n",
       "   'output': ['combined_abundance']},\n",
       "  {'name': 'Quality Control - PCA Plot',\n",
       "   'description': 'Perform PCA analysis for quality control of samples based on expression data.',\n",
       "   'purpose': 'To visualize sample clustering and identify potential outliers.',\n",
       "   'functions': ['prcomp', 'ggplot'],\n",
       "   'input': ['combined_abundance'],\n",
       "   'output': ['pca_plot']},\n",
       "  {'name': 'Model Design',\n",
       "   'description': 'Create a design formula based on sample metadata for differential expression analysis.',\n",
       "   'purpose': 'To set up the framework for statistical comparisons between conditions.',\n",
       "   'functions': ['model.matrix'],\n",
       "   'input': ['metadata'],\n",
       "   'output': ['design_matrix']},\n",
       "  {'name': 'Count Data Normalization',\n",
       "   'description': 'Normalize count data to account for library size and other biases.',\n",
       "   'purpose': 'To ensure that differences in read counts are not driven by sequencing depth.',\n",
       "   'functions': ['normalizeBetweenArrays'],\n",
       "   'input': ['combined_abundance'],\n",
       "   'output': ['normalized_counts']},\n",
       "  {'name': 'Differential Expression Analysis',\n",
       "   'description': 'Utilize DESeq2 to identify differentially expressed genes.',\n",
       "   'purpose': 'To find genes that are significantly upregulated or downregulated between conditions.',\n",
       "   'functions': ['DESeq', 'results'],\n",
       "   'input': ['normalized_counts', 'design_matrix'],\n",
       "   'output': ['de_results']},\n",
       "  {'name': 'Extract Significant Genes',\n",
       "   'description': 'Filter results to extract genes with significant differences.',\n",
       "   'purpose': 'To focus on genes that are biologically meaningful and warrant further investigation.',\n",
       "   'functions': ['filter', 'write_csv'],\n",
       "   'input': ['de_results'],\n",
       "   'output': ['significant_genes.csv']},\n",
       "  {'name': 'Generate MA Plot',\n",
       "   'description': 'Create an MA plot to visualize the differentially expressed genes.',\n",
       "   'purpose': 'To provide a visual representation of the change in gene expression across conditions.',\n",
       "   'functions': ['plotMA'],\n",
       "   'input': ['de_results'],\n",
       "   'output': ['ma_plot']},\n",
       "  {'name': 'Generate Volcano Plot',\n",
       "   'description': 'Create a volcano plot to visualize significant genes.',\n",
       "   'purpose': 'To illustrate the significance of differentially expressed genes and their fold changes.',\n",
       "   'functions': ['EnhancedVolcano'],\n",
       "   'input': ['de_results'],\n",
       "   'output': ['volcano_plot']},\n",
       "  {'name': 'Save Final Results and Plots',\n",
       "   'description': 'Export results and visualizations to files for reporting.',\n",
       "   'purpose': 'To ensure that the results are preserved for future reference and sharing with collaborators.',\n",
       "   'functions': ['write_csv', 'ggsave'],\n",
       "   'input': ['significant_genes.csv', 'ma_plot', 'volcano_plot'],\n",
       "   'output': ['final_results_summary']}]}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Steps(BaseModel):\n",
    "    name: str = Field(description = \"A simple, descriptive name of the step to be performed\")\n",
    "    description: str = Field(description=\"Description of the step to be performed\")\n",
    "    purpose: str = Field(description=\"Justification of why step is needed\")\n",
    "    functions: list[str] = Field(description = \"R functions required for this step\")\n",
    "    input: list[str] = Field(description = \"List of required input files\")\n",
    "    output: list[str] = Field(description = \"List of output files\")\n",
    "\n",
    "class Pipeline(BaseModel):\n",
    "    pipeline: list[Steps]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "### IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert bioinformatician, who meticulously and carefully plans computational RNAseq experiments. \n",
    "\n",
    "You have been asked to provide a basic analysis pipeline which can be used to analyse quantification data generated from Kallisto. \n",
    "\n",
    "Take a deep breath, and carefully take note of the requirements outlined below to achieve the best possible outcome.\n",
    "\n",
    "### PIPELINE REQUIREMENTS\n",
    "\n",
    "1. Keep in mind that the pipeline will have the following available inputs: Kallisto abundance files, sample metadata\n",
    "2. Your pipeline should be based in R\n",
    "3. Avoid installing unnecessary packages. Packages such as tidyverse, limma, edgeR, tximport, and DESeq2 are permitted.\n",
    "4. Your pipeline should incorporate analysis steps, validation steps (e.g. checking inputs/outputs), and also quality control steps\n",
    "5. The final output should be related to differentially expressed genes\n",
    "6. The pipeline should be constructed in a logical order, taking into consideration the expected inputs and outputs of each stage\n",
    "7. The starting point of the pipeline will be the input Kallisto abudance files\n",
    "8. Specify the functions that will be used at each ste\n",
    "\n",
    "### OUTPUT\n",
    "\n",
    "1. Construct a list of sequential steps to perform the RNAseq analysis\n",
    "2. Each step should achieve a single goal\n",
    "3. Specify the expected input and output of each stage\n",
    "4. Specify the functions that will be used at each step, but you do not need to include any parameters (e.g. specify \"write_csv\" rather than \"write_csv(x, file = \"test.csv')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.beta.chat.completions.parse(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=Pipeline\n",
    ")\n",
    "result = chat_completion.choices[0].message.parsed\n",
    "result.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ce3c81d5-3377-4eb3-a420-d37644273f11",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9zELI9BtD5ey4VnhNnmTecSRM01tY',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': '{\"all_assessments\":[{\"name\":\"Load Required Libraries\",\"code_eval\":\"The functions \\'library\\' and \\'suppressPackageStartupMessages\\' exist in R and are commonly used for loading libraries and suppressing messages. Both functions are correctly named and structured.\",\"pipeline_eval\":\"Very necessary step as loading libraries is crucial for the analysis to proceed without errors.\",\"step_eval\":\"Yes\"},{\"name\":\"Load Metadata\",\"code_eval\":\"Functions \\'read.csv\\' and \\'glimpse\\' exist and are correctly referenced. They perform the tasks of reading a CSV file and glancing at the data structure, respectively.\",\"pipeline_eval\":\"Necessary for importing sample information which is essential for subsequent analyses.\",\"step_eval\":\"Yes\"},{\"name\":\"Load Kallisto Abundance Files\",\"code_eval\":\"Functions \\'list.files\\' and \\'read_tsv\\' are valid R functions. \\'list.files\\' helps in getting the list of files, and \\'read_tsv\\' is suitable for reading tab-separated values from files.\",\"pipeline_eval\":\"Important step since it aggregates quantification data from Kallisto outputs, which is central for the analysis.\",\"step_eval\":\"Yes\"},{\"name\":\"Combine Abundance Data\",\"code_eval\":\"Functions \\'tximport\\' and \\'as.data.frame\\' are correctly referred to and exist. \\'tximport\\' is used for importing transcript quantification data and \\'as.data.frame\\' is appropriate for converting data into an R data frame.\",\"pipeline_eval\":\"Crucial for creating a unified dataset necessary for downstream analyses.\",\"step_eval\":\"Yes\"},{\"name\":\"Quality Control - PCA Plot\",\"code_eval\":\"Functions \\'prcomp\\' and \\'ggplot\\' are valid. \\'prcomp\\' for PCA analysis and \\'ggplot\\' for visualization are appropriately named and commonly accepted.\",\"pipeline_eval\":\"Significant for checking sample clustering and outlier detection, ensuring data quality before further steps.\",\"step_eval\":\"Yes\"},{\"name\":\"Model Design\",\"code_eval\":\"The function \\'model.matrix\\' is appropriately referenced. It is used to create design matrices in R for statistical modeling.\",\"pipeline_eval\":\"Essential for setting up the framework for differential expression analysis based on experimental design.\",\"step_eval\":\"Yes\"},{\"name\":\"Count Data Normalization\",\"code_eval\":\"The function \\'normalizeBetweenArrays\\' is correctly named but it may not be directly applicable for count data; typically \\'DESeq2::estimateSizeFactors\\' could be used for normalization of count data.\",\"pipeline_eval\":\"Necessary step; however, the function’s appropriateness needs clarification.\",\"step_eval\":\"No\"},{\"name\":\"Differential Expression Analysis\",\"code_eval\":\"Functions \\'DESeq\\' and \\'results\\' are correctly named and part of the DESeq2 package used for differential expression analysis.\",\"pipeline_eval\":\"Absolutely required for discovering differentially expressed genes across conditions, a core aspect of RNA-seq pipeline.\",\"step_eval\":\"Yes\"},{\"name\":\"Extract Significant Genes\",\"code_eval\":\"Functions \\'filter\\' and \\'write_csv\\' are correctly referenced. Both functions exist and serve the purpose of subsetting data and exporting CSV files, respectively.\",\"pipeline_eval\":\"Necessary to focus on biologically relevant genes post-analysis, ensuring meaningful interpretations.\",\"step_eval\":\"Yes\"},{\"name\":\"Generate MA Plot\",\"code_eval\":\"The function \\'plotMA\\' is correctly named and exists for generating MA plots from DE analysis results.\",\"pipeline_eval\":\"Important for visual representation of expression changes, thus supporting analysis conclusions.\",\"step_eval\":\"Yes\"},{\"name\":\"Generate Volcano Plot\",\"code_eval\":\"The function \\'EnhancedVolcano\\' requires confirmation of correct spelling and existence; if intended as a package, it should be prefixed with the library name (e.g. \\'EnhancedVolcano::EnhancedVolcano\\').\",\"pipeline_eval\":\"Useful for illustrating significance and fold changes of differentially expressed genes, complementing the MA plot.\",\"step_eval\":\"No\"},{\"name\":\"Save Final Results and Plots\",\"code_eval\":\"Functions \\'write_csv\\' and \\'ggsave\\' exist and appropriately serve for exporting data and visualizations.\",\"pipeline_eval\":\"Large necessity for preserving analysis outputs for future references and sharing.\",\"step_eval\":\"Yes\"}],\"overall_eval\":\"No\"}',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'function_call': None,\n",
       "    'tool_calls': [],\n",
       "    'parsed': {'all_assessments': [{'name': 'Load Required Libraries',\n",
       "       'code_eval': \"The functions 'library' and 'suppressPackageStartupMessages' exist in R and are commonly used for loading libraries and suppressing messages. Both functions are correctly named and structured.\",\n",
       "       'pipeline_eval': 'Very necessary step as loading libraries is crucial for the analysis to proceed without errors.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Load Metadata',\n",
       "       'code_eval': \"Functions 'read.csv' and 'glimpse' exist and are correctly referenced. They perform the tasks of reading a CSV file and glancing at the data structure, respectively.\",\n",
       "       'pipeline_eval': 'Necessary for importing sample information which is essential for subsequent analyses.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Load Kallisto Abundance Files',\n",
       "       'code_eval': \"Functions 'list.files' and 'read_tsv' are valid R functions. 'list.files' helps in getting the list of files, and 'read_tsv' is suitable for reading tab-separated values from files.\",\n",
       "       'pipeline_eval': 'Important step since it aggregates quantification data from Kallisto outputs, which is central for the analysis.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Combine Abundance Data',\n",
       "       'code_eval': \"Functions 'tximport' and 'as.data.frame' are correctly referred to and exist. 'tximport' is used for importing transcript quantification data and 'as.data.frame' is appropriate for converting data into an R data frame.\",\n",
       "       'pipeline_eval': 'Crucial for creating a unified dataset necessary for downstream analyses.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Quality Control - PCA Plot',\n",
       "       'code_eval': \"Functions 'prcomp' and 'ggplot' are valid. 'prcomp' for PCA analysis and 'ggplot' for visualization are appropriately named and commonly accepted.\",\n",
       "       'pipeline_eval': 'Significant for checking sample clustering and outlier detection, ensuring data quality before further steps.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Model Design',\n",
       "       'code_eval': \"The function 'model.matrix' is appropriately referenced. It is used to create design matrices in R for statistical modeling.\",\n",
       "       'pipeline_eval': 'Essential for setting up the framework for differential expression analysis based on experimental design.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Count Data Normalization',\n",
       "       'code_eval': \"The function 'normalizeBetweenArrays' is correctly named but it may not be directly applicable for count data; typically 'DESeq2::estimateSizeFactors' could be used for normalization of count data.\",\n",
       "       'pipeline_eval': 'Necessary step; however, the function’s appropriateness needs clarification.',\n",
       "       'step_eval': 'No'},\n",
       "      {'name': 'Differential Expression Analysis',\n",
       "       'code_eval': \"Functions 'DESeq' and 'results' are correctly named and part of the DESeq2 package used for differential expression analysis.\",\n",
       "       'pipeline_eval': 'Absolutely required for discovering differentially expressed genes across conditions, a core aspect of RNA-seq pipeline.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Extract Significant Genes',\n",
       "       'code_eval': \"Functions 'filter' and 'write_csv' are correctly referenced. Both functions exist and serve the purpose of subsetting data and exporting CSV files, respectively.\",\n",
       "       'pipeline_eval': 'Necessary to focus on biologically relevant genes post-analysis, ensuring meaningful interpretations.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Generate MA Plot',\n",
       "       'code_eval': \"The function 'plotMA' is correctly named and exists for generating MA plots from DE analysis results.\",\n",
       "       'pipeline_eval': 'Important for visual representation of expression changes, thus supporting analysis conclusions.',\n",
       "       'step_eval': 'Yes'},\n",
       "      {'name': 'Generate Volcano Plot',\n",
       "       'code_eval': \"The function 'EnhancedVolcano' requires confirmation of correct spelling and existence; if intended as a package, it should be prefixed with the library name (e.g. 'EnhancedVolcano::EnhancedVolcano').\",\n",
       "       'pipeline_eval': 'Useful for illustrating significance and fold changes of differentially expressed genes, complementing the MA plot.',\n",
       "       'step_eval': 'No'},\n",
       "      {'name': 'Save Final Results and Plots',\n",
       "       'code_eval': \"Functions 'write_csv' and 'ggsave' exist and appropriately serve for exporting data and visualizations.\",\n",
       "       'pipeline_eval': 'Large necessity for preserving analysis outputs for future references and sharing.',\n",
       "       'step_eval': 'Yes'}],\n",
       "     'overall_eval': 'No'}}}],\n",
       " 'created': 1724380168,\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': 'fp_507c9469a1',\n",
       " 'usage': {'completion_tokens': 815,\n",
       "  'prompt_tokens': 1165,\n",
       "  'total_tokens': 1980}}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is where I will include the initial plan for an evaluation framework - the goal is just to evaluate whether the proposed pipeline looks reasonable\n",
    "\n",
    "# A quick glance at the JSON makes it seem... ok...?\n",
    "\n",
    "class StepAssessment(BaseModel):\n",
    "    name: str = Field(description = \"A simple, descriptive name of the step to be performed\")\n",
    "    code_eval: str = Field(description=\"Evaluation of if the proposed code is likely to work\")\n",
    "    pipeline_eval: str = Field(description=\"Evaluation of if the proposed step is useful in the context of the pipeline\")\n",
    "    step_eval: Literal[\"Yes\", \"No\"] = Field(description=\"Yes if the step is ok, No if the step needs improvements/changes, or was missing from the input pipeline\")\n",
    "\n",
    "\n",
    "class OverallAssessment(BaseModel):\n",
    "    all_assessments: list[StepAssessment]\n",
    "    overall_eval: Literal[\"Yes\", \"No\"] = Field(description=\"Yes if all steps in the pipeline are ok, No if any step needs improvements/changes, or was missing from the input pipeline\")\n",
    "\n",
    "### TEMPORARY NOTE THAT I WILL HOPEFULLY REMEMBER TO LOOK AT \n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "# .... kek, I forgot what I wanted to make a tempo\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "### IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert bioinformatician, who meticulously and carefully plans computational RNAseq experiments. \n",
    "\n",
    "You have been asked to evaluate a basic analysis pipeline which can be used to analyse quantification data generated from Kallisto. \n",
    "\n",
    "Take a deep breath, and carefully take note of the steps outlined below to achieve the best possible outcome.\n",
    "\n",
    "### STEPS\n",
    "\n",
    "1. Evaluate each proposed step in the pipeline, taking into consideration\n",
    "a) The accuracy of the proposed functions \n",
    "- Assess the general structure of the code, and double check the existence of any proposed functions and libraries\n",
    "- Pay special attention to capitalization, correct use of underscores/periods in functions, and whether or not the function exists\n",
    "- There may be placeholder values in the proposed code - do not assess these as incorrect\n",
    "- The original instruction was simply to list the name of the function - this is your main focus, rather than the parameters within the function\n",
    "b) The necessity and value of each step of the code\n",
    "c) The simplicity of each code\n",
    "d) Whether the code follows commonly accepted guidelines\n",
    "2. If possible improvements can be made in any of the above factors, make these suggestions to individual steps\n",
    "3. If there appears to be steps missing, generate additional steps. Mark these additional steps as \"not\" passing the step evaluation.\n",
    "4. If and only if all steps pass the evaluation, mark the overall pipeline as \"Yes\".\n",
    "\n",
    "### OUTPUT\n",
    "\n",
    "1. Return a JSON of a list of evaluations\n",
    "2. One evaluation should be made for each step\n",
    "3. Each step should achieve a single goal\n",
    "\n",
    "### INPUT PIPELINE\n",
    "\n",
    "{result.dict()}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pipeline_eval = client.beta.chat.completions.parse(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=OverallAssessment\n",
    ")\n",
    "pipeline_eval.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "16030bd9-82bd-4c05-a69a-cc2706e2dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StepAssessment(name='Load Kallisto Abundance Files', code_eval=\"Functions 'list.files' and 'read_tsv' are valid R functions. 'list.files' helps in getting the list of files, and 'read_tsv' is suitable for reading tab-separated values from files.\", pipeline_eval='Important step since it aggregates quantification data from Kallisto outputs, which is central for the analysis.', step_eval='Yes')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_eval.choices[0].message.parsed.all_assessments[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a171242b-ac23-4ed2-9516-af185ea8b77f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1:\n",
      "\n",
      "Proposed Pipeline:\n",
      "{'pipeline': [{'name': 'Load Required Libraries', 'description': 'Load necessary R packages for the analysis.', 'purpose': 'To ensure that all required functions from specified packages are available for use in the pipeline.', 'functions': ['library', 'require'], 'input': [], 'output': []}, {'name': 'Load Sample Metadata', 'description': 'Import sample metadata for the analysis.', 'purpose': 'Sample metadata is needed to associate sample information with Kallisto abundance files for downstream analysis.', 'functions': ['read.csv'], 'input': ['sample_metadata.csv'], 'output': ['metadata']}, {'name': 'Load Kallisto Abundance Files', 'description': 'Import Kallisto abundance files using tximport.', 'purpose': 'To read the Kallisto output files into R to prepare for differential expression analysis.', 'functions': ['tximport'], 'input': ['kallisto_abundance_files'], 'output': ['txi_kallisto']}, {'name': 'Validate Inputs', 'description': 'Check the integrity of the imported abundance data and metadata.', 'purpose': 'To ensure that the data loaded correctly and that the sample sizes match, preventing downstream errors.', 'functions': ['all.equal', 'stop'], 'input': ['txi_kallisto', 'metadata'], 'output': []}, {'name': 'Preprocess Count Data', 'description': 'Transform Kallisto counts to a counts matrix suitable for differential analysis.', 'purpose': 'To prepare the data for analysis by creating a counts matrix from the Kallisto results.', 'functions': ['as.data.frame'], 'input': ['txi_kallisto'], 'output': ['counts_matrix']}, {'name': 'Quality Control of Count Data', 'description': 'Ensure that the count data is appropriate for analysis by looking at distribution.', 'purpose': 'To visualize and check the quality of the count data before analysis.', 'functions': ['boxplot', 'hist'], 'input': ['counts_matrix'], 'output': []}, {'name': 'Normalize Count Data', 'description': \"Normalize the counts using DESeq2's normalization method.\", 'purpose': 'To adjust for differences in sequencing depth and RNA composition between samples.', 'functions': ['DESeqDataSet', 'estimateSizeFactors'], 'input': ['counts_matrix', 'metadata'], 'output': ['dds']}, {'name': 'Differential Expression Analysis', 'description': 'Perform differential expression analysis using DESeq2.', 'purpose': 'To identify genes that are differentially expressed between conditions or treatments.', 'functions': ['DESeq', 'results'], 'input': ['dds'], 'output': ['de_results']}, {'name': 'Results Filtering', 'description': 'Filter the differential expression results for significance based on adjusted p-value and log-fold change.', 'purpose': 'To focus on biologically meaningful results by filtering out non-significant genes.', 'functions': ['subset'], 'input': ['de_results'], 'output': ['de_results_filtered']}, {'name': 'Generate MA Plot', 'description': 'Create an MA plot for visualizing differential expression results.', 'purpose': 'To provide a visual summary of differentially expressed genes to aid interpretation of results.', 'functions': ['plotMA'], 'input': ['de_results_filtered'], 'output': []}, {'name': 'Export Results', 'description': 'Write the significant differential expression results to a file for further analysis or reporting.', 'purpose': 'To save the results in a format that can be used in presentations or further analysis.', 'functions': ['write.csv'], 'input': ['de_results_filtered'], 'output': ['differential_expression_results.csv']}]}\n",
      "\n",
      "Pipeline Evaluation:\n",
      "{'id': 'chatcmpl-9zEwPTK4nvtpMUJ5ehMvT1USTcqhi', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': '{\"all_assessments\":[{\"name\":\"Load Required Libraries\",\"code_eval\":\"The functions \\'library\\' and \\'require\\' both exist in R and are used correctly.\",\"pipeline_eval\":\"Loading libraries is necessary as it ensures that the required functions are available for the rest of the pipeline.\",\"step_eval\":\"Yes\"},{\"name\":\"Load Sample Metadata\",\"code_eval\":\"The function \\'read.csv\\' is a valid function in R for reading CSV files.\",\"pipeline_eval\":\"Importing sample metadata is essential to associate sample information with Kallisto output files for analysis.\",\"step_eval\":\"Yes\"},{\"name\":\"Load Kallisto Abundance Files\",\"code_eval\":\"The function \\'tximport\\' is correctly referenced; however, it is typically a function call and might need an additional function to execute it (e.g., \\'tximport()\\').\",\"pipeline_eval\":\"Loading Kallisto abundance files is crucial for preparing data for differential expression analysis.\",\"step_eval\":\"No\"},{\"name\":\"Validate Inputs\",\"code_eval\":\"The functions \\'all.equal\\' and \\'stop\\' are valid, but \\'all.equal\\' should be used for comparison and \\'stop\\' should be conditioned appropriately to prevent errors if comparisons fail.\",\"pipeline_eval\":\"Validating the integrity of input data is important to prevent downstream errors.\",\"step_eval\":\"No\"},{\"name\":\"Preprocess Count Data\",\"code_eval\":\"The function \\'as.data.frame\\' does exist in R and is appropriately used to convert Kallisto output into a data frame.\",\"pipeline_eval\":\"Preprocessing to create a counts matrix is necessary for subsequent analysis.\",\"step_eval\":\"Yes\"},{\"name\":\"Quality Control of Count Data\",\"code_eval\":\"The functions \\'boxplot\\' and \\'hist\\' exist in R for visualizing data distributions.\",\"pipeline_eval\":\"Quality control is important to ensure the appropriateness of the count data for analysis.\",\"step_eval\":\"Yes\"},{\"name\":\"Normalize Count Data\",\"code_eval\":\"The functions \\'DESeqDataSet\\' and \\'estimateSizeFactors\\' are valid but require correct object initialization and usage context with DESeq2.\",\"pipeline_eval\":\"Normalization is crucial to account for sequencing depth and RNA composition differences between samples.\",\"step_eval\":\"No\"},{\"name\":\"Differential Expression Analysis\",\"code_eval\":\"The functions \\'DESeq\\' and \\'results\\' are valid and commonly used in DESeq2 for differential expression analysis.\",\"pipeline_eval\":\"Performing differential expression analysis is key to identifying significant genes across conditions.\",\"step_eval\":\"Yes\"},{\"name\":\"Results Filtering\",\"code_eval\":\"The function \\'subset\\' exists, but its usage should consider the appropriate filtering conditions for significance.\",\"pipeline_eval\":\"Filtering results is necessary to focus on biologically significant expressions detected.\",\"step_eval\":\"Yes\"},{\"name\":\"Generate MA Plot\",\"code_eval\":\"The function \\'plotMA\\' is valid and appropriate for visualizing differential expression results in R.\",\"pipeline_eval\":\"Creating visual summaries of differential expression results is beneficial for result interpretation.\",\"step_eval\":\"Yes\"},{\"name\":\"Export Results\",\"code_eval\":\"The function \\'write.csv\\' is valid for exporting results to a CSV file.\",\"pipeline_eval\":\"Exporting results is necessary for documentation and further analysis beyond the R environment.\",\"step_eval\":\"Yes\"}],\"any_missing_res\":\"Yes\",\"any_missing_justification\":\"Steps for input validation and normalization have inaccuracies that could lead to potential errors, and proper function calls need to be formatted correctly.\",\"overall_eval\":\"No\"}', 'refusal': None, 'role': 'assistant', 'function_call': None, 'tool_calls': [], 'parsed': {'all_assessments': [{'name': 'Load Required Libraries', 'code_eval': \"The functions 'library' and 'require' both exist in R and are used correctly.\", 'pipeline_eval': 'Loading libraries is necessary as it ensures that the required functions are available for the rest of the pipeline.', 'step_eval': 'Yes'}, {'name': 'Load Sample Metadata', 'code_eval': \"The function 'read.csv' is a valid function in R for reading CSV files.\", 'pipeline_eval': 'Importing sample metadata is essential to associate sample information with Kallisto output files for analysis.', 'step_eval': 'Yes'}, {'name': 'Load Kallisto Abundance Files', 'code_eval': \"The function 'tximport' is correctly referenced; however, it is typically a function call and might need an additional function to execute it (e.g., 'tximport()').\", 'pipeline_eval': 'Loading Kallisto abundance files is crucial for preparing data for differential expression analysis.', 'step_eval': 'No'}, {'name': 'Validate Inputs', 'code_eval': \"The functions 'all.equal' and 'stop' are valid, but 'all.equal' should be used for comparison and 'stop' should be conditioned appropriately to prevent errors if comparisons fail.\", 'pipeline_eval': 'Validating the integrity of input data is important to prevent downstream errors.', 'step_eval': 'No'}, {'name': 'Preprocess Count Data', 'code_eval': \"The function 'as.data.frame' does exist in R and is appropriately used to convert Kallisto output into a data frame.\", 'pipeline_eval': 'Preprocessing to create a counts matrix is necessary for subsequent analysis.', 'step_eval': 'Yes'}, {'name': 'Quality Control of Count Data', 'code_eval': \"The functions 'boxplot' and 'hist' exist in R for visualizing data distributions.\", 'pipeline_eval': 'Quality control is important to ensure the appropriateness of the count data for analysis.', 'step_eval': 'Yes'}, {'name': 'Normalize Count Data', 'code_eval': \"The functions 'DESeqDataSet' and 'estimateSizeFactors' are valid but require correct object initialization and usage context with DESeq2.\", 'pipeline_eval': 'Normalization is crucial to account for sequencing depth and RNA composition differences between samples.', 'step_eval': 'No'}, {'name': 'Differential Expression Analysis', 'code_eval': \"The functions 'DESeq' and 'results' are valid and commonly used in DESeq2 for differential expression analysis.\", 'pipeline_eval': 'Performing differential expression analysis is key to identifying significant genes across conditions.', 'step_eval': 'Yes'}, {'name': 'Results Filtering', 'code_eval': \"The function 'subset' exists, but its usage should consider the appropriate filtering conditions for significance.\", 'pipeline_eval': 'Filtering results is necessary to focus on biologically significant expressions detected.', 'step_eval': 'Yes'}, {'name': 'Generate MA Plot', 'code_eval': \"The function 'plotMA' is valid and appropriate for visualizing differential expression results in R.\", 'pipeline_eval': 'Creating visual summaries of differential expression results is beneficial for result interpretation.', 'step_eval': 'Yes'}, {'name': 'Export Results', 'code_eval': \"The function 'write.csv' is valid for exporting results to a CSV file.\", 'pipeline_eval': 'Exporting results is necessary for documentation and further analysis beyond the R environment.', 'step_eval': 'Yes'}], 'any_missing_res': 'Yes', 'any_missing_justification': 'Steps for input validation and normalization have inaccuracies that could lead to potential errors, and proper function calls need to be formatted correctly.', 'overall_eval': 'No'}}}], 'created': 1724382469, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_48196bc67a', 'usage': {'completion_tokens': 672, 'prompt_tokens': 1102, 'total_tokens': 1774}}\n",
      "\n",
      "Pipeline needs improvement. Rewriting with feedback...\n",
      "\n",
      "Iteration 2:\n",
      "\n",
      "Proposed Pipeline:\n",
      "{'pipeline': [{'name': 'Load Required Libraries', 'description': 'Load necessary R packages for the analysis pipeline.', 'purpose': 'Ensure that all required functions from the specified packages are available for analysis steps.', 'functions': ['library', 'require'], 'input': [], 'output': []}, {'name': 'Load Sample Metadata', 'description': 'Import a CSV file containing sample metadata.', 'purpose': 'Associate sample specific information with Kallisto outputs for analysis context.', 'functions': ['read.csv'], 'input': ['sample_metadata.csv'], 'output': ['metaData']}, {'name': 'Load Kallisto Abundance Files', 'description': 'Use the tximport function to load Kallisto abundance files into R.', 'purpose': 'Prepare the Kallisto output for downstream analysis.', 'functions': ['tximport'], 'input': ['kallisto_abundance_files'], 'output': ['kallisto_data']}, {'name': 'Validate Inputs', 'description': 'Check for integrity and compatibility of input files and data structures.', 'purpose': 'Prevent downstream analysis errors by ensuring inputs are as expected.', 'functions': ['all.equal', 'stop'], 'input': ['metaData', 'kallisto_data'], 'output': []}, {'name': 'Preprocess Count Data', 'description': 'Convert Kallisto output into a suitable counts matrix for further analysis.', 'purpose': 'Prepare and structure count data for the analysis process.', 'functions': ['as.data.frame'], 'input': ['kallisto_data'], 'output': ['countData']}, {'name': 'Quality Control of Count Data', 'description': 'Generate visualizations of the count data to assess data quality.', 'purpose': 'Identify any anomalies or issues within the count data before analysis.', 'functions': ['boxplot', 'hist'], 'input': ['countData'], 'output': []}, {'name': 'Normalize Count Data', 'description': 'Create a DESeqDataSet object and normalize the count data.', 'purpose': 'Adjust the data to account for differences in sequencing depth between samples.', 'functions': ['DESeqDataSet', 'estimateSizeFactors'], 'input': ['countData', 'metaData'], 'output': ['normalizedCounts']}, {'name': 'Differential Expression Analysis', 'description': 'Perform differential expression analysis using DESeq2 functions.', 'purpose': 'Identify significantly differentially expressed genes between conditions.', 'functions': ['DESeq', 'results'], 'input': ['normalizedCounts'], 'output': ['deResults']}, {'name': 'Results Filtering', 'description': 'Filter the results based on significance criteria (i.e. p-value and log2 fold change).', 'purpose': 'Focus on biologically relevant results for downstream analysis.', 'functions': ['subset'], 'input': ['deResults'], 'output': ['filteredResults']}, {'name': 'Generate MA Plot', 'description': 'Create an MA plot to visually summarize the differential expression results.', 'purpose': 'Provide an intuitive visualization for interpreting differential expression data.', 'functions': ['plotMA'], 'input': ['filteredResults'], 'output': ['maPlot']}, {'name': 'Export Results', 'description': 'Export the filtered differential expression results to a CSV file.', 'purpose': 'Facilitate downstream analysis or documentation by saving the results to a file.', 'functions': ['write.csv'], 'input': ['filteredResults'], 'output': ['differential_expression_results.csv']}]}\n",
      "\n",
      "Pipeline Evaluation:\n",
      "{'id': 'chatcmpl-9zEwm3PZ08Mwzn4tXWJHEdUlWQhHV', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': '{\"all_assessments\":[{\"name\":\"Load Required Libraries\",\"code_eval\":\"The function \\'library\\' is correctly spelled, and \\'require\\' is also valid but less commonly used in this context. No issues with capitalization or structure.\",\"pipeline_eval\":\"This step is necessary to ensure required packages are available for subsequent steps.\",\"step_eval\":\"Yes\"},{\"name\":\"Load Sample Metadata\",\"code_eval\":\"The function \\'read.csv\\' is correctly spelled and valid for reading CSV files.\",\"pipeline_eval\":\"This step is essential to associate metadata with Kallisto outputs.\",\"step_eval\":\"Yes\"},{\"name\":\"Load Kallisto Abundance Files\",\"code_eval\":\"The proposed function \\'tximport\\' is valid, provided the \\'tximport\\' package is loaded.\",\"pipeline_eval\":\"Loading Kallisto outputs is critical for downstream analysis.\",\"step_eval\":\"Yes\"},{\"name\":\"Validate Inputs\",\"code_eval\":\"Both \\'all.equal\\' and \\'stop\\' are valid functions. However, their usage should ensure both data structures are compatible and can trigger an error if validation fails.\",\"pipeline_eval\":\"This step is crucial to prevent downstream errors due to invalid inputs.\",\"step_eval\":\"Yes\"},{\"name\":\"Preprocess Count Data\",\"code_eval\":\"The function \\'as.data.frame\\' is correctly spelled and valid, but actually needs to be applied correctly to the output of \\'tximport\\'.\",\"pipeline_eval\":\"Preprocessing count data is necessary for further analysis steps.\",\"step_eval\":\"Yes\"},{\"name\":\"Quality Control of Count Data\",\"code_eval\":\"The functions \\'boxplot\\' and \\'hist\\' are correctly spelled and valid for creating visualizations.\",\"pipeline_eval\":\"Quality control is extremely important to assess data integrity before proceeding.\",\"step_eval\":\"Yes\"},{\"name\":\"Normalize Count Data\",\"code_eval\":\"The functions \\'DESeqDataSet\\' and \\'estimateSizeFactors\\' should be checked for correct usage, but both are valid constructions if DESeq2 is loaded.\",\"pipeline_eval\":\"Normalizing the count data is critical for accurate differential expression analysis.\",\"step_eval\":\"Yes\"},{\"name\":\"Differential Expression Analysis\",\"code_eval\":\"The functions \\'DESeq\\' and \\'results\\' are valid, assuming DESeq2 is properly installed and loaded.\",\"pipeline_eval\":\"This is a key step for identifying significant gene expression differences.\",\"step_eval\":\"Yes\"},{\"name\":\"Results Filtering\",\"code_eval\":\"The function \\'subset\\' is correctly spelled and valid for filtering datasets.\",\"pipeline_eval\":\"This step is necessary to focus on biologically relevant results.\",\"step_eval\":\"Yes\"},{\"name\":\"Generate MA Plot\",\"code_eval\":\"The function \\'plotMA\\' is correctly spelled and valid if using DESeq2 results.\",\"pipeline_eval\":\"Visualizing differential expression results is valuable for interpretation.\",\"step_eval\":\"Yes\"},{\"name\":\"Export Results\",\"code_eval\":\"The function \\'write.csv\\' is correctly spelled and valid for exporting data to a CSV file.\",\"pipeline_eval\":\"This step is essential for documentation and sharing results.\",\"step_eval\":\"Yes\"}],\"any_missing_res\":\"No\",\"any_missing_justification\":\"\",\"overall_eval\":\"Yes\"}', 'refusal': None, 'role': 'assistant', 'function_call': None, 'tool_calls': [], 'parsed': {'all_assessments': [{'name': 'Load Required Libraries', 'code_eval': \"The function 'library' is correctly spelled, and 'require' is also valid but less commonly used in this context. No issues with capitalization or structure.\", 'pipeline_eval': 'This step is necessary to ensure required packages are available for subsequent steps.', 'step_eval': 'Yes'}, {'name': 'Load Sample Metadata', 'code_eval': \"The function 'read.csv' is correctly spelled and valid for reading CSV files.\", 'pipeline_eval': 'This step is essential to associate metadata with Kallisto outputs.', 'step_eval': 'Yes'}, {'name': 'Load Kallisto Abundance Files', 'code_eval': \"The proposed function 'tximport' is valid, provided the 'tximport' package is loaded.\", 'pipeline_eval': 'Loading Kallisto outputs is critical for downstream analysis.', 'step_eval': 'Yes'}, {'name': 'Validate Inputs', 'code_eval': \"Both 'all.equal' and 'stop' are valid functions. However, their usage should ensure both data structures are compatible and can trigger an error if validation fails.\", 'pipeline_eval': 'This step is crucial to prevent downstream errors due to invalid inputs.', 'step_eval': 'Yes'}, {'name': 'Preprocess Count Data', 'code_eval': \"The function 'as.data.frame' is correctly spelled and valid, but actually needs to be applied correctly to the output of 'tximport'.\", 'pipeline_eval': 'Preprocessing count data is necessary for further analysis steps.', 'step_eval': 'Yes'}, {'name': 'Quality Control of Count Data', 'code_eval': \"The functions 'boxplot' and 'hist' are correctly spelled and valid for creating visualizations.\", 'pipeline_eval': 'Quality control is extremely important to assess data integrity before proceeding.', 'step_eval': 'Yes'}, {'name': 'Normalize Count Data', 'code_eval': \"The functions 'DESeqDataSet' and 'estimateSizeFactors' should be checked for correct usage, but both are valid constructions if DESeq2 is loaded.\", 'pipeline_eval': 'Normalizing the count data is critical for accurate differential expression analysis.', 'step_eval': 'Yes'}, {'name': 'Differential Expression Analysis', 'code_eval': \"The functions 'DESeq' and 'results' are valid, assuming DESeq2 is properly installed and loaded.\", 'pipeline_eval': 'This is a key step for identifying significant gene expression differences.', 'step_eval': 'Yes'}, {'name': 'Results Filtering', 'code_eval': \"The function 'subset' is correctly spelled and valid for filtering datasets.\", 'pipeline_eval': 'This step is necessary to focus on biologically relevant results.', 'step_eval': 'Yes'}, {'name': 'Generate MA Plot', 'code_eval': \"The function 'plotMA' is correctly spelled and valid if using DESeq2 results.\", 'pipeline_eval': 'Visualizing differential expression results is valuable for interpretation.', 'step_eval': 'Yes'}, {'name': 'Export Results', 'code_eval': \"The function 'write.csv' is correctly spelled and valid for exporting data to a CSV file.\", 'pipeline_eval': 'This step is essential for documentation and sharing results.', 'step_eval': 'Yes'}], 'any_missing_res': 'No', 'any_missing_justification': '', 'overall_eval': 'Yes'}}}], 'created': 1724382492, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_48196bc67a', 'usage': {'completion_tokens': 604, 'prompt_tokens': 1066, 'total_tokens': 1670}}\n",
      "\n",
      "Pipeline passed evaluation. Returning final pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Your existing model definitions\n",
    "class Steps(BaseModel):\n",
    "    name: str = Field(description=\"A simple, descriptive name of the step to be performed\")\n",
    "    description: str = Field(description=\"Description of the step to be performed\")\n",
    "    purpose: str = Field(description=\"Justification of why step is needed\")\n",
    "    functions: list[str] = Field(description=\"R functions required for this step\")\n",
    "    input: list[str] = Field(description=\"List of required input files\")\n",
    "    output: list[str] = Field(description=\"List of output files\")\n",
    "\n",
    "class Pipeline(BaseModel):\n",
    "    pipeline: list[Steps]\n",
    "\n",
    "class StepAssessment(BaseModel):\n",
    "    name: str = Field(description=\"A simple, descriptive name of the step to be performed\")\n",
    "    code_eval: str = Field(description=\"Evaluation of if the proposed code is likely to work\")\n",
    "    pipeline_eval: str = Field(description=\"Evaluation of if the proposed step is useful in the context of the pipeline\")\n",
    "    step_eval: Literal[\"Yes\", \"No\"] = Field(description=\"Yes if the step is ok, No if the step needs improvements/changes, or was missing from the input pipeline\")\n",
    "\n",
    "class OverallAssessment(BaseModel):\n",
    "    all_assessments: list[StepAssessment]\n",
    "    any_missing_res: Literal[\"Yes\", \"No\"] = Field(description=\"A yes/no answer as to whether any critical steps are missing\")\n",
    "    any_missing_justification: str = Field(description=\"A description of any steps which are missing in this analysis\")\n",
    "    overall_eval: Literal[\"Yes\", \"No\"] = Field(description=\"Yes if all steps in the pipeline are ok, No if any step needs improvements/changes, or was missing from the input pipeline\")\n",
    "\n",
    "def create_pipeline(feedback=None, pipeline = None):\n",
    "    base_prompt = \"\"\"\n",
    "    ### IDENTITY AND PURPOSE\n",
    "    You are an expert bioinformatician, who meticulously and carefully plans computational RNAseq experiments. \n",
    "    You have been asked to provide a basic analysis pipeline which can be used to analyse quantification data generated from Kallisto. \n",
    "    Take a deep breath, and carefully take note of the requirements outlined below to achieve the best possible outcome.\n",
    "    ### PIPELINE REQUIREMENTS\n",
    "    1. Keep in mind that the pipeline will have the following available inputs: Kallisto abundance files, sample metadata\n",
    "    2. Your pipeline should be based in R\n",
    "    3. Avoid installing unnecessary packages. Packages such as tidyverse, limma, edgeR, tximport, and DESeq2 are permitted.\n",
    "    4. Your pipeline should incorporate analysis steps, validation steps (e.g. checking inputs/outputs), and also quality control steps\n",
    "    5. The final output should be related to differentially expressed genes\n",
    "    6. The pipeline should be constructed in a logical order, taking into consideration the expected inputs and outputs of each stage\n",
    "    7. The starting point of the pipeline will be the input Kallisto abudance files\n",
    "    8. Specify the functions that will be used at each step\n",
    "    ### OUTPUT\n",
    "    1. Construct a list of sequential steps to perform the RNAseq analysis\n",
    "    2. Each step should achieve a single goal\n",
    "    3. Specify the expected input and output of each stage\n",
    "    4. Specify the functions that will be used at each step, but you do not need to include any parameters (e.g. specify \"write_csv\" rather than \"write_csv(x, file = \"test.csv')\n",
    "    \"\"\"\n",
    "    \n",
    "    if feedback:\n",
    "        prompt = base_prompt + f\"\"\"\n",
    "        ### FEEDBACK\n",
    "        The following feedback was given on this pipeline. \n",
    "        \n",
    "        {pipeline}\n",
    "        \n",
    "        Improve the pipeline by integrating this feedback, focussing only on the steps that needed to be improved:\n",
    "        {feedback}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = base_prompt\n",
    "\n",
    "    chat_completion = client.beta.chat.completions.parse(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_format=Pipeline\n",
    "    )\n",
    "    return chat_completion.choices[0].message.parsed\n",
    "\n",
    "def evaluate_pipeline(pipeline):\n",
    "    prompt = f\"\"\"\n",
    "    ### IDENTITY AND PURPOSE\n",
    "    You are an expert bioinformatician, who meticulously and carefully plans computational RNAseq experiments. \n",
    "    You have been asked to evaluate a basic analysis pipeline which can be used to analyse quantification data generated from Kallisto. \n",
    "    Take a deep breath, and carefully take note of the steps outlined below to achieve the best possible outcome.\n",
    "    ### STEPS\n",
    "    1. Evaluate each proposed step in the pipeline, taking into consideration\n",
    "    a) The accuracy of the proposed functions \n",
    "    - Assess the general structure of the code, and double check the existence of any proposed functions and libraries\n",
    "    - Pay special attention to capitalization, correct use of underscores/periods in functions, and whether or not the function exists\n",
    "    - Comment ONLY on if the functions are correct and valid - do not make any comments about parameters. For example, if the proposed function specifies \"write_csv()\", this is ok, as is \"write_csv\". However, \"writeCSV\" is incorrect, as this function does not exist.\n",
    "    b) The necessity and value of each step of the code\n",
    "    c) The simplicity of each code\n",
    "    d) Whether the code follows commonly accepted guidelines\n",
    "    2. If possible improvements can be made in any of the above factors, make these suggestions to individual steps\n",
    "    3. Specify if there appear to be any missing steps, for example if normalisation or filtering is not performed at all.\n",
    "    4. If and only if all steps pass the evaluation, mark the overall pipeline as \"Yes\".\n",
    "    ### OUTPUT\n",
    "    1. Return a JSON of a list of evaluations\n",
    "    2. One evaluation should be made for each step\n",
    "    3. Each step should achieve a single goal\n",
    "    ### INPUT PIPELINE\n",
    "    {pipeline.dict()}\n",
    "    \"\"\"\n",
    "    pipeline_eval = client.beta.chat.completions.parse(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_format=OverallAssessment\n",
    "    )\n",
    "    return pipeline_eval\n",
    "\n",
    "def run_pipeline_creation_and_evaluation(max_iterations=3):\n",
    "    feedback = None\n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"\\nIteration {iteration + 1}:\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = create_pipeline(feedback)\n",
    "        print(\"\\nProposed Pipeline:\")\n",
    "        print(pipeline.dict())\n",
    "        \n",
    "        # Evaluate pipeline\n",
    "        evaluation = evaluate_pipeline(pipeline)\n",
    "        print(\"\\nPipeline Evaluation:\")\n",
    "        print(evaluation.dict())\n",
    "        \n",
    "        # Check if pipeline passes evaluation\n",
    "        if evaluation.choices[0].message.parsed.overall_eval == \"Yes\":\n",
    "            print(\"\\nPipeline passed evaluation. Returning final pipeline.\")\n",
    "            return pipeline\n",
    "        elif iteration < max_iterations - 1:\n",
    "            print(\"\\nPipeline needs improvement. Rewriting with feedback...\")\n",
    "            # Prepare feedback for the next iteration\n",
    "            feedback = \"Evaluation results:\\n\"\n",
    "            for assessment in evaluation.choices[0].message.parsed.all_assessments:\n",
    "                feedback += f\"Step: {assessment.name}\\n\"\n",
    "                feedback += f\"Code evaluation: {assessment.code_eval}\\n\"\n",
    "                feedback += f\"Pipeline evaluation: {assessment.pipeline_eval}\\n\"\n",
    "                feedback += f\"Step evaluation: {assessment.step_eval}\\n\\n\"\n",
    "            feedback += f\"Missing steps: {evaluation.choices[0].message.parsed.any_missing_justification}\\n\\n\"\n",
    "        else:\n",
    "            print(\"\\nMaximum iterations reached. Returning last proposed pipeline.\")\n",
    "            return pipeline\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "final_pipeline = run_pipeline_creation_and_evaluation(max_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2f7adde6-88ec-4017-8923-b958178dd9c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': [{'name': 'Load Required Libraries',\n",
       "   'description': 'Load necessary R packages for the analysis pipeline.',\n",
       "   'purpose': 'Ensure that all required functions from the specified packages are available for analysis steps.',\n",
       "   'functions': ['library', 'require'],\n",
       "   'input': [],\n",
       "   'output': []},\n",
       "  {'name': 'Load Sample Metadata',\n",
       "   'description': 'Import a CSV file containing sample metadata.',\n",
       "   'purpose': 'Associate sample specific information with Kallisto outputs for analysis context.',\n",
       "   'functions': ['read.csv'],\n",
       "   'input': ['sample_metadata.csv'],\n",
       "   'output': ['metaData']},\n",
       "  {'name': 'Load Kallisto Abundance Files',\n",
       "   'description': 'Use the tximport function to load Kallisto abundance files into R.',\n",
       "   'purpose': 'Prepare the Kallisto output for downstream analysis.',\n",
       "   'functions': ['tximport'],\n",
       "   'input': ['kallisto_abundance_files'],\n",
       "   'output': ['kallisto_data']},\n",
       "  {'name': 'Validate Inputs',\n",
       "   'description': 'Check for integrity and compatibility of input files and data structures.',\n",
       "   'purpose': 'Prevent downstream analysis errors by ensuring inputs are as expected.',\n",
       "   'functions': ['all.equal', 'stop'],\n",
       "   'input': ['metaData', 'kallisto_data'],\n",
       "   'output': []},\n",
       "  {'name': 'Preprocess Count Data',\n",
       "   'description': 'Convert Kallisto output into a suitable counts matrix for further analysis.',\n",
       "   'purpose': 'Prepare and structure count data for the analysis process.',\n",
       "   'functions': ['as.data.frame'],\n",
       "   'input': ['kallisto_data'],\n",
       "   'output': ['countData']},\n",
       "  {'name': 'Quality Control of Count Data',\n",
       "   'description': 'Generate visualizations of the count data to assess data quality.',\n",
       "   'purpose': 'Identify any anomalies or issues within the count data before analysis.',\n",
       "   'functions': ['boxplot', 'hist'],\n",
       "   'input': ['countData'],\n",
       "   'output': []},\n",
       "  {'name': 'Normalize Count Data',\n",
       "   'description': 'Create a DESeqDataSet object and normalize the count data.',\n",
       "   'purpose': 'Adjust the data to account for differences in sequencing depth between samples.',\n",
       "   'functions': ['DESeqDataSet', 'estimateSizeFactors'],\n",
       "   'input': ['countData', 'metaData'],\n",
       "   'output': ['normalizedCounts']},\n",
       "  {'name': 'Differential Expression Analysis',\n",
       "   'description': 'Perform differential expression analysis using DESeq2 functions.',\n",
       "   'purpose': 'Identify significantly differentially expressed genes between conditions.',\n",
       "   'functions': ['DESeq', 'results'],\n",
       "   'input': ['normalizedCounts'],\n",
       "   'output': ['deResults']},\n",
       "  {'name': 'Results Filtering',\n",
       "   'description': 'Filter the results based on significance criteria (i.e. p-value and log2 fold change).',\n",
       "   'purpose': 'Focus on biologically relevant results for downstream analysis.',\n",
       "   'functions': ['subset'],\n",
       "   'input': ['deResults'],\n",
       "   'output': ['filteredResults']},\n",
       "  {'name': 'Generate MA Plot',\n",
       "   'description': 'Create an MA plot to visually summarize the differential expression results.',\n",
       "   'purpose': 'Provide an intuitive visualization for interpreting differential expression data.',\n",
       "   'functions': ['plotMA'],\n",
       "   'input': ['filteredResults'],\n",
       "   'output': ['maPlot']},\n",
       "  {'name': 'Export Results',\n",
       "   'description': 'Export the filtered differential expression results to a CSV file.',\n",
       "   'purpose': 'Facilitate downstream analysis or documentation by saving the results to a file.',\n",
       "   'functions': ['write.csv'],\n",
       "   'input': ['filteredResults'],\n",
       "   'output': ['differential_expression_results.csv']}]}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9554b-0d08-4593-9f09-ebe08c86d8ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The above seems to be functional. \n",
    "\n",
    "I think the next steps will be to:\n",
    "- Develop the pipeline from the scaffold\n",
    "- Feed in the metadata, specifying the metadata contrasts that I would want to investigate\n",
    "- Execute the pipeline?\n",
    "\n",
    "I do anticipate having problems "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b116acb-6e89-4a44-a309-0928c913eeac",
   "metadata": {},
   "source": [
    "# The future is now, thanks to science...\n",
    "\n",
    "In other words, this is where I will be using the R scripts I have been creating.\n",
    "\n",
    "I am doing this in two parts - one where I construct the processed DGE object (i.e. after filtering and normalization), and one where I do all the steps after (construction of contrast matrix, DEG analysis. I am anticipating the setup of the contrast matrix to be quite problematic, but all the steps before that point should be quite binary (i.e. there is either a \"correct\" or \"reasonable\" value I am expecting). \n",
    "- This point also acts as a checkpoint - \"did normalization and filtering occur as expected?\"\n",
    "- My initial plan with the contrast matrix was to have the LLM create the code for the contrast matrix, and give it a few examples to work with (just in my head, I don't see this working out too well if I don't give it guidance)\n",
    "- The other benefit of separating these out is I think the Kallisto importing step is the one that takes the longest, yet the one that's most likely to fail (I think) is the construction of the contrast matrix. By saving the intermediate output, I do think it will save me a very appreciable amount of time.\n",
    "\n",
    "We will begin by checking that the script works with a known test case (and I will be using this as a troubleshooting case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "505746a0-93a7-4d0a-a6e5-b1536772105e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script executed successfully.\n",
      "Output:\n",
      " [2024-08-23 07:43:40] Step 1: Loading GEO-SRA mapping data...\n",
      "[2024-08-23 07:43:40] GEO-SRA mapping data loaded.\n",
      "[2024-08-23 07:43:40] Step 2: Loading metadata...\n",
      "[2024-08-23 07:43:40] Original metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1.1\"   \"characteristics_ch1.2\"  \n",
      "[13] \"characteristics_ch1.3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1.1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing.1\"       \"data_processing.2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip/postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation.1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell line:ch1\"           \"cell type:ch1\"          \n",
      "[43] \"genotype:ch1\"            \"treatment:ch1\"          \n",
      "[2024-08-23 07:43:40] Cleaned metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1_1\"   \"characteristics_ch1_2\"  \n",
      "[13] \"characteristics_ch1_3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1_1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing_1\"       \"data_processing_2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip_postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation_1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell_line_ch1\"           \"cell_type_ch1\"          \n",
      "[43] \"genotype_ch1\"            \"treatment_ch1\"          \n",
      "[2024-08-23 07:43:40] Step 3: Cleaning specified columns...\n",
      "[2024-08-23 07:43:40] Columns cleaned:\n",
      "[1] \"genotype_ch1\"\n",
      "[2024-08-23 07:43:40] Step 4: Joining metadata with GEO-SRA mapping data...\n",
      "[2024-08-23 07:43:40] Metadata joined with GEO-SRA mapping data.\n",
      "[2024-08-23 07:43:40] Step 5: Listing abundance files...\n",
      "[2024-08-23 07:43:40] Abundance files found: 12 files\n",
      "[2024-08-23 07:43:40] Metadata updated with abundance file paths.\n",
      "[2024-08-23 07:43:40] Step 6: Loading tx2gene data...\n",
      "[2024-08-23 07:43:41] tx2gene data loaded.\n",
      "[2024-08-23 07:43:41] Step 7: Importing quantification files...\n",
      "[2024-08-23 07:43:46] Quantification files imported.\n",
      "[2024-08-23 07:43:46] Step 8: Creating DGEList object...\n",
      "[2024-08-23 07:43:46] DGEList object created.\n",
      "[2024-08-23 07:43:46] Step 9: Filtering based on expression...\n",
      "[2024-08-23 07:43:46] Filtering complete. Number of genes retained: 87\n",
      "[2024-08-23 07:43:46] Step 10: Plotting filtering results...\n",
      "null device \n",
      "          1 \n",
      "[2024-08-23 07:43:47] Filtering plot saved as Filtering.png.\n",
      "[2024-08-23 07:43:47] Step 11: Normalizing the DGEList object...\n",
      "[2024-08-23 07:43:47] Normalization complete.\n",
      "[2024-08-23 07:43:47] Step 12: Plotting normalization results...\n",
      "null device \n",
      "          1 \n",
      "[2024-08-23 07:43:47] Normalization plot saved as Normalization.png.\n",
      "[2024-08-23 07:43:47] Step 13: Saving the final DGEList object...\n",
      "[2024-08-23 07:43:47] Final DGEList object saved as DGE.RDS.\n",
      "[2024-08-23 07:43:47] Script execution completed successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command = \"Rscript\"\n",
    "script_path = \"./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r\"\n",
    "args = [\n",
    "    \"--directory\", \"/home/myuser/work/data/kallisto_output/\",\n",
    "    \"--t2g\", \"/home/myuser/work/data/kallisto_indices/human/t2g.txt\",\n",
    "    \"--metadata\", \"/home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv\",\n",
    "    \"--clean_columns\", \"genotype_ch1\",\n",
    "    \"--group\", \"genotype_clean\",\n",
    "    \"--output\", \"./TheLLMPlayground/ManualInputs\",\n",
    "    \"--geo_sra_mapping\", \"/home/myuser/work/notebooks/2_extract_data/results.txt\"\n",
    "]\n",
    "\n",
    "# Combine the command and arguments into a single command string\n",
    "cmd = f\"{command} {script_path} {' '.join(shlex.quote(arg) for arg in args)}\"\n",
    "\n",
    "# Execute the command\n",
    "try:\n",
    "    result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    print(\"Script executed successfully.\")\n",
    "    print(\"Output:\\n\", result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"An error occurred while executing the script.\")\n",
    "    print(\"Error message:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c10d16-1312-448f-bab6-4659e7899b7e",
   "metadata": {},
   "source": [
    "Great - this doesn't mean too much, but is a good sanity check that things are working. As it happens, ChatGPT is REALLY helpful with just streamlining something that might otherwise take 30 minutes. \n",
    "\n",
    "Now for the slightly bigger test - how well will this do when I pass it to the LLM?\n",
    "\n",
    "There is also the question of how I'm going to handle the metadata files... I think in the end, I would want to implement it such that it considers the input code that was used to generate these files, and then uses this information to determine what the most appropriate value is. \n",
    "\n",
    "In my initial test cases (just with prompt development and whatnot), I'll hard code this in - I will make a note that these need to be adjusted as I work on a integrated pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f704975e-d995-4f59-b713-d6dfd671e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script executed successfully.\n",
      "Output:\n",
      " [2024-08-26 06:09:08] Step 1: Loading GEO-SRA mapping data...\n",
      "[2024-08-26 06:09:08] GEO-SRA mapping data loaded.\n",
      "[2024-08-26 06:09:08] Step 2: Loading metadata...\n",
      "[2024-08-26 06:09:08] Original metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1.1\"   \"characteristics_ch1.2\"  \n",
      "[13] \"characteristics_ch1.3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1.1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing.1\"       \"data_processing.2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip/postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation.1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell line:ch1\"           \"cell type:ch1\"          \n",
      "[43] \"genotype:ch1\"            \"treatment:ch1\"          \n",
      "[2024-08-26 06:09:08] Cleaned metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1_1\"   \"characteristics_ch1_2\"  \n",
      "[13] \"characteristics_ch1_3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1_1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing_1\"       \"data_processing_2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip_postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation_1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell_line_ch1\"           \"cell_type_ch1\"          \n",
      "[43] \"genotype_ch1\"            \"treatment_ch1\"          \n",
      "[2024-08-26 06:09:08] Step 3: Cleaning specified columns...\n",
      "[2024-08-26 06:09:08] Columns cleaned:\n",
      "[1] \"genotype_ch1\"\n",
      "[2024-08-26 06:09:08] Step 3.1: Mutating and creating new columns...\n",
      "[2024-08-26 06:09:08] New columns created by merging:\n",
      "[1] \"new_col1\"\n",
      "[2024-08-26 06:09:08] Step 4: Joining metadata with GEO-SRA mapping data...\n",
      "[2024-08-26 06:09:08] Metadata joined with GEO-SRA mapping data.\n",
      "[2024-08-26 06:09:08] Step 5: Listing abundance files...\n",
      "[2024-08-26 06:09:08] Abundance files found: 12 files\n",
      "[2024-08-26 06:09:08] Metadata updated with abundance file paths.\n",
      "[2024-08-26 06:09:08] Step 6: Loading tx2gene data...\n",
      "[2024-08-26 06:09:09] tx2gene data loaded.\n",
      "[2024-08-26 06:09:09] Step 7: Importing quantification files...\n",
      "[2024-08-26 06:09:14] Quantification files imported.\n",
      "[2024-08-26 06:09:14] Step 8: Creating DGEList object...\n",
      "[2024-08-26 06:09:15] DGEList object created.\n",
      "[2024-08-26 06:09:15] Step 9: Filtering based on expression...\n",
      "[2024-08-26 06:09:15] Filtering complete. Number of genes retained: 621\n",
      "[2024-08-26 06:09:15] Step 10: Plotting filtering results...\n",
      "null device \n",
      "          1 \n",
      "[2024-08-26 06:09:15] Filtering plot saved as Filtering.png.\n",
      "[2024-08-26 06:09:15] Step 11: Normalizing the DGEList object...\n",
      "[2024-08-26 06:09:15] Normalization complete.\n",
      "[2024-08-26 06:09:15] Step 12: Plotting normalization results...\n",
      "null device \n",
      "          1 \n",
      "[2024-08-26 06:09:15] Normalization plot saved as Normalization.png.\n",
      "[2024-08-26 06:09:15] Step 13: Saving the final DGEList object...\n",
      "[2024-08-26 06:09:15] Final DGEList object saved as DGE.RDS.\n",
      "[2024-08-26 06:09:15] Script execution completed successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "import json\n",
    "\n",
    "# Prepare the command and script path\n",
    "command = \"Rscript\"\n",
    "script_path = \"./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r\"\n",
    "\n",
    "# Define the JSON string for --clean_columns and --mutate_columns\n",
    "clean_columns = json.dumps({\"genotype_ch1\": \"genotype_clean\"})\n",
    "mutate_columns = json.dumps({\"new_col1\": \"genotype_clean+treatment_ch1\"})\n",
    "\n",
    "# Define the argument list with the updated JSON strings\n",
    "args = [\n",
    "    \"--directory\", \"/home/myuser/work/data/kallisto_output/\",\n",
    "    \"--t2g\", \"/home/myuser/work/data/kallisto_indices/human/t2g.txt\",\n",
    "    \"--metadata\", \"/home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv\",\n",
    "    \"--clean_columns\", clean_columns,\n",
    "    \"--merge_columns\", mutate_columns,  # Optional, include only if needed\n",
    "    \"--group\", \"genotype_clean\",\n",
    "    \"--output\", \"./TheLLMPlayground/ManualInputs\",\n",
    "    \"--geo_sra_mapping\", \"/home/myuser/work/notebooks/2_extract_data/results.txt\"\n",
    "]\n",
    "\n",
    "# Combine the command and arguments into a single command string\n",
    "cmd = f\"{command} {script_path} {' '.join(shlex.quote(arg) for arg in args)}\"\n",
    "\n",
    "# Execute the command\n",
    "try:\n",
    "    result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    print(\"Script executed successfully.\")\n",
    "    print(\"Output:\\n\", result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"An error occurred while executing the script.\")\n",
    "    print(\"Error message:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e9e7a5e6-42a5-47e2-910e-c0b19b7d6761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load libraries silently\\nsuppressMessages({\\n  suppressWarnings({\\n    library(tidyverse)\\n    library(edgeR)\\n    library(limma)\\n    library(tximport)\\n    library(DESeq2)\\n    library(janitor)\\n    library(viridis)\\n    library(optparse)\\n    library(jsonlite)  # Add this library to handle JSON strings\\n  })\\n})\\n\\n# Function to print messages with a timestamp\\nprint_message <- function(message) {\\n  cat(sprintf(\"[%s] %s\\\\n\", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\"), message))\\n}\\n\\n# Set up command-line options\\noption_list <- list(\\n  make_option(c(\"-d\", \"--directory\"), type=\"character\", default=NULL,\\n              help=\"Directory containing Kallisto abundance files\", metavar=\"character\"),\\n  make_option(c(\"-t\", \"--t2g\"), type=\"character\", default=NULL,\\n              help=\"Path to t2g.txt file\", metavar=\"character\"),\\n  make_option(c(\"-m\", \"--metadata\"), type=\"character\", default=NULL,\\n              help=\"Path to metadata CSV file\", metavar=\"character\"),\\n  make_option(c(\"-c\", \"--clean_columns\"), type=\"character\", default=NULL,\\n              help=\"Dictionary format: JSON string of columns to clean, e.g., \\'{\\\\\"col1\\\\\":\\\\\"new_col1\\\\\",\\\\\"col2\\\\\":\\\\\"new_col2\\\\\"}\\'\", metavar=\"character\"),\\n  make_option(c(\"-g\", \"--group\"), type=\"character\", default=\"genotype_clean\",\\n              help=\"Group column to use for filtering [default: %default]\", metavar=\"character\"),\\n  make_option(c(\"-o\", \"--output\"), type=\"character\", default=\"./output/\",\\n              help=\"Directory to save output files [default: %default]\", metavar=\"character\"),\\n  make_option(c(\"-r\", \"--geo_sra_mapping\"), type=\"character\", default=NULL,\\n              help=\"Path to GEO-SRA mapping file\", metavar=\"character\"),\\n  make_option(c(\"--merge_columns\"), type=\"character\", default=NULL,\\n              help=\"Dictionary format: JSON string for creating new columns, e.g., \\'{\\\\\"new_col1\\\\\":\\\\\"col1+col2\\\\\",\\\\\"new_col2\\\\\":\\\\\"col3+col4\\\\\"}\\'\", metavar=\"character\")\\n\\n)\\n\\n# Parse options\\nopt_parser <- OptionParser(option_list=option_list)\\nopt <- parse_args(opt_parser)\\n\\n# Ensure required arguments are provided\\nif (is.null(opt$directory) | is.null(opt$t2g) | is.null(opt$metadata) | is.null(opt$geo_sra_mapping)) {\\n  print_help(opt_parser)\\n  stop(\"Please supply the required arguments.\", call.=FALSE)\\n}\\n\\n# Ensure the output directory ends with a slash\\nif (!grepl(\"/$\", opt$output)) {\\n  opt$output <- paste0(opt$output, \"/\")\\n}\\n\\n# Create output directory if it doesn\\'t exist\\nif (!dir.exists(opt$output)) {\\n  dir.create(opt$output, recursive = TRUE)\\n}\\n\\n# Step 1: Load GEO-SRA mapping data\\nprint_message(\"Step 1: Loading GEO-SRA mapping data...\")\\ngeo_sra_map <- read_tsv(opt$geo_sra_mapping) %>%\\n  dplyr::rename(geo_accession = sample_ID)\\nprint_message(\"GEO-SRA mapping data loaded.\")\\n\\n# Step 2: Load metadata\\nprint_message(\"Step 2: Loading metadata...\")\\nmeta <- read_csv(opt$metadata)\\nprint_message(\"Original metadata column names:\")\\nprint(colnames(meta))\\n\\nmeta <- meta %>%\\n  clean_names()\\nprint_message(\"Cleaned metadata column names:\")\\nprint(colnames(meta))\\n\\n# Step 3: Clean specified columns\\nif (!is.null(opt$clean_columns)) {\\n  print_message(\"Step 3: Cleaning specified columns...\")\\n\\n  # Parse the JSON string into a list\\n  cols_to_clean <- fromJSON(opt$clean_columns)\\n\\n  for (old_col in names(cols_to_clean)) {\\n    new_col <- cols_to_clean[[old_col]]\\n    meta <- meta %>%\\n      mutate(!!sym(new_col) := str_remove_all(!!sym(old_col), \" \"))\\n  }\\n  print_message(\"Columns cleaned:\")\\n  print(names(cols_to_clean))\\n}\\n\\n# New Step: Mutate and create new columns by merging specified columns\\nif (!is.null(opt$merge_columns)) {\\n  print_message(\"Step 3.1: Mutating and creating new columns...\")\\n\\n  # Parse the JSON string into a list\\n  mutate_instructions <- fromJSON(opt$merge_columns)\\n\\n  for (new_col in names(mutate_instructions)) {\\n    cols_to_merge <- str_split(mutate_instructions[[new_col]], \"\\\\\\\\+\")[[1]]\\n\\n    meta <- meta %>%\\n      mutate(!!sym(new_col) := paste(!!!syms(cols_to_merge), sep = \"_\"))\\n  }\\n  print_message(\"New columns created by merging:\")\\n  print(names(mutate_instructions))\\n}\\n\\n# Step 4: Join metadata with GEO-SRA mapping data\\nprint_message(\"Step 4: Joining metadata with GEO-SRA mapping data...\")\\nmeta <- left_join(meta, geo_sra_map, by = \"geo_accession\")\\nprint_message(\"Metadata joined with GEO-SRA mapping data.\")\\n\\n# Step 5: List the abundance files\\nprint_message(\"Step 5: Listing abundance files...\")\\nfiles <- list.files(path = opt$directory,\\n                    pattern = \"abundance.tsv\",\\n                    recursive = TRUE,\\n                    full.names = TRUE)\\nprint_message(sprintf(\"Abundance files found: %d files\", length(files)))\\n\\nfile_data <- data.frame(path = files,\\n                        SRA_ID = basename(dirname(files)))\\n\\nmeta <- left_join(meta, file_data, by = \"SRA_ID\")\\nprint_message(\"Metadata updated with abundance file paths.\")\\n\\n# Step 6: Load tx2gene data\\nprint_message(\"Step 6: Loading tx2gene data...\")\\ntx2gene <- read_tsv(opt$t2g, col_names = FALSE) %>%\\n  dplyr::select(1, 3) %>%\\n  drop_na()\\nprint_message(\"tx2gene data loaded.\")\\n\\n# Step 7: Import the quantification files\\nprint_message(\"Step 7: Importing quantification files...\")\\nkallisto <- tximport(files = files,\\n                     type = \"kallisto\",\\n                     tx2gene = tx2gene,\\n                     ignoreAfterBar = TRUE,\\n                     countsFromAbundance = \"lengthScaledTPM\")\\nprint_message(\"Quantification files imported.\")\\n\\n# Step 8: Create a DGEList object\\nprint_message(\"Step 8: Creating DGEList object...\")\\nDGE <- DGEList(counts = kallisto$counts, samples = meta)\\nprint_message(\"DGEList object created.\")\\n\\n# Step 9: Filter based on expression\\nprint_message(\"Step 9: Filtering based on expression...\")\\nkeep.exprs <- filterByExpr(DGE, group = DGE$samples[[opt$group]])\\nDGE.filtered <- DGE[keep.exprs, keep.lib.sizes = FALSE]\\nprint_message(sprintf(\"Filtering complete. Number of genes retained: %d\", sum(keep.exprs)))\\n\\n# Step 10: Plot filtering results\\nprint_message(\"Step 10: Plotting filtering results...\")\\nL <- mean(DGE$samples$lib.size) * 1e-6\\nM <- median(DGE$samples$lib.size) * 1e-6\\n\\ncpm <- cpm(DGE)\\nlcpm <- cpm(DGE, log = TRUE)\\n\\nlcpm.cutoff <- log2(10/M + 2/L)\\nnsamples <- ncol(DGE)\\n\\ncol <- viridis(n = nsamples, direction = -1)\\n\\npng(file.path(opt$output, \"Filtering.png\"))\\n\\npar(mfrow=c(1,2))\\nplot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,0.5), las=2, main=\"\", xlab=\"\")\\ntitle(main=\"A. Unfiltered data\", xlab=\"Log-cpm\")\\nabline(v=lcpm.cutoff, lty=3)\\nfor (i in 2:nsamples) {\\n  den <- density(lcpm[,i])\\n  lines(den$x, den$y, col=col[i], lwd=2)\\n}\\nlcpm <- cpm(DGE.filtered, log=TRUE)\\nplot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,0.5), las=2, main=\"\", xlab=\"\")\\ntitle(main=\"B. Filtered data\", xlab=\"Log-cpm\")\\nabline(v=lcpm.cutoff, lty=3)\\nfor (i in 2:nsamples) {\\n  den <- density(lcpm[,i])\\n  lines(den$x, den$y, col=col[i], lwd=2)\\n}\\n\\ndev.off()\\nprint_message(\"Filtering plot saved as Filtering.png.\")\\n\\n# Step 11: Normalize the DGEList object\\nprint_message(\"Step 11: Normalizing the DGEList object...\")\\nDGE.final <- calcNormFactors(DGE.filtered)\\nprint_message(\"Normalization complete.\")\\n\\n# Step 12: Plot normalization results\\nprint_message(\"Step 12: Plotting normalization results...\")\\npng(file.path(opt$output, \"Normalization.png\"))\\n\\npar(mfrow=c(1,2))\\nlcpm <- cpm(DGE.filtered, log=TRUE)\\nboxplot(lcpm, las=2, main=\"\")\\ntitle(main=\"A. Example: Unnormalised data\",ylab=\"Log-cpm\")\\nlcpm <- cpm(DGE.final, log=TRUE)\\nboxplot(lcpm, las=2, main=\"\")\\ntitle(main=\"B. Example: Normalised data\",ylab=\"Log-cpm\")\\n\\ndev.off()\\nprint_message(\"Normalization plot saved as Normalization.png.\")\\n\\n# Step 13: Save the final DGEList object\\nprint_message(\"Step 13: Saving the final DGEList object...\")\\nsaveRDS(DGE.final, file.path(opt$output, \"DGE.RDS\"))\\nprint_message(\"Final DGEList object saved as DGE.RDS.\")\\n\\nprint_message(\"Script execution completed successfully.\")'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_script_file = \"./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r\"\n",
    "\n",
    "# Read the R script file into a string\n",
    "with open(r_script_file, 'r') as file:\n",
    "    RNAseq_Rscript = file.read()\n",
    "\n",
    "RNAseq_Rscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "58b0131e-1ff1-4339-94a5-7fb12a90ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens:  328\n",
      "Prompt tokens:  5810\n",
      "Total tokens:  6138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FunctionInputs(kallisto_directory='/home/myuser/work/data/kallisto_output/', t2g='/home/myuser/work/data/kallisto_indices/human/t2g.txt', metadata='/home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv', columns_to_clean='{\"genotype:ch1\":\"genotype_clean\",\"treatment:ch1\":\"treatment_clean\"}', filter_group='genotype_clean', output_directory='./TheLLMPlayground/LLMInputs', geo_sra_mapping='/home/myuser/work/notebooks/2_extract_data/results.txt', merge_columns='', justifications=\"The 'kallisto_directory' is set to the provided path containing abundance files, necessary for downstream analysis. The 't2g' path points to the mapping of transcript IDs to gene IDs, crucial for creating the DGEList object. The 'metadata' path is included to extract sample information; it's essential for associating abundances with sample characteristics. The 'columns_to_clean' specifies genotype and treatment columns that need sanitization for proper analysis, thus improving data reliability. The 'filter_group' is set to 'genotype_clean' since it is a logical grouping factor for differential expression analysis based on the experimental design. The 'output_directory' is designated for storing results and outputs, ensuring organized data management. The 'geo_sra_mapping' file path is necessary for linking the GEO accessions to SRA IDs, enriching the metadata context. Not providing 'merge_columns' indicates no additional derived features are required for this analysis step.\")"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FunctionInputs(BaseModel):\n",
    "    kallisto_directory: str = Field(description = \"Name of directory containing Kallisto abundances\")\n",
    "    t2g: str = Field(description = \"Path to the text-to-gene (t2g.txt) file\")\n",
    "    metadata: str = Field(description = \"Path to sample metadata\")\n",
    "    columns_to_clean: str = Field(description = \"Columns where values should be cleaned\")\n",
    "    filter_group: str = Field(description = \"Name of column that should be used to determine experimental sample groups\")\n",
    "    output_directory: str = Field(description = \"Name of output directory\")\n",
    "    geo_sra_mapping: str = Field(description = \"Path to file linking sample GEO accessions to SRA IDs\")\n",
    "    merge_columns: str = Field(description = \"Optional: Columns that should be joined using the dplyr::mutate function\")\n",
    "    justifications: str = Field(description = \"Justifications for selection of all command-line arguments\")\n",
    "\n",
    "RNAseq_Inputs_Prompt = f\"\"\"\n",
    "\n",
    "### IDENTITY AND PURPOSE\n",
    "\n",
    "You are an expert bioinformatician who routinely performs standardized RNAseq experiments to find differentially expressed genes (DEGs) in a given experiment. \n",
    "\n",
    "You will be asked to perform part of an RNAseq analysis on a given dataset. The RNAseq analysis will begin from quantification files produced by Kallisto, and finish with the production of a DGEList object. The RNAseq analysis pipeline will be provided to you - note that this is an R script, with command line arguments. Your task will be to identify the most appropriate parameters for the command line arguments.\n",
    "\n",
    "Carefully follow the steps outlined below to achieve the best possible outcome.\n",
    "\n",
    "### STEPS\n",
    "\n",
    "1. Carefully digest the R script that you will be using. \n",
    "- Take note of the optional parameters\n",
    "- Take note of the functions which are being used for each parameter to ascertain how each parameter is being used\n",
    "- Take note of the description of each parameter to ascertain the necessary format required for the parameter\n",
    "- Take careful note of packages such as \"janitor\" and other value clean-ups, which may change what the correct value should be\n",
    "- Note that this R script has been carefully validated: there are no errors in the script\n",
    "2. Carefully analyse the provided metadata as well as the study summary\n",
    "- Do not assume any additional comparisons which are not explicitly provided\n",
    "- Note that the study summary should be used to \n",
    "- Keep in mind this recommendation: \"The filtering should be based on the grouping factors or treatment factors that will be involved in the differential expression test\"\n",
    "3. After understanding the script and metadata, state the appropriate parameters that should be included.\n",
    "- Note that mutate_columns is optional. If no columns should be joined, then specify NULL\n",
    "4. \n",
    "\n",
    "### OUTPUT \n",
    "\n",
    "- Return the required command line arguments and justification for ALL included arugments\n",
    "\n",
    "### INPUT AND OTHER INFORMATION\n",
    "\n",
    "This is the R script:\n",
    "\n",
    "{RNAseq_Rscript}\n",
    "\n",
    "This is the dataset metadata:\n",
    "\n",
    "{meta.to_string}\n",
    "\n",
    "This is the study summary:\n",
    "\n",
    "{study_summary}\n",
    "\n",
    "Use the following information as well:\n",
    "\n",
    "The Kallisto abundances can be found at /home/myuser/work/data/kallisto_output/\n",
    "The geo_sra_mapping file can be found at /home/myuser/work/notebooks/2_extract_data/results.txt\n",
    "The output should be ./TheLLMPlayground/LLMInputs\n",
    "The metadata can be found at /home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv\n",
    "The text-to-gene file can be found at /home/myuser/work/data/kallisto_indices/human/t2g.txt\n",
    "\n",
    "\"\"\"\n",
    "chat_completion = client.beta.chat.completions.parse(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": RNAseq_Inputs_Prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=FunctionInputs,\n",
    ")\n",
    "\n",
    "print(f\"Generated tokens: \", chat_completion.usage.completion_tokens)\n",
    "print(f\"Prompt tokens: \", chat_completion.usage.prompt_tokens)\n",
    "print(f\"Total tokens: \", chat_completion.usage.total_tokens)\n",
    "\n",
    "result = chat_completion.choices[0].message.parsed\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4bd11449-c372-46be-8595-a96d86ece408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--directory',\n",
       " '/home/myuser/work/data/kallisto_output/',\n",
       " '--t2g',\n",
       " '/home/myuser/work/data/kallisto_indices/human/t2g.txt',\n",
       " '--metadata',\n",
       " '/home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv',\n",
       " '--clean_columns',\n",
       " '{\"genotype:ch1\":\"genotype_clean\",\"treatment:ch1\":\"treatment_clean\"}',\n",
       " '--group',\n",
       " 'genotype_clean',\n",
       " '--output',\n",
       " './TheLLMPlayground/LLMInputs',\n",
       " '--geo_sra_mapping',\n",
       " '/home/myuser/work/notebooks/2_extract_data/results.txt']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_arguments(result):\n",
    "    # Define the argument mapping\n",
    "    arg_map = {\n",
    "        \"kallisto_directory\": \"--directory\",\n",
    "        \"t2g\": \"--t2g\",\n",
    "        \"metadata\": \"--metadata\",\n",
    "        \"columns_to_clean\": \"--clean_columns\",\n",
    "        \"filter_group\": \"--group\",\n",
    "        \"output_directory\": \"--output\",\n",
    "        \"geo_sra_mapping\": \"--geo_sra_mapping\",\n",
    "        \"merge_columns\": \"--merge_columns\"\n",
    "    }\n",
    "    \n",
    "    # Extract values from the result and format them into args\n",
    "    args = []\n",
    "    for attr, arg in arg_map.items():\n",
    "        value = getattr(result, attr, None)\n",
    "        if value:  # Only add if the attribute is not None\n",
    "            args.extend([arg, value])\n",
    "    \n",
    "    return args\n",
    "\n",
    "# Example usage:\n",
    "args = extract_arguments(result)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "bfe6621d-3e51-4d11-99c6-4f482342e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:  Rscript ./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r --directory /home/myuser/work/data/kallisto_output/ --t2g /home/myuser/work/data/kallisto_indices/human/t2g.txt --metadata /home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv --clean_columns '{\"genotype:ch1\":\"genotype_clean\",\"treatment:ch1\":\"treatment_clean\"}' --group genotype_clean --output ./TheLLMPlayground/LLMInputs --geo_sra_mapping /home/myuser/work/notebooks/2_extract_data/results.txt\n",
      "An error occurred while executing the script.\n",
      "Error message:\n",
      " Rows: 12 Columns: 3\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (3): sample_ID, experiment, SRA_ID\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Rows: 12 Columns: 44\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \",\"\n",
      "chr (41): title, geo_accession, status, submission_date, last_update_date, t...\n",
      "dbl  (3): channel_count, taxid_ch1, data_row_count\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Error in `mutate()`:\n",
      "ℹ In argument: `genotype_clean = str_remove_all(`genotype:ch1`, \" \")`.\n",
      "Caused by error in `vctrs::vec_size_common()`:\n",
      "! object 'genotype:ch1' not found\n",
      "Backtrace:\n",
      "     ▆\n",
      "  1. ├─meta %>% ...\n",
      "  2. ├─dplyr::mutate(...)\n",
      "  3. ├─dplyr:::mutate.data.frame(., `:=`(!!sym(new_col), str_remove_all(!!sym(old_col), \" \")))\n",
      "  4. │ └─dplyr:::mutate_cols(.data, dplyr_quosures(...), by)\n",
      "  5. │   ├─base::withCallingHandlers(...)\n",
      "  6. │   └─dplyr:::mutate_col(dots[[i]], data, mask, new_columns)\n",
      "  7. │     └─mask$eval_all_mutate(quo)\n",
      "  8. │       └─dplyr (local) eval()\n",
      "  9. ├─stringr::str_remove_all(`genotype:ch1`, \" \")\n",
      " 10. │ └─stringr::str_replace_all(string, pattern, \"\")\n",
      " 11. │   └─stringr:::check_lengths(string, pattern, replacement)\n",
      " 12. │     └─vctrs::vec_size_common(...)\n",
      " 13. └─base::.handleSimpleError(...)\n",
      " 14.   └─dplyr (local) h(simpleError(msg, call))\n",
      " 15.     └─rlang::abort(message, class = error_class, parent = parent, call = error_call)\n",
      "Execution halted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command = \"Rscript\"\n",
    "script_path = \"./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r\"\n",
    "\n",
    "def extract_arguments(result):\n",
    "    # Define the argument mapping\n",
    "    arg_map = {\n",
    "        \"kallisto_directory\": \"--directory\",\n",
    "        \"t2g\": \"--t2g\",\n",
    "        \"metadata\": \"--metadata\",\n",
    "        \"columns_to_clean\": \"--clean_columns\",\n",
    "        \"filter_group\": \"--group\",\n",
    "        \"output_directory\": \"--output\",\n",
    "        \"geo_sra_mapping\": \"--geo_sra_mapping\",\n",
    "        \"merge_columns\": \"--merge_columns\"\n",
    "    }\n",
    "    \n",
    "    # Extract values from the result and format them into args\n",
    "    args = []\n",
    "    for attr, arg in arg_map.items():\n",
    "        value = getattr(result, attr, None)\n",
    "        if value:  # Only add if the attribute is not None\n",
    "            args.extend([arg, value])\n",
    "    \n",
    "    return args\n",
    "\n",
    "# Example usage:\n",
    "args = extract_arguments(result)\n",
    "args\n",
    "\n",
    "# Combine the command and arguments into a single command string\n",
    "cmd = f\"{command} {script_path} {' '.join(shlex.quote(arg) for arg in args)}\"\n",
    "print(\"Executing command: \", cmd)\n",
    "# Execute the command\n",
    "try:\n",
    "    result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    print(\"Script executed successfully.\")\n",
    "    print(\"Output:\\n\", result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"An error occurred while executing the script.\")\n",
    "    print(\"Error message:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3bfa9f55-35b9-4c3e-b0ce-ec09b4e2edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens:  462\n",
      "Prompt tokens:  11654\n",
      "Total tokens:  12116\n",
      "Attempt 1: Executing command: Rscript ./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r --directory /home/myuser/work/data/kallisto_output/ --t2g /home/myuser/work/data/kallisto_indices/human/t2g.txt --metadata /home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv --clean_columns '{\"genotype:ch1\":\"genotype_clean\",\"treatment:ch1\":\"treatment_clean\"}' --group genotype_clean --output ./TheLLMPlayground/LLMInputs --geo_sra_mapping /home/myuser/work/notebooks/2_extract_data/results.txt\n",
      "Justification: The provided parameters were chosen after a careful review of the RNAseq analysis pipeline and available dataset metadata. 1. **kallisto_directory**: This points to the correct folder where Kallisto output files are stored, which is essential for importing quantification files. 2. **t2g**: The path to the text-to-gene mapping file is provided to facilitate the mapping of transcripts to genes during quantification file import. 3. **metadata**: The specified metadata path is necessary to load sample information that will be linked to the quantification data. 4. **columns_to_clean**: This maps the original column names to cleaned versions. Based on the metadata, 'genotype:ch1' is cleaned to 'genotype_clean' for consistent naming to avoid any errors during analysis, and 'treatment:ch1' is similarly cleaned to 'treatment_clean'. 5. **filter_group**: Selected 'genotype_clean' as the group column for filtering, as it directly represents distinct experimental conditions for differential expression analysis. 6. **output_directory**: Specified to ensure all generated output files are saved in an organized manner. 7. **geo_sra_mapping**: Supplied for linking GEO accessions to SRA IDs, a critical step for full integration of sampled data. 8. **merge_columns**: Set to NULL because there are no additional columns to create via merging as indicated in the provided information. Please note: no prior error messages were reported, so all parameters were selected based on exploring the R script and available metadata.\n",
      "[2024-08-26 07:45:43] Step 1: Loading GEO-SRA mapping data...\n",
      "[2024-08-26 07:45:43] GEO-SRA mapping data loaded.\n",
      "[2024-08-26 07:45:43] Step 2: Loading metadata...\n",
      "[2024-08-26 07:45:43] Original metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1.1\"   \"characteristics_ch1.2\"  \n",
      "[13] \"characteristics_ch1.3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1.1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing.1\"       \"data_processing.2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip/postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation.1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell line:ch1\"           \"cell type:ch1\"          \n",
      "[43] \"genotype:ch1\"            \"treatment:ch1\"          \n",
      "[2024-08-26 07:45:43] Cleaned metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1_1\"   \"characteristics_ch1_2\"  \n",
      "[13] \"characteristics_ch1_3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1_1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing_1\"       \"data_processing_2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip_postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation_1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell_line_ch1\"           \"cell_type_ch1\"          \n",
      "[43] \"genotype_ch1\"            \"treatment_ch1\"          \n",
      "[2024-08-26 07:45:43] Step 3: Cleaning specified columns...\n",
      "Attempt 1 failed.\n",
      "Retrying with error information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rows: 12 Columns: 3\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (3): sample_ID, experiment, SRA_ID\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Rows: 12 Columns: 44\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \",\"\n",
      "chr (41): title, geo_accession, status, submission_date, last_update_date, t...\n",
      "dbl  (3): channel_count, taxid_ch1, data_row_count\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Error in `mutate()`:\n",
      "ℹ In argument: `genotype_clean = str_remove_all(`genotype:ch1`, \" \")`.\n",
      "Caused by error in `vctrs::vec_size_common()`:\n",
      "! object 'genotype:ch1' not found\n",
      "Backtrace:\n",
      "     ▆\n",
      "  1. ├─meta %>% ...\n",
      "  2. ├─dplyr::mutate(...)\n",
      "  3. ├─dplyr:::mutate.data.frame(., `:=`(!!sym(new_col), str_remove_all(!!sym(old_col), \" \")))\n",
      "  4. │ └─dplyr:::mutate_cols(.data, dplyr_quosures(...), by)\n",
      "  5. │   ├─base::withCallingHandlers(...)\n",
      "  6. │   └─dplyr:::mutate_col(dots[[i]], data, mask, new_columns)\n",
      "  7. │     └─mask$eval_all_mutate(quo)\n",
      "  8. │       └─dplyr (local) eval()\n",
      "  9. ├─stringr::str_remove_all(`genotype:ch1`, \" \")\n",
      " 10. │ └─stringr::str_replace_all(string, pattern, \"\")\n",
      " 11. │   └─stringr:::check_lengths(string, pattern, replacement)\n",
      " 12. │     └─vctrs::vec_size_common(...)\n",
      " 13. └─base::.handleSimpleError(...)\n",
      " 14.   └─dplyr (local) h(simpleError(msg, call))\n",
      " 15.     └─rlang::abort(message, class = error_class, parent = parent, call = error_call)\n",
      "Execution halted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens:  560\n",
      "Prompt tokens:  13172\n",
      "Total tokens:  13732\n",
      "Attempt 2: Executing command: Rscript ./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r --directory /home/myuser/work/data/kallisto_output/ --t2g /home/myuser/work/data/kallisto_indices/human/t2g.txt --metadata /home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv --clean_columns '{\"genotype_ch1\":\"genotype_clean\",\"treatment_ch1\":\"treatment_clean\"}' --group genotype_clean --output ./TheLLMPlayground/LLMInputs --geo_sra_mapping /home/myuser/work/notebooks/2_extract_data/results.txt\n",
      "Justification: The provided command-line arguments have been chosen based on several key considerations:\n",
      "\n",
      "1. **Kallisto Directory**: Set to the location of Kallisto output files as specified. This is essential for the analysis to find the appropriate quantification data.\n",
      "\n",
      "2. **T2G File**: The path to the text-to-gene file is required for mapping transcript identifiers to gene identifiers, which is necessary for further analysis.\n",
      "\n",
      "3. **Metadata**: The path to the metadata file must be provided to join with other datasets and get essential sample characteristics for analysis.\n",
      "\n",
      "4. **Columns to Clean**: This parameter is specified as a JSON string mapping the original column names to cleaned names. The errors encountered previously arose because the original metadata columns had colons (':') which led to issues in processing through R's `dplyr` functions. The entries have been adjusted to match the cleaned column names as per the output from the `janitor` clean_names() function. Therefore, 'genotype:ch1' is referred to as 'genotype_ch1', and 'treatment:ch1' is referred to as 'treatment_ch1'. \n",
      "\n",
      "5. **Filter Group**: The grouping factor specified is 'genotype_clean'. This is essential for filtering based on the identified sample groups during DEGs analysis. \n",
      "\n",
      "6. **Output Directory**: This is the desired directory for saving output files generated by the script. The default inclusion makes organizational sense. \n",
      "\n",
      "7. **GEO-SRA Mapping**: The path to the GEO-SRA mapping file is included to link metadata with SRA IDs accurately.\n",
      "\n",
      "8. **Merge Columns**: As no new columns need to be created through merging based on previous findings, this parameter is set to NULL or its equivalent in command format.\n",
      "\n",
      "9. **Error Consideration**: Previous error messages indicated that the script was unable to locate the original column names due to incorrect naming in the cleaning function. Adjustments were made as per the new cleaned names.\n",
      "[2024-08-26 07:46:00] Step 1: Loading GEO-SRA mapping data...\n",
      "[2024-08-26 07:46:00] GEO-SRA mapping data loaded.\n",
      "[2024-08-26 07:46:00] Step 2: Loading metadata...\n",
      "[2024-08-26 07:46:00] Original metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1.1\"   \"characteristics_ch1.2\"  \n",
      "[13] \"characteristics_ch1.3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1.1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing.1\"       \"data_processing.2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip/postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation.1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell line:ch1\"           \"cell type:ch1\"          \n",
      "[43] \"genotype:ch1\"            \"treatment:ch1\"          \n",
      "[2024-08-26 07:46:00] Cleaned metadata column names:\n",
      " [1] \"title\"                   \"geo_accession\"          \n",
      " [3] \"status\"                  \"submission_date\"        \n",
      " [5] \"last_update_date\"        \"type\"                   \n",
      " [7] \"channel_count\"           \"source_name_ch1\"        \n",
      " [9] \"organism_ch1\"            \"characteristics_ch1\"    \n",
      "[11] \"characteristics_ch1_1\"   \"characteristics_ch1_2\"  \n",
      "[13] \"characteristics_ch1_3\"   \"treatment_protocol_ch1\" \n",
      "[15] \"growth_protocol_ch1\"     \"molecule_ch1\"           \n",
      "[17] \"extract_protocol_ch1\"    \"extract_protocol_ch1_1\" \n",
      "[19] \"taxid_ch1\"               \"data_processing\"        \n",
      "[21] \"data_processing_1\"       \"data_processing_2\"      \n",
      "[23] \"platform_id\"             \"contact_name\"           \n",
      "[25] \"contact_email\"           \"contact_phone\"          \n",
      "[27] \"contact_institute\"       \"contact_address\"        \n",
      "[29] \"contact_city\"            \"contact_state\"          \n",
      "[31] \"contact_zip_postal_code\" \"contact_country\"        \n",
      "[33] \"data_row_count\"          \"instrument_model\"       \n",
      "[35] \"library_selection\"       \"library_source\"         \n",
      "[37] \"library_strategy\"        \"relation\"               \n",
      "[39] \"relation_1\"              \"supplementary_file_1\"   \n",
      "[41] \"cell_line_ch1\"           \"cell_type_ch1\"          \n",
      "[43] \"genotype_ch1\"            \"treatment_ch1\"          \n",
      "[2024-08-26 07:46:00] Step 3: Cleaning specified columns...\n",
      "[2024-08-26 07:46:00] Columns cleaned:\n",
      "[1] \"genotype_ch1\"  \"treatment_ch1\"\n",
      "[2024-08-26 07:46:00] Step 4: Joining metadata with GEO-SRA mapping data...\n",
      "[2024-08-26 07:46:00] Metadata joined with GEO-SRA mapping data.\n",
      "[2024-08-26 07:46:00] Step 5: Listing abundance files...\n",
      "[2024-08-26 07:46:00] Abundance files found: 12 files\n",
      "[2024-08-26 07:46:00] Metadata updated with abundance file paths.\n",
      "[2024-08-26 07:46:00] Step 6: Loading tx2gene data...\n",
      "[2024-08-26 07:46:01] tx2gene data loaded.\n",
      "[2024-08-26 07:46:01] Step 7: Importing quantification files...\n",
      "[2024-08-26 07:46:06] Quantification files imported.\n",
      "[2024-08-26 07:46:06] Step 8: Creating DGEList object...\n",
      "[2024-08-26 07:46:06] DGEList object created.\n",
      "[2024-08-26 07:46:06] Step 9: Filtering based on expression...\n",
      "[2024-08-26 07:46:06] Filtering complete. Number of genes retained: 621\n",
      "[2024-08-26 07:46:06] Step 10: Plotting filtering results...\n",
      "null device \n",
      "          1 \n",
      "[2024-08-26 07:46:06] Filtering plot saved as Filtering.png.\n",
      "[2024-08-26 07:46:06] Step 11: Normalizing the DGEList object...\n",
      "[2024-08-26 07:46:06] Normalization complete.\n",
      "[2024-08-26 07:46:06] Step 12: Plotting normalization results...\n",
      "null device \n",
      "          1 \n",
      "[2024-08-26 07:46:06] Normalization plot saved as Normalization.png.\n",
      "[2024-08-26 07:46:06] Step 13: Saving the final DGEList object...\n",
      "[2024-08-26 07:46:06] Final DGEList object saved as DGE.RDS.\n",
      "[2024-08-26 07:46:06] Script execution completed successfully.\n",
      "Script executed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rows: 12 Columns: 3\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (3): sample_ID, experiment, SRA_ID\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Rows: 12 Columns: 44\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \",\"\n",
      "chr (41): title, geo_accession, status, submission_date, last_update_date, t...\n",
      "dbl  (3): channel_count, taxid_ch1, data_row_count\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Rows: 227665 Columns: 8\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (6): X1, X2, X3, X4, X5, X8\n",
      "dbl (2): X6, X7\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Note: importing `abundance.h5` is typically faster than `abundance.tsv`\n",
      "reading in files with read_tsv\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 \n",
      "transcripts missing from tx2gene: 24683\n",
      "summarizing abundance\n",
      "summarizing counts\n",
      "summarizing length\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class FunctionInputs(BaseModel):\n",
    "    kallisto_directory: str = Field(description=\"Name of directory containing Kallisto abundances\")\n",
    "    t2g: str = Field(description=\"Path to the text-to-gene (t2g.txt) file\")\n",
    "    metadata: str = Field(description=\"Path to sample metadata\")\n",
    "    columns_to_clean: str = Field(description=\"Columns where values should be cleaned\")\n",
    "    filter_group: str = Field(description=\"Name of column that should be used to determine experimental sample groups\")\n",
    "    output_directory: str = Field(description=\"Name of output directory\")\n",
    "    geo_sra_mapping: str = Field(description=\"Path to file linking sample GEO accessions to SRA IDs\")\n",
    "    merge_columns: str = Field(description=\"Optional: Columns that should be joined using the dplyr::mutate function\")\n",
    "    justifications: str = Field(description=\"Justifications for selection of all command-line arguments\")\n",
    "\n",
    "def run_rnaseq_analysis(RNAseq_Rscript, meta, study_summary, max_retries=3):\n",
    "    def generate_prompt(error_message=None):\n",
    "        prompt = f\"\"\"\n",
    "        ### IDENTITY AND PURPOSE\n",
    "        You are an expert bioinformatician who routinely performs standardized RNAseq experiments to find differentially expressed genes (DEGs) in a given experiment. \n",
    "        You will be asked to perform part of an RNAseq analysis on a given dataset. The RNAseq analysis will begin from quantification files produced by Kallisto, and finish with the production of a DGEList object. The RNAseq analysis pipeline will be provided to you - note that this is an R script, with command line arguments. Your task will be to identify the most appropriate parameters for the command line arguments.\n",
    "        Carefully follow the steps outlined below to achieve the best possible outcome.\n",
    "        ### STEPS\n",
    "        1. Carefully digest the R script that you will be using. \n",
    "        - Take note of the optional parameters\n",
    "        - Take note of the functions which are being used for each parameter to ascertain how each parameter is being used\n",
    "        - Take note of the description of each parameter to ascertain the necessary format required for the parameter\n",
    "        - Take careful note of packages such as \"janitor\" and other value clean-ups, which may change what the correct value should be. For example, if the original column name is \"genotype:ch1\", this will likely be changed to \"genotype_ch1\"\n",
    "        - Note that this R script has been carefully validated: there are no errors in the script\n",
    "        - The columns to clean should be used for any column that may be used for identification of DEGs\n",
    "        - The columns to merged should be used when identification of DEGs makes use of multiple groups simulataneously\n",
    "            - For example, if we are interested in \"Treatment X vs Y in Genotype A\", then the Treatment and Genotype columns should be merged\n",
    "        2. Carefully analyse the provided metadata as well as the study summary\n",
    "        - Do not assume any additional comparisons which are not explicitly provided\n",
    "        - Note that the study summary should be used to \n",
    "        - Keep in mind this recommendation: \"The filtering should be based on the grouping factors or treatment factors that will be involved in the differential expression test\"\n",
    "        3. After understanding the script and metadata, state the appropriate parameters that should be included.\n",
    "        - Note that mutate_columns is optional. If no columns should be joined, then specify NULL\n",
    "        4. If you have been provided error messages, take into consideration these error messages \n",
    "        ### OUTPUT \n",
    "        - Return the required command line arguments and justification for ALL included arguments\n",
    "        - If there was previous error messages, describe how you have incorporated this information in your response as part of the justificaiton \n",
    "        - If no error message was provided, explicitly indicate this as well.\n",
    "        ### INPUT AND OTHER INFORMATION\n",
    "        This is the R script:\n",
    "        {RNAseq_Rscript}\n",
    "        This is the dataset metadata:\n",
    "        {meta.to_string()}\n",
    "        This is the study summary:\n",
    "        {study_summary}\n",
    "        Use the following information as well:\n",
    "        The Kallisto abundances can be found at /home/myuser/work/data/kallisto_output/\n",
    "        The geo_sra_mapping file can be found at /home/myuser/work/notebooks/2_extract_data/results.txt\n",
    "        The output should be ./TheLLMPlayground/LLMInputs\n",
    "        The metadata can be found at /home/myuser/work/notebooks/Testing/GSE268034/GSE268034_series_matrix_metadata.csv\n",
    "        The text-to-gene file can be found at /home/myuser/work/data/kallisto_indices/human/t2g.txt\n",
    "        \"\"\"\n",
    "        if error_message:\n",
    "            prompt += f\"\"\"\\n### PREVIOUS ERROR\\nThe previous attempt resulted in the following error. Please adjust your recommendations accordingly:\\n{error_message}\n",
    "            \n",
    "            The command used to produce this error message was {cmd}\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def extract_arguments(result):\n",
    "        arg_map = {\n",
    "            \"kallisto_directory\": \"--directory\",\n",
    "            \"t2g\": \"--t2g\",\n",
    "            \"metadata\": \"--metadata\",\n",
    "            \"columns_to_clean\": \"--clean_columns\",\n",
    "            \"filter_group\": \"--group\",\n",
    "            \"output_directory\": \"--output\",\n",
    "            \"geo_sra_mapping\": \"--geo_sra_mapping\",\n",
    "            \"merge_columns\": \"--merge_columns\"\n",
    "        }\n",
    "        args = []\n",
    "        for attr, arg in arg_map.items():\n",
    "            value = getattr(result, attr, None)\n",
    "            if value:\n",
    "                args.extend([arg, value])\n",
    "        return args\n",
    "\n",
    "    command = \"Rscript\"\n",
    "    script_path = \"./ManualRNASeqAnalysis/RNASeq_DGEObjectCreate.r\"\n",
    "\n",
    "    error_message = None  # Initialize error_message to None\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            chat_completion = client.beta.chat.completions.parse(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": generate_prompt(error_message),\n",
    "                    }\n",
    "                ],\n",
    "                model=\"gpt-4o-mini\",\n",
    "                response_format=FunctionInputs,\n",
    "            )\n",
    "            print(f\"Generated tokens: \", chat_completion.usage.completion_tokens)\n",
    "            print(f\"Prompt tokens: \", chat_completion.usage.prompt_tokens)\n",
    "            print(f\"Total tokens: \", chat_completion.usage.total_tokens)\n",
    "            result = chat_completion.choices[0].message.parsed\n",
    "            args = extract_arguments(result)\n",
    "            cmd = f\"{command} {script_path} {' '.join(shlex.quote(arg) for arg in args)}\"\n",
    "            \n",
    "            print(f\"Attempt {attempt + 1}: Executing command: {cmd}\")\n",
    "            print(f\"Justification: {chat_completion.choices[0].message.parsed.justifications}\")\n",
    "            \n",
    "            # Execute the command with real-time output capture\n",
    "            process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "            # Capture and store stdout and stderr\n",
    "            stdout, stderr = process.communicate()\n",
    "            \n",
    "            # Print stdout and stderr\n",
    "            sys.stdout.write(stdout)\n",
    "            sys.stderr.write(stderr)\n",
    "\n",
    "            if process.returncode == 0:\n",
    "                print(\"Script executed successfully.\")\n",
    "                return process\n",
    "            else:\n",
    "                # Create a combined error message\n",
    "                error_message = f\"STDOUT:\\n{stdout}\\nSTDERR:\\n{stderr}\"\n",
    "                raise subprocess.CalledProcessError(process.returncode, cmd)\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Attempt {attempt + 1} failed.\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(\"Retrying with error information...\")\n",
    "                time.sleep(2)  # Add a short delay before retrying\n",
    "            else:\n",
    "                print(\"Max retries reached. Analysis failed.\")\n",
    "                raise\n",
    "\n",
    "    return None\n",
    "\n",
    "result = run_rnaseq_analysis(RNAseq_Rscript, meta, study_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Poetry)",
   "language": "python",
   "name": "poetry-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
